{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "57d13e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from shapely.ops import nearest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "647a18bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# 1. Load & Clean Tabular CSV Features\n",
    "# -------------------------------------\n",
    "\n",
    "# Adjust these paths if your filenames differ - using raw GitHub URLs\n",
    "hv_path     = 'https://raw.githubusercontent.com/IflyNY2PR/CASA0004/071702afad8b880e82c9ed33500e52ba2508e055/data-preparation/economic/housing-value.csv'\n",
    "ptal_path   = 'https://raw.githubusercontent.com/IflyNY2PR/CASA0004/071702afad8b880e82c9ed33500e52ba2508e055/data-preparation/Infrastructure/LSOA_aggregated_PTAL_stats_2023.csv'\n",
    "ls_path     = 'https://raw.githubusercontent.com/IflyNY2PR/CASA0004/071702afad8b880e82c9ed33500e52ba2508e055/data-preparation/social/demographic/lsoa-data.csv'\n",
    "sent_path   = 'https://raw.githubusercontent.com/IflyNY2PR/CASA0004/071702afad8b880e82c9ed33500e52ba2508e055/data-preparation/social/lsoa_sentiment_stats.csv'\n",
    "\n",
    "# Read CSVs (use latin-1 if you hit encoding errors)\n",
    "hv   = pd.read_csv(hv_path, encoding='latin-1', low_memory=False)\n",
    "ptal = pd.read_csv(ptal_path, encoding='latin-1', low_memory=False)\n",
    "ls   = pd.read_csv(ls_path, encoding='latin-1', low_memory=False)\n",
    "sent = pd.read_csv(sent_path, encoding='latin-1', low_memory=False)\n",
    "\n",
    "# --- Housing Value ---\n",
    "# Use LSOA code column (not the first column which is Local authority code)\n",
    "hv_code   = 'LSOA code'  # Use the correct LSOA code column\n",
    "# Find the column with 'Mar' and '2023' - use a safer approach\n",
    "mar_2023_cols = [c for c in hv.columns if 'Mar' in c and '2023' in c]\n",
    "if mar_2023_cols:\n",
    "    hv_price = mar_2023_cols[0]\n",
    "else:\n",
    "    # Fallback to the last column if no Mar 2023 found\n",
    "    hv_price = hv.columns[-1]\n",
    "hv_sales  = next((c for c in hv.columns if 'sale' in c.lower()), None)\n",
    "hv_cols   = [hv_code, hv_price] + ([hv_sales] if hv_sales else [])\n",
    "hv_tab    = hv[hv_cols].copy()\n",
    "hv_tab.columns = ['LSOA_CODE', 'AvgPrice'] + (['NumSales'] if hv_sales else [])\n",
    "\n",
    "# Convert price from string to numeric (remove commas and convert to float)\n",
    "hv_tab['AvgPrice'] = hv_tab['AvgPrice'].astype(str).str.replace(',', '').replace('', None)\n",
    "hv_tab['AvgPrice'] = pd.to_numeric(hv_tab['AvgPrice'], errors='coerce')\n",
    "\n",
    "# --- PTAL Stats ---\n",
    "# Handle BOM character in column name\n",
    "ptal_code_col = ptal.columns[0]  # This will be 'ï»¿LSOA21CD'\n",
    "ptal_tab = ptal[[ptal_code_col,'MEAN_PTAL_2023','MAX_AI','MIN_AI']].rename(\n",
    "    columns={ptal_code_col:'LSOA_CODE'}\n",
    ")\n",
    "\n",
    "# --- Demographics & Area ---\n",
    "ls_code  = ls.columns[0]\n",
    "# Find population column - try 2023 first, then any population column\n",
    "ls_pop_candidates = [c for c in ls.columns if 'Population' in c and '2023' in c]\n",
    "if not ls_pop_candidates:\n",
    "    ls_pop_candidates = [c for c in ls.columns if 'Population' in c]\n",
    "ls_pop = ls_pop_candidates[0] if ls_pop_candidates else None\n",
    "\n",
    "# Find IMD column\n",
    "ls_imd_candidates = [c for c in ls.columns if 'IMD' in c.upper()]\n",
    "ls_imd = ls_imd_candidates[0] if ls_imd_candidates else None\n",
    "\n",
    "# Find area column\n",
    "ls_area_candidates = [c for c in ls.columns if 'AREA' in c.upper()]\n",
    "ls_area = ls_area_candidates[0] if ls_area_candidates else None\n",
    "\n",
    "# Build the columns list, only including found columns\n",
    "ls_cols = [ls_code]\n",
    "ls_col_names = ['LSOA_CODE']\n",
    "if ls_pop:\n",
    "    ls_cols.append(ls_pop)\n",
    "    ls_col_names.append('Population')\n",
    "if ls_imd:\n",
    "    ls_cols.append(ls_imd)\n",
    "    ls_col_names.append('IMD_Decile')\n",
    "if ls_area:\n",
    "    ls_cols.append(ls_area)\n",
    "    ls_col_names.append('Area_km2')\n",
    "\n",
    "ls_tab = ls[ls_cols].copy()\n",
    "ls_tab.columns = ls_col_names\n",
    "\n",
    "# --- Sentiment Stats ---\n",
    "sent_tab = sent[['LSOA','Avg_Sentiment_Score','Sentiment_Std','Total_Reviews']].rename(\n",
    "    columns={\n",
    "        'LSOA':'LSOA_CODE',\n",
    "        'Avg_Sentiment_Score':'MeanSentiment',\n",
    "        'Sentiment_Std':'SentimentSD',\n",
    "        'Total_Reviews':'ReviewCount'\n",
    "    }\n",
    ")\n",
    "\n",
    "# Merge all tabular data\n",
    "df_tab = (\n",
    "    hv_tab\n",
    "    .merge(ptal_tab, on='LSOA_CODE', how='outer')\n",
    "    .merge(ls_tab,   on='LSOA_CODE', how='outer')\n",
    "    .merge(sent_tab, on='LSOA_CODE', how='outer')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "f2399287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using column 'code' as LSOA code column\n",
      "Sample values: ['E01000037', 'E01033729', 'E01000038', 'E01033730', 'E01000039']\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# 2. Download & Unzip Shapefiles Layers\n",
    "# ---------------------------------\n",
    "import requests\n",
    "\n",
    "zip_paths = {\n",
    "    'lsoa':       'https://github.com/IflyNY2PR/CASA0004/raw/071702afad8b880e82c9ed33500e52ba2508e055/data-preparation/shapefiles/lsoa.zip',\n",
    "    'street':     'https://github.com/IflyNY2PR/CASA0004/raw/071702afad8b880e82c9ed33500e52ba2508e055/data-preparation/shapefiles/streetnetwork.zip',\n",
    "    'station':    'https://github.com/IflyNY2PR/CASA0004/raw/071702afad8b880e82c9ed33500e52ba2508e055/data-preparation/shapefiles/station.zip',\n",
    "    'landuse':    'https://github.com/IflyNY2PR/CASA0004/raw/071702afad8b880e82c9ed33500e52ba2508e055/data-preparation/shapefiles/landuse.zip',\n",
    "    'rail':       'https://github.com/IflyNY2PR/CASA0004/raw/071702afad8b880e82c9ed33500e52ba2508e055/data-preparation/shapefiles/railnetwork.zip'\n",
    "}\n",
    "\n",
    "# Download and extract each zip file\n",
    "for name, zip_url in zip_paths.items():\n",
    "    outdir = f'./{name}'\n",
    "    zip_path = f'./{name}.zip'\n",
    "    \n",
    "    if not os.path.isdir(outdir):\n",
    "        os.makedirs(outdir, exist_ok=True)\n",
    "        \n",
    "        # Download the zip file\n",
    "        print(f\"Downloading {name}...\")\n",
    "        response = requests.get(zip_url)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Save the zip file\n",
    "        with open(zip_path, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        # Extract the zip file\n",
    "        print(f\"Extracting {name}...\")\n",
    "        with zipfile.ZipFile(zip_path, 'r') as z:\n",
    "            z.extractall(outdir)\n",
    "        \n",
    "        # Clean up the zip file\n",
    "        os.remove(zip_path)\n",
    "\n",
    "def find_shp(dirpath):\n",
    "    for root, _, files in os.walk(dirpath):\n",
    "        for f in files:\n",
    "            if f.lower().endswith('.shp') and not f.startswith('._'):\n",
    "                return os.path.join(root, f)\n",
    "    raise FileNotFoundError(f\"No .shp in {dirpath}\")\n",
    "\n",
    "def load_gdf(shp_path):\n",
    "    with fiona.open(shp_path) as src:\n",
    "        feats = list(src)\n",
    "        return gpd.GeoDataFrame.from_features(feats, crs=src.crs)\n",
    "\n",
    "# Load & reproject layers\n",
    "lsoa_gdf    = load_gdf(find_shp('./lsoa')).to_crs('EPSG:27700')\n",
    "street_gdf  = load_gdf(find_shp('./street')).to_crs('EPSG:27700')\n",
    "station_gdf = load_gdf(find_shp('./station')).to_crs('EPSG:27700')\n",
    "landuse_gdf = load_gdf(find_shp('./landuse')).to_crs('EPSG:27700')\n",
    "rail_gdf    = load_gdf(find_shp('./rail')).to_crs('EPSG:27700')\n",
    "\n",
    "# Determine the code column in LSOA shapefile\n",
    "# Look for columns that might contain LSOA codes\n",
    "possible_code_cols = [c for c in lsoa_gdf.columns if 'LSOA' in c.upper() and lsoa_gdf[c].dtype == object]\n",
    "if possible_code_cols:\n",
    "    shp_code = possible_code_cols[0]\n",
    "else:\n",
    "    # Fallback to 'code' column if no LSOA-named column found\n",
    "    shp_code = 'code'\n",
    "\n",
    "print(f\"Using column '{shp_code}' as LSOA code column\")\n",
    "print(f\"Sample values: {lsoa_gdf[shp_code].head().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "498603cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Checking: Merged Tabular Data (df_tab) ---\n",
      "\n",
      "Shape: (35090, 10)\n",
      "Columns: ['LSOA_CODE', 'AvgPrice', 'MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount']\n",
      "Total Missing Values: 250189\n",
      "\n",
      "Head:\n",
      "   LSOA_CODE  AvgPrice MEAN_PTAL_2023      MAX_AI     MIN_AI  Population  \\\n",
      "0  E01000001  837500.0             6b   97.664050  43.344686      1615.0   \n",
      "1  E01000002  850000.0             6b  102.127724  44.802674      1493.0   \n",
      "2  E01000003  540000.0             6b   66.989479  36.995870      1573.0   \n",
      "3  E01000005       NaN             6b  104.154096  45.504887      1090.0   \n",
      "4  E01000006  241000.0              5   33.400903   2.836977      1612.0   \n",
      "\n",
      "    Area_km2  MeanSentiment  SentimentSD  ReviewCount  \n",
      "0  E01000001          0.427        0.312       1505.0  \n",
      "1  E01000002          0.524        0.188       5819.0  \n",
      "2  E01000003          0.317          NaN          3.0  \n",
      "3  E01000005          0.675        0.100       1067.0  \n",
      "4  E01000006            NaN          NaN          NaN  \n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Checking: LSOA Polygons (lsoa_gdf) ---\n",
      "\n",
      "Shape: (4719, 7)\n",
      "Columns: ['geometry', 'code', 'name', 'label', 'Area', 'Half densi', 'Area2']\n",
      "Total Missing Values: 0\n",
      "CRS: EPSG:27700\n",
      "Geometry Type: ['Polygon' 'MultiPolygon']\n",
      "\n",
      "Head:\n",
      "                                            geometry       code  \\\n",
      "0  POLYGON ((551549.998 187364.637, 551528.633 18...  E01000037   \n",
      "1  POLYGON ((544812 174524, 544819.775 174523.378...  E01033729   \n",
      "2  POLYGON ((550920.362 187341.138, 550921.876 18...  E01000038   \n",
      "3  POLYGON ((537938 177696, 537941.714 177678.043...  E01033730   \n",
      "4  POLYGON ((551431.061 186927.155, 551444.481 18...  E01000039   \n",
      "\n",
      "                        name                        label     Area  \\\n",
      "0  Barking and Dagenham 003B  E09000002E02000004E01000037   233488   \n",
      "1             Greenwich 030E  E09000011E02000342E01033729   691074   \n",
      "2  Barking and Dagenham 003C  E09000002E02000004E01000038   214094   \n",
      "3             Greenwich 035D  E09000011E02006928E01033730   187153   \n",
      "4  Barking and Dagenham 003D  E09000002E02000004E01000039  1532166   \n",
      "\n",
      "   Half densi    Area2  \n",
      "0        3764   233488  \n",
      "1        2034   691074  \n",
      "2        3519   214094  \n",
      "3        4950   187153  \n",
      "4         530  1532166  \n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Checking: Street Network (street_gdf) ---\n",
      "\n",
      "Shape: (115305, 2)\n",
      "Columns: ['geometry', 'FID']\n",
      "Total Missing Values: 0\n",
      "CRS: EPSG:27700\n",
      "Geometry Type: ['LineString']\n",
      "\n",
      "Head:\n",
      "                                    geometry  FID\n",
      "0  LINESTRING (533496 194642, 533521 194711)    0\n",
      "1  LINESTRING (532979 195192, 532937 194981)    1\n",
      "2  LINESTRING (532451 194748, 532358 194770)    2\n",
      "3  LINESTRING (532358 194770, 532225 194797)    3\n",
      "4  LINESTRING (532019 194636, 532123 194669)    4\n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Checking: Stations (station_gdf) ---\n",
      "\n",
      "Shape: (21002, 5)\n",
      "Columns: ['geometry', 'osm_id', 'code', 'fclass', 'name']\n",
      "Total Missing Values: 218\n",
      "CRS: EPSG:27700\n",
      "Geometry Type: ['Point']\n",
      "\n",
      "Head:\n",
      "                        geometry  osm_id  code           fclass  \\\n",
      "0  POINT (526506.781 196024.294)  659860  5601  railway_station   \n",
      "1  POINT (523318.835 178683.784)  702503  5601  railway_station   \n",
      "2   POINT (523190.202 180031.21)  780856  5601  railway_station   \n",
      "3  POINT (523344.763 180490.543)  780911  5601  railway_station   \n",
      "4   POINT (537270.73 188970.803)  818704  5601  railway_station   \n",
      "\n",
      "                     name  \n",
      "0              New Barnet  \n",
      "1             Hammersmith  \n",
      "2  Shepherd's Bush Market  \n",
      "3               Wood Lane  \n",
      "4     Walthamstow Central  \n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Checking: Land Use (landuse_gdf) ---\n",
      "\n",
      "Shape: (30775, 5)\n",
      "Columns: ['geometry', 'osm_id', 'code', 'fclass', 'name']\n",
      "Total Missing Values: 26239\n",
      "CRS: EPSG:27700\n",
      "Geometry Type: ['Polygon' 'MultiPolygon']\n",
      "\n",
      "Head:\n",
      "                                            geometry   osm_id  code fclass  \\\n",
      "0  POLYGON ((532065.726 197873.867, 532093.379 19...  2838058  7202   park   \n",
      "1  POLYGON ((532863.867 198097.732, 532874.832 19...  2903046  7202   park   \n",
      "2  POLYGON ((532433.383 197662.081, 532438.091 19...  2903368  7202   park   \n",
      "3  POLYGON ((532711.413 197548.732, 532736.071 19...  2903369  7202   park   \n",
      "4  POLYGON ((533583.521 196021.414, 533586.278 19...  2903398  7202   park   \n",
      "\n",
      "             name  \n",
      "0            None  \n",
      "1            None  \n",
      "2            None  \n",
      "3            None  \n",
      "4  Bush Hill Park  \n",
      "\n",
      "==================================================\n",
      "\n",
      "--- Checking: Rail Network (rail_gdf) ---\n",
      "\n",
      "Shape: (11777, 5)\n",
      "Columns: ['geometry', 'osm_id', 'code', 'fclass', 'name']\n",
      "Total Missing Values: 5421\n",
      "CRS: EPSG:27700\n",
      "Geometry Type: ['LineString']\n",
      "\n",
      "Head:\n",
      "                                            geometry  osm_id  code  fclass  \\\n",
      "0  LINESTRING (538865.67 194026.578, 538953.872 1...   30804  6101    rail   \n",
      "1  LINESTRING (523318.835 178683.784, 523314.286 ...  101298  6103  subway   \n",
      "2  LINESTRING (524598.481 181595.074, 524626.148 ...  101486  6103  subway   \n",
      "3  LINESTRING (524694.206 181886.633, 524655.584 ...  101511  6101    rail   \n",
      "4  LINESTRING (525670.998 192344.253, 525634.231 ...  282898  6103  subway   \n",
      "\n",
      "                                 name  \n",
      "0                    Lea Valley Lines  \n",
      "1           Hammersmith and City Line  \n",
      "2           Hammersmith and City Line  \n",
      "3             Great Western Main Line  \n",
      "4  Northern Line (High Barnet Branch)  \n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------\n",
    "# 3. Comprehensive Input Data Check\n",
    "# ---------------------------------\n",
    "\n",
    "# Dictionary of all loaded datasets for easy iteration\n",
    "datasets = {\n",
    "    \"Merged Tabular Data (df_tab)\": df_tab,\n",
    "    \"LSOA Polygons (lsoa_gdf)\": lsoa_gdf,\n",
    "    \"Street Network (street_gdf)\": street_gdf,\n",
    "    \"Stations (station_gdf)\": station_gdf,\n",
    "    \"Land Use (landuse_gdf)\": landuse_gdf,\n",
    "    \"Rail Network (rail_gdf)\": rail_gdf\n",
    "}\n",
    "\n",
    "# Loop through and print a summary of each dataset\n",
    "for name, data in datasets.items():\n",
    "    print(f\"--- Checking: {name} ---\\n\")\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        print(f\"Shape: {data.shape}\")\n",
    "        print(f\"Columns: {data.columns.tolist()}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_values = data.isnull().sum().sum()\n",
    "        print(f\"Total Missing Values: {missing_values}\")\n",
    "        \n",
    "        # Display info for GeoDataFrames\n",
    "        if isinstance(data, gpd.GeoDataFrame):\n",
    "            print(f\"CRS: {data.crs}\")\n",
    "            print(f\"Geometry Type: {data.geom_type.unique()}\")\n",
    "        \n",
    "        print(\"\\nHead:\")\n",
    "        print(data.head())\n",
    "        \n",
    "    else:\n",
    "        print(f\"'{name}' is not a DataFrame or GeoDataFrame.\")\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ca5b9531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      ï»¿Local authority code Local authority name  LSOA code  \\\n",
      "0                   E06000001           Hartlepool  E01011949   \n",
      "1                   E06000001           Hartlepool  E01011950   \n",
      "2                   E06000001           Hartlepool  E01011951   \n",
      "3                   E06000001           Hartlepool  E01011952   \n",
      "4                   E06000001           Hartlepool  E01011953   \n",
      "...                       ...                  ...        ...   \n",
      "34748               W06000024       Merthyr Tydfil  W01001320   \n",
      "34749               W06000024       Merthyr Tydfil  W01001321   \n",
      "34750               W06000024       Merthyr Tydfil  W01001322   \n",
      "34751               W06000024       Merthyr Tydfil  W01001324   \n",
      "34752               W06000024       Merthyr Tydfil  W01001898   \n",
      "\n",
      "                 LSOA name Year ending Dec 1995 Year ending Mar 1996  \\\n",
      "0          Hartlepool 009A               34,750               34,500   \n",
      "1          Hartlepool 008A               25,000               25,000   \n",
      "2          Hartlepool 007A               27,000               27,000   \n",
      "3          Hartlepool 002A               44,500               44,500   \n",
      "4          Hartlepool 002B               22,000               27,000   \n",
      "...                    ...                  ...                  ...   \n",
      "34748  Merthyr Tydfil 007C               29,000               35,000   \n",
      "34749  Merthyr Tydfil 007D               23,500               24,000   \n",
      "34750  Merthyr Tydfil 007E               20,000               27,248   \n",
      "34751  Merthyr Tydfil 003E               34,748               34,998   \n",
      "34752  Merthyr Tydfil 008F               43,750               54,375   \n",
      "\n",
      "      Year ending Jun 1996 Year ending Sep 1996 Year ending Dec 1996  \\\n",
      "0                   30,500               30,000               29,950   \n",
      "1                   25,300               25,625               25,000   \n",
      "2                   27,250               28,950               28,500   \n",
      "3                   30,000               26,675               26,000   \n",
      "4                   27,000               20,600               20,000   \n",
      "...                    ...                  ...                  ...   \n",
      "34748               35,000               44,250               44,250   \n",
      "34749               26,000               30,000               29,475   \n",
      "34750               28,498               25,500               29,725   \n",
      "34751               32,500               33,000               31,000   \n",
      "34752               65,000               68,725               62,500   \n",
      "\n",
      "      Year ending Mar 1997  ... Year ending Dec 2020 Year ending Mar 2021  \\\n",
      "0                   29,000  ...               88,000               81,500   \n",
      "1                   24,800  ...               29,750               33,000   \n",
      "2                   28,950  ...               50,000               51,500   \n",
      "3                   25,500  ...               85,000                    :   \n",
      "4                   19,500  ...                    :                    :   \n",
      "...                    ...  ...                  ...                  ...   \n",
      "34748               43,500  ...              139,500              144,000   \n",
      "34749               22,725  ...               95,000              100,750   \n",
      "34750               28,750  ...               91,000              100,000   \n",
      "34751               29,000  ...              142,000              150,000   \n",
      "34752               59,294  ...                    :                    :   \n",
      "\n",
      "      Year ending Jun 2021 Year ending Sep 2021 Year ending Dec 2021  \\\n",
      "0                   80,500               89,000              101,500   \n",
      "1                   47,000               49,999               50,159   \n",
      "2                   53,000               58,574               60,000   \n",
      "3                   83,500               83,000               80,000   \n",
      "4                        :               95,000               92,500   \n",
      "...                    ...                  ...                  ...   \n",
      "34748              141,500              140,000              140,000   \n",
      "34749              107,000              110,000              109,500   \n",
      "34750              105,000              105,000              107,500   \n",
      "34751              130,500              146,000              137,500   \n",
      "34752                    :              142,500              165,000   \n",
      "\n",
      "      Year ending Mar 2022 Year ending Jun 2022 Year ending Sep 2022  \\\n",
      "0                   94,500              113,000               97,500   \n",
      "1                   50,159               46,000               43,500   \n",
      "2                   62,999               61,500               60,000   \n",
      "3                   76,000               75,000               75,000   \n",
      "4                   95,000               95,000               92,500   \n",
      "...                    ...                  ...                  ...   \n",
      "34748              142,500              141,975              149,500   \n",
      "34749              108,250              110,000              109,500   \n",
      "34750              108,500              113,500              119,000   \n",
      "34751              135,000              137,500              140,000   \n",
      "34752              180,000              182,500              182,500   \n",
      "\n",
      "      Year ending Dec 2022 Year ending Mar 2023  \n",
      "0                  102,500              106,500  \n",
      "1                   42,000               43,500  \n",
      "2                   65,500               66,000  \n",
      "3                   70,000               60,000  \n",
      "4                   93,750               92,500  \n",
      "...                    ...                  ...  \n",
      "34748              155,000              149,500  \n",
      "34749              113,500              120,000  \n",
      "34750              135,000              136,000  \n",
      "34751              140,000              145,000  \n",
      "34752              185,000              211,000  \n",
      "\n",
      "[34753 rows x 114 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "bf61991f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HOUSING VALUE DATASET DIAGNOSIS ===\n",
      "Shape: (34753, 114)\n",
      "Columns: ['ï»¿Local authority code', 'Local authority name', 'LSOA code', 'LSOA name', 'Year ending Dec 1995', 'Year ending Mar 1996', 'Year ending Jun 1996', 'Year ending Sep 1996', 'Year ending Dec 1996', 'Year ending Mar 1997', 'Year ending Jun 1997', 'Year ending Sep 1997', 'Year ending Dec 1997', 'Year ending Mar 1998', 'Year ending Jun 1998', 'Year ending Sep 1998', 'Year ending Dec 1998', 'Year ending Mar 1999', 'Year ending Jun 1999', 'Year ending Sep 1999', 'Year ending Dec 1999', 'Year ending Mar 2000', 'Year ending Jun 2000', 'Year ending Sep 2000', 'Year ending Dec 2000', 'Year ending Mar 2001', 'Year ending Jun 2001', 'Year ending Sep 2001', 'Year ending Dec 2001', 'Year ending Mar 2002', 'Year ending Jun 2002', 'Year ending Sep 2002', 'Year ending Dec 2002', 'Year ending Mar 2003', 'Year ending Jun 2003', 'Year ending Sep 2003', 'Year ending Dec 2003', 'Year ending Mar 2004', 'Year ending Jun 2004', 'Year ending Sep 2004', 'Year ending Dec 2004', 'Year ending Mar 2005', 'Year ending Jun 2005', 'Year ending Sep 2005', 'Year ending Dec 2005', 'Year ending Mar 2006', 'Year ending Jun 2006', 'Year ending Sep 2006', 'Year ending Dec 2006', 'Year ending Mar 2007', 'Year ending Jun 2007', 'Year ending Sep 2007', 'Year ending Dec 2007', 'Year ending Mar 2008', 'Year ending Jun 2008', 'Year ending Sep 2008', 'Year ending Dec 2008', 'Year ending Mar 2009', 'Year ending Jun 2009', 'Year ending Sep 2009', 'Year ending Dec 2009', 'Year ending Mar 2010', 'Year ending Jun 2010', 'Year ending Sep 2010', 'Year ending Dec 2010', 'Year ending Mar 2011', 'Year ending Jun 2011', 'Year ending Sep 2011', 'Year ending Dec 2011', 'Year ending Mar 2012', 'Year ending Jun 2012', 'Year ending Sep 2012', 'Year ending Dec 2012', 'Year ending Mar 2013', 'Year ending Jun 2013', 'Year ending Sep 2013', 'Year ending Dec 2013', 'Year ending Mar 2014', 'Year ending Jun 2014', 'Year ending Sep 2014', 'Year ending Dec 2014', 'Year ending Mar 2015', 'Year ending Jun 2015', 'Year ending Sep 2015', 'Year ending Dec 2015', 'Year ending Mar 2016', 'Year ending Jun 2016', 'Year ending Sep 2016', 'Year ending Dec 2016', 'Year ending Mar 2017', 'Year ending Jun 2017', 'Year ending Sep 2017', 'Year ending Dec 2017', 'Year ending Mar 2018', 'Year ending Jun 2018', 'Year ending Sep 2018', 'Year ending Dec 2018', 'Year ending Mar 2019', 'Year ending Jun 2019', 'Year ending Sep 2019', 'Year ending Dec 2019', 'Year ending Mar 2020', 'Year ending Jun 2020', 'Year ending Sep 2020', 'Year ending Dec 2020', 'Year ending Mar 2021', 'Year ending Jun 2021', 'Year ending Sep 2021', 'Year ending Dec 2021', 'Year ending Mar 2022', 'Year ending Jun 2022', 'Year ending Sep 2022', 'Year ending Dec 2022', 'Year ending Mar 2023']\n",
      "\n",
      "First few rows:\n",
      "  ï»¿Local authority code Local authority name  LSOA code        LSOA name  \\\n",
      "0               E06000001           Hartlepool  E01011949  Hartlepool 009A   \n",
      "1               E06000001           Hartlepool  E01011950  Hartlepool 008A   \n",
      "2               E06000001           Hartlepool  E01011951  Hartlepool 007A   \n",
      "3               E06000001           Hartlepool  E01011952  Hartlepool 002A   \n",
      "4               E06000001           Hartlepool  E01011953  Hartlepool 002B   \n",
      "\n",
      "  Year ending Dec 1995 Year ending Mar 1996 Year ending Jun 1996  \\\n",
      "0               34,750               34,500               30,500   \n",
      "1               25,000               25,000               25,300   \n",
      "2               27,000               27,000               27,250   \n",
      "3               44,500               44,500               30,000   \n",
      "4               22,000               27,000               27,000   \n",
      "\n",
      "  Year ending Sep 1996 Year ending Dec 1996 Year ending Mar 1997  ...  \\\n",
      "0               30,000               29,950               29,000  ...   \n",
      "1               25,625               25,000               24,800  ...   \n",
      "2               28,950               28,500               28,950  ...   \n",
      "3               26,675               26,000               25,500  ...   \n",
      "4               20,600               20,000               19,500  ...   \n",
      "\n",
      "  Year ending Dec 2020 Year ending Mar 2021 Year ending Jun 2021  \\\n",
      "0               88,000               81,500               80,500   \n",
      "1               29,750               33,000               47,000   \n",
      "2               50,000               51,500               53,000   \n",
      "3               85,000                    :               83,500   \n",
      "4                    :                    :                    :   \n",
      "\n",
      "  Year ending Sep 2021 Year ending Dec 2021 Year ending Mar 2022  \\\n",
      "0               89,000              101,500               94,500   \n",
      "1               49,999               50,159               50,159   \n",
      "2               58,574               60,000               62,999   \n",
      "3               83,000               80,000               76,000   \n",
      "4               95,000               92,500               95,000   \n",
      "\n",
      "  Year ending Jun 2022 Year ending Sep 2022 Year ending Dec 2022  \\\n",
      "0              113,000               97,500              102,500   \n",
      "1               46,000               43,500               42,000   \n",
      "2               61,500               60,000               65,500   \n",
      "3               75,000               75,000               70,000   \n",
      "4               95,000               92,500               93,750   \n",
      "\n",
      "  Year ending Mar 2023  \n",
      "0              106,500  \n",
      "1               43,500  \n",
      "2               66,000  \n",
      "3               60,000  \n",
      "4               92,500  \n",
      "\n",
      "[5 rows x 114 columns]\n",
      "\n",
      "Data types:\n",
      "ï»¿Local authority code    object\n",
      "Local authority name       object\n",
      "LSOA code                  object\n",
      "LSOA name                  object\n",
      "Year ending Dec 1995       object\n",
      "                            ...  \n",
      "Year ending Mar 2022       object\n",
      "Year ending Jun 2022       object\n",
      "Year ending Sep 2022       object\n",
      "Year ending Dec 2022       object\n",
      "Year ending Mar 2023       object\n",
      "Length: 114, dtype: object\n",
      "\n",
      "Column names with potential encoding issues:\n",
      "Column 0: 'ï»¿Local authority code' (repr: 'ï»¿Local authority code')\n",
      "Column 1: 'Local authority name' (repr: 'Local authority name')\n",
      "Column 2: 'LSOA code' (repr: 'LSOA code')\n",
      "Column 3: 'LSOA name' (repr: 'LSOA name')\n",
      "Column 4: 'Year ending Dec 1995' (repr: 'Year ending Dec 1995')\n",
      "Column 5: 'Year ending Mar 1996' (repr: 'Year ending Mar 1996')\n",
      "Column 6: 'Year ending Jun 1996' (repr: 'Year ending Jun 1996')\n",
      "Column 7: 'Year ending Sep 1996' (repr: 'Year ending Sep 1996')\n",
      "Column 8: 'Year ending Dec 1996' (repr: 'Year ending Dec 1996')\n",
      "Column 9: 'Year ending Mar 1997' (repr: 'Year ending Mar 1997')\n",
      "Column 10: 'Year ending Jun 1997' (repr: 'Year ending Jun 1997')\n",
      "Column 11: 'Year ending Sep 1997' (repr: 'Year ending Sep 1997')\n",
      "Column 12: 'Year ending Dec 1997' (repr: 'Year ending Dec 1997')\n",
      "Column 13: 'Year ending Mar 1998' (repr: 'Year ending Mar 1998')\n",
      "Column 14: 'Year ending Jun 1998' (repr: 'Year ending Jun 1998')\n",
      "Column 15: 'Year ending Sep 1998' (repr: 'Year ending Sep 1998')\n",
      "Column 16: 'Year ending Dec 1998' (repr: 'Year ending Dec 1998')\n",
      "Column 17: 'Year ending Mar 1999' (repr: 'Year ending Mar 1999')\n",
      "Column 18: 'Year ending Jun 1999' (repr: 'Year ending Jun 1999')\n",
      "Column 19: 'Year ending Sep 1999' (repr: 'Year ending Sep 1999')\n",
      "Column 20: 'Year ending Dec 1999' (repr: 'Year ending Dec 1999')\n",
      "Column 21: 'Year ending Mar 2000' (repr: 'Year ending Mar 2000')\n",
      "Column 22: 'Year ending Jun 2000' (repr: 'Year ending Jun 2000')\n",
      "Column 23: 'Year ending Sep 2000' (repr: 'Year ending Sep 2000')\n",
      "Column 24: 'Year ending Dec 2000' (repr: 'Year ending Dec 2000')\n",
      "Column 25: 'Year ending Mar 2001' (repr: 'Year ending Mar 2001')\n",
      "Column 26: 'Year ending Jun 2001' (repr: 'Year ending Jun 2001')\n",
      "Column 27: 'Year ending Sep 2001' (repr: 'Year ending Sep 2001')\n",
      "Column 28: 'Year ending Dec 2001' (repr: 'Year ending Dec 2001')\n",
      "Column 29: 'Year ending Mar 2002' (repr: 'Year ending Mar 2002')\n",
      "Column 30: 'Year ending Jun 2002' (repr: 'Year ending Jun 2002')\n",
      "Column 31: 'Year ending Sep 2002' (repr: 'Year ending Sep 2002')\n",
      "Column 32: 'Year ending Dec 2002' (repr: 'Year ending Dec 2002')\n",
      "Column 33: 'Year ending Mar 2003' (repr: 'Year ending Mar 2003')\n",
      "Column 34: 'Year ending Jun 2003' (repr: 'Year ending Jun 2003')\n",
      "Column 35: 'Year ending Sep 2003' (repr: 'Year ending Sep 2003')\n",
      "Column 36: 'Year ending Dec 2003' (repr: 'Year ending Dec 2003')\n",
      "Column 37: 'Year ending Mar 2004' (repr: 'Year ending Mar 2004')\n",
      "Column 38: 'Year ending Jun 2004' (repr: 'Year ending Jun 2004')\n",
      "Column 39: 'Year ending Sep 2004' (repr: 'Year ending Sep 2004')\n",
      "Column 40: 'Year ending Dec 2004' (repr: 'Year ending Dec 2004')\n",
      "Column 41: 'Year ending Mar 2005' (repr: 'Year ending Mar 2005')\n",
      "Column 42: 'Year ending Jun 2005' (repr: 'Year ending Jun 2005')\n",
      "Column 43: 'Year ending Sep 2005' (repr: 'Year ending Sep 2005')\n",
      "Column 44: 'Year ending Dec 2005' (repr: 'Year ending Dec 2005')\n",
      "Column 45: 'Year ending Mar 2006' (repr: 'Year ending Mar 2006')\n",
      "Column 46: 'Year ending Jun 2006' (repr: 'Year ending Jun 2006')\n",
      "Column 47: 'Year ending Sep 2006' (repr: 'Year ending Sep 2006')\n",
      "Column 48: 'Year ending Dec 2006' (repr: 'Year ending Dec 2006')\n",
      "Column 49: 'Year ending Mar 2007' (repr: 'Year ending Mar 2007')\n",
      "Column 50: 'Year ending Jun 2007' (repr: 'Year ending Jun 2007')\n",
      "Column 51: 'Year ending Sep 2007' (repr: 'Year ending Sep 2007')\n",
      "Column 52: 'Year ending Dec 2007' (repr: 'Year ending Dec 2007')\n",
      "Column 53: 'Year ending Mar 2008' (repr: 'Year ending Mar 2008')\n",
      "Column 54: 'Year ending Jun 2008' (repr: 'Year ending Jun 2008')\n",
      "Column 55: 'Year ending Sep 2008' (repr: 'Year ending Sep 2008')\n",
      "Column 56: 'Year ending Dec 2008' (repr: 'Year ending Dec 2008')\n",
      "Column 57: 'Year ending Mar 2009' (repr: 'Year ending Mar 2009')\n",
      "Column 58: 'Year ending Jun 2009' (repr: 'Year ending Jun 2009')\n",
      "Column 59: 'Year ending Sep 2009' (repr: 'Year ending Sep 2009')\n",
      "Column 60: 'Year ending Dec 2009' (repr: 'Year ending Dec 2009')\n",
      "Column 61: 'Year ending Mar 2010' (repr: 'Year ending Mar 2010')\n",
      "Column 62: 'Year ending Jun 2010' (repr: 'Year ending Jun 2010')\n",
      "Column 63: 'Year ending Sep 2010' (repr: 'Year ending Sep 2010')\n",
      "Column 64: 'Year ending Dec 2010' (repr: 'Year ending Dec 2010')\n",
      "Column 65: 'Year ending Mar 2011' (repr: 'Year ending Mar 2011')\n",
      "Column 66: 'Year ending Jun 2011' (repr: 'Year ending Jun 2011')\n",
      "Column 67: 'Year ending Sep 2011' (repr: 'Year ending Sep 2011')\n",
      "Column 68: 'Year ending Dec 2011' (repr: 'Year ending Dec 2011')\n",
      "Column 69: 'Year ending Mar 2012' (repr: 'Year ending Mar 2012')\n",
      "Column 70: 'Year ending Jun 2012' (repr: 'Year ending Jun 2012')\n",
      "Column 71: 'Year ending Sep 2012' (repr: 'Year ending Sep 2012')\n",
      "Column 72: 'Year ending Dec 2012' (repr: 'Year ending Dec 2012')\n",
      "Column 73: 'Year ending Mar 2013' (repr: 'Year ending Mar 2013')\n",
      "Column 74: 'Year ending Jun 2013' (repr: 'Year ending Jun 2013')\n",
      "Column 75: 'Year ending Sep 2013' (repr: 'Year ending Sep 2013')\n",
      "Column 76: 'Year ending Dec 2013' (repr: 'Year ending Dec 2013')\n",
      "Column 77: 'Year ending Mar 2014' (repr: 'Year ending Mar 2014')\n",
      "Column 78: 'Year ending Jun 2014' (repr: 'Year ending Jun 2014')\n",
      "Column 79: 'Year ending Sep 2014' (repr: 'Year ending Sep 2014')\n",
      "Column 80: 'Year ending Dec 2014' (repr: 'Year ending Dec 2014')\n",
      "Column 81: 'Year ending Mar 2015' (repr: 'Year ending Mar 2015')\n",
      "Column 82: 'Year ending Jun 2015' (repr: 'Year ending Jun 2015')\n",
      "Column 83: 'Year ending Sep 2015' (repr: 'Year ending Sep 2015')\n",
      "Column 84: 'Year ending Dec 2015' (repr: 'Year ending Dec 2015')\n",
      "Column 85: 'Year ending Mar 2016' (repr: 'Year ending Mar 2016')\n",
      "Column 86: 'Year ending Jun 2016' (repr: 'Year ending Jun 2016')\n",
      "Column 87: 'Year ending Sep 2016' (repr: 'Year ending Sep 2016')\n",
      "Column 88: 'Year ending Dec 2016' (repr: 'Year ending Dec 2016')\n",
      "Column 89: 'Year ending Mar 2017' (repr: 'Year ending Mar 2017')\n",
      "Column 90: 'Year ending Jun 2017' (repr: 'Year ending Jun 2017')\n",
      "Column 91: 'Year ending Sep 2017' (repr: 'Year ending Sep 2017')\n",
      "Column 92: 'Year ending Dec 2017' (repr: 'Year ending Dec 2017')\n",
      "Column 93: 'Year ending Mar 2018' (repr: 'Year ending Mar 2018')\n",
      "Column 94: 'Year ending Jun 2018' (repr: 'Year ending Jun 2018')\n",
      "Column 95: 'Year ending Sep 2018' (repr: 'Year ending Sep 2018')\n",
      "Column 96: 'Year ending Dec 2018' (repr: 'Year ending Dec 2018')\n",
      "Column 97: 'Year ending Mar 2019' (repr: 'Year ending Mar 2019')\n",
      "Column 98: 'Year ending Jun 2019' (repr: 'Year ending Jun 2019')\n",
      "Column 99: 'Year ending Sep 2019' (repr: 'Year ending Sep 2019')\n",
      "Column 100: 'Year ending Dec 2019' (repr: 'Year ending Dec 2019')\n",
      "Column 101: 'Year ending Mar 2020' (repr: 'Year ending Mar 2020')\n",
      "Column 102: 'Year ending Jun 2020' (repr: 'Year ending Jun 2020')\n",
      "Column 103: 'Year ending Sep 2020' (repr: 'Year ending Sep 2020')\n",
      "Column 104: 'Year ending Dec 2020' (repr: 'Year ending Dec 2020')\n",
      "Column 105: 'Year ending Mar 2021' (repr: 'Year ending Mar 2021')\n",
      "Column 106: 'Year ending Jun 2021' (repr: 'Year ending Jun 2021')\n",
      "Column 107: 'Year ending Sep 2021' (repr: 'Year ending Sep 2021')\n",
      "Column 108: 'Year ending Dec 2021' (repr: 'Year ending Dec 2021')\n",
      "Column 109: 'Year ending Mar 2022' (repr: 'Year ending Mar 2022')\n",
      "Column 110: 'Year ending Jun 2022' (repr: 'Year ending Jun 2022')\n",
      "Column 111: 'Year ending Sep 2022' (repr: 'Year ending Sep 2022')\n",
      "Column 112: 'Year ending Dec 2022' (repr: 'Year ending Dec 2022')\n",
      "Column 113: 'Year ending Mar 2023' (repr: 'Year ending Mar 2023')\n"
     ]
    }
   ],
   "source": [
    "# Let's examine the housing value dataset more carefully\n",
    "print(\"=== HOUSING VALUE DATASET DIAGNOSIS ===\")\n",
    "print(f\"Shape: {hv.shape}\")\n",
    "print(f\"Columns: {list(hv.columns)}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(hv.head())\n",
    "print(\"\\nData types:\")\n",
    "print(hv.dtypes)\n",
    "print(\"\\nColumn names with potential encoding issues:\")\n",
    "for i, col in enumerate(hv.columns):\n",
    "    print(f\"Column {i}: '{col}' (repr: {repr(col)})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "a9e73ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== HOUSING VALUE FOCUSED ANALYSIS ===\n",
      "Dataset shape: (34753, 114)\n",
      "Number of columns: 114\n",
      "\n",
      "First 10 columns:\n",
      "  0: 'ï»¿Local authority code'\n",
      "  1: 'Local authority name'\n",
      "  2: 'LSOA code'\n",
      "  3: 'LSOA name'\n",
      "  4: 'Year ending Dec 1995'\n",
      "  5: 'Year ending Mar 1996'\n",
      "  6: 'Year ending Jun 1996'\n",
      "  7: 'Year ending Sep 1996'\n",
      "  8: 'Year ending Dec 1996'\n",
      "  9: 'Year ending Mar 1997'\n",
      "\n",
      "Selected columns for processing:\n",
      "  Code column: 'LSOA code'\n",
      "  Price column: 'Year ending Mar 2023'\n",
      "  Sales column: None\n",
      "\n",
      "Processed hv_tab shape: (34753, 2)\n",
      "hv_tab columns: ['LSOA_CODE', 'AvgPrice']\n",
      "\n",
      "hv_tab sample:\n",
      "   LSOA_CODE  AvgPrice\n",
      "0  E01011949  106500.0\n",
      "1  E01011950   43500.0\n",
      "2  E01011951   66000.0\n",
      "3  E01011952   60000.0\n",
      "4  E01011953   92500.0\n",
      "\n",
      "hv_tab data types:\n",
      "LSOA_CODE     object\n",
      "AvgPrice     float64\n",
      "dtype: object\n",
      "\n",
      "Missing values in hv_tab:\n",
      "LSOA_CODE      0\n",
      "AvgPrice     886\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# More focused housing value analysis\n",
    "print(\"=== HOUSING VALUE FOCUSED ANALYSIS ===\")\n",
    "print(f\"Dataset shape: {hv.shape}\")\n",
    "print(f\"Number of columns: {len(hv.columns)}\")\n",
    "\n",
    "# Show first 10 column names to check for issues\n",
    "print(\"\\nFirst 10 columns:\")\n",
    "for i, col in enumerate(hv.columns[:10]):\n",
    "    print(f\"  {i}: {repr(col)}\")\n",
    "\n",
    "# Check if there are issues with column detection\n",
    "print(f\"\\nSelected columns for processing:\")\n",
    "print(f\"  Code column: {repr(hv_code)}\")\n",
    "print(f\"  Price column: {repr(hv_price)}\")\n",
    "print(f\"  Sales column: {hv_sales}\")\n",
    "\n",
    "# Check the processed housing value table\n",
    "print(f\"\\nProcessed hv_tab shape: {hv_tab.shape}\")\n",
    "print(f\"hv_tab columns: {list(hv_tab.columns)}\")\n",
    "print(\"\\nhv_tab sample:\")\n",
    "print(hv_tab.head())\n",
    "\n",
    "# Check for missing values and data types\n",
    "print(f\"\\nhv_tab data types:\")\n",
    "print(hv_tab.dtypes)\n",
    "print(f\"\\nMissing values in hv_tab:\")\n",
    "print(hv_tab.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "65d3de36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FIXING HOUSING VALUE DATASET ===\n",
      "Using price column: Year ending Mar 2023\n",
      "Corrected hv_tab shape: (34753, 2)\n",
      "Data types after correction:\n",
      "LSOA_CODE     object\n",
      "AvgPrice     float64\n",
      "dtype: object\n",
      "\n",
      "Sample of corrected data:\n",
      "   LSOA_CODE  AvgPrice\n",
      "0  E01011949  106500.0\n",
      "1  E01011950   43500.0\n",
      "2  E01011951   66000.0\n",
      "3  E01011952   60000.0\n",
      "4  E01011953   92500.0\n",
      "5  E01011954  104000.0\n",
      "6  E01011955  104750.0\n",
      "7  E01011957   78000.0\n",
      "8  E01011959  374950.0\n",
      "9  E01011960  194500.0\n",
      "\n",
      "Missing values after correction:\n",
      "LSOA_CODE      0\n",
      "AvgPrice     886\n",
      "dtype: int64\n",
      "\n",
      "Price statistics:\n",
      "count    3.386700e+04\n",
      "mean     3.408105e+05\n",
      "std      2.394217e+05\n",
      "min      3.250000e+04\n",
      "25%      1.950000e+05\n",
      "50%      2.870000e+05\n",
      "75%      4.185000e+05\n",
      "max      6.600000e+06\n",
      "Name: AvgPrice, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Fix the housing value dataset processing\n",
    "print(\"=== FIXING HOUSING VALUE DATASET ===\")\n",
    "\n",
    "# Re-process housing value data with corrections\n",
    "# Use 'LSOA code' column instead of first column\n",
    "hv_code_correct = 'LSOA code'  # Use the actual LSOA code column\n",
    "\n",
    "# Find the March 2023 column (already found correctly)\n",
    "print(f\"Using price column: {hv_price}\")\n",
    "\n",
    "# Create corrected housing value table\n",
    "hv_tab_corrected = hv[[hv_code_correct, hv_price]].copy()\n",
    "hv_tab_corrected.columns = ['LSOA_CODE', 'AvgPrice']\n",
    "\n",
    "# Convert price from string to numeric (remove commas and convert to float)\n",
    "hv_tab_corrected['AvgPrice'] = hv_tab_corrected['AvgPrice'].astype(str).str.replace(',', '').replace('', None)\n",
    "\n",
    "# Convert to numeric, handling any non-numeric values\n",
    "hv_tab_corrected['AvgPrice'] = pd.to_numeric(hv_tab_corrected['AvgPrice'], errors='coerce')\n",
    "\n",
    "print(f\"Corrected hv_tab shape: {hv_tab_corrected.shape}\")\n",
    "print(f\"Data types after correction:\")\n",
    "print(hv_tab_corrected.dtypes)\n",
    "print(f\"\\nSample of corrected data:\")\n",
    "print(hv_tab_corrected.head(10))\n",
    "print(f\"\\nMissing values after correction:\")\n",
    "print(hv_tab_corrected.isnull().sum())\n",
    "print(f\"\\nPrice statistics:\")\n",
    "print(hv_tab_corrected['AvgPrice'].describe())\n",
    "\n",
    "# Update the main hv_tab variable\n",
    "hv_tab = hv_tab_corrected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2cc5354d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RE-MERGING TABULAR DATA ===\n",
      "Corrected merged data shape: (35090, 10)\n",
      "Columns: ['LSOA_CODE', 'AvgPrice', 'MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount']\n",
      "\n",
      "Sample of corrected merged data:\n",
      "   LSOA_CODE  AvgPrice MEAN_PTAL_2023      MAX_AI     MIN_AI  Population  \\\n",
      "0  E01000001  837500.0             6b   97.664050  43.344686      1615.0   \n",
      "1  E01000002  850000.0             6b  102.127724  44.802674      1493.0   \n",
      "2  E01000003  540000.0             6b   66.989479  36.995870      1573.0   \n",
      "3  E01000005       NaN             6b  104.154096  45.504887      1090.0   \n",
      "4  E01000006  241000.0              5   33.400903   2.836977      1612.0   \n",
      "\n",
      "    Area_km2  MeanSentiment  SentimentSD  ReviewCount  \n",
      "0  E01000001          0.427        0.312       1505.0  \n",
      "1  E01000002          0.524        0.188       5819.0  \n",
      "2  E01000003          0.317          NaN          3.0  \n",
      "3  E01000005          0.675        0.100       1067.0  \n",
      "4  E01000006            NaN          NaN          NaN  \n",
      "\n",
      "Data types:\n",
      "LSOA_CODE          object\n",
      "AvgPrice          float64\n",
      "MEAN_PTAL_2023     object\n",
      "MAX_AI            float64\n",
      "MIN_AI            float64\n",
      "Population        float64\n",
      "Area_km2           object\n",
      "MeanSentiment     float64\n",
      "SentimentSD       float64\n",
      "ReviewCount       float64\n",
      "dtype: object\n",
      "\n",
      "Missing values summary:\n",
      "LSOA_CODE             2\n",
      "AvgPrice           1223\n",
      "MEAN_PTAL_2023    30096\n",
      "MAX_AI            30096\n",
      "MIN_AI            30096\n",
      "Population        30255\n",
      "Area_km2          30255\n",
      "MeanSentiment     32345\n",
      "SentimentSD       33476\n",
      "ReviewCount       32345\n",
      "dtype: int64\n",
      "\n",
      "=== HOUSING VALUE ISSUE RESOLVED ===\n",
      "✓ Used correct LSOA code column\n",
      "✓ Converted price strings to numeric values\n",
      "✓ Handled missing values appropriately\n",
      "✓ Updated merged dataset\n"
     ]
    }
   ],
   "source": [
    "# Re-merge all tabular data with corrected housing values\n",
    "print(\"=== RE-MERGING TABULAR DATA ===\")\n",
    "\n",
    "# Merge all tabular data with corrected housing values\n",
    "df_tab_corrected = (\n",
    "    hv_tab  # Now using the corrected housing value data\n",
    "    .merge(ptal_tab, on='LSOA_CODE', how='outer')\n",
    "    .merge(ls_tab,   on='LSOA_CODE', how='outer')\n",
    "    .merge(sent_tab, on='LSOA_CODE', how='outer')\n",
    ")\n",
    "\n",
    "print(f\"Corrected merged data shape: {df_tab_corrected.shape}\")\n",
    "print(f\"Columns: {list(df_tab_corrected.columns)}\")\n",
    "print(f\"\\nSample of corrected merged data:\")\n",
    "print(df_tab_corrected.head())\n",
    "print(f\"\\nData types:\")\n",
    "print(df_tab_corrected.dtypes)\n",
    "print(f\"\\nMissing values summary:\")\n",
    "print(df_tab_corrected.isnull().sum())\n",
    "\n",
    "# Update the main df_tab variable\n",
    "df_tab = df_tab_corrected\n",
    "\n",
    "print(\"\\n=== HOUSING VALUE ISSUE RESOLVED ===\")\n",
    "print(\"✓ Used correct LSOA code column\")\n",
    "print(\"✓ Converted price strings to numeric values\") \n",
    "print(\"✓ Handled missing values appropriately\")\n",
    "print(\"✓ Updated merged dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "326e5f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FINAL VERIFICATION ===\n",
      "Housing value dataset is now properly processed:\n",
      "✓ Shape: (35090, 10)\n",
      "✓ AvgPrice column type: float64\n",
      "✓ Price range: £32,500 - £6,600,000\n",
      "✓ Average price: £340,811\n",
      "✓ Non-null prices: 33,867 out of 35,090\n",
      "\n",
      "Sample of properly formatted data:\n",
      "    LSOA_CODE  AvgPrice\n",
      "0   E01000001  837500.0\n",
      "1   E01000002  850000.0\n",
      "2   E01000003  540000.0\n",
      "4   E01000006  241000.0\n",
      "5   E01000007  310000.0\n",
      "7   E01000009  235000.0\n",
      "8   E01000010  194000.0\n",
      "10  E01000012  242500.0\n",
      "11  E01000013  393000.0\n",
      "12  E01000014  365000.0\n"
     ]
    }
   ],
   "source": [
    "# Final verification of housing value dataset\n",
    "print(\"=== FINAL VERIFICATION ===\")\n",
    "print(\"Housing value dataset is now properly processed:\")\n",
    "print(f\"✓ Shape: {df_tab.shape}\")\n",
    "print(f\"✓ AvgPrice column type: {df_tab['AvgPrice'].dtype}\")\n",
    "print(f\"✓ Price range: £{df_tab['AvgPrice'].min():,.0f} - £{df_tab['AvgPrice'].max():,.0f}\")\n",
    "print(f\"✓ Average price: £{df_tab['AvgPrice'].mean():,.0f}\")\n",
    "print(f\"✓ Non-null prices: {df_tab['AvgPrice'].notna().sum():,} out of {len(df_tab):,}\")\n",
    "\n",
    "print(\"\\nSample of properly formatted data:\")\n",
    "print(df_tab[['LSOA_CODE', 'AvgPrice']].dropna().head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "25a25667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== FILTERING TO LONDON LSOA AREAS ONLY ===\n",
      "LSOA codes in shapefile (first 10):\n",
      "['E01000037', 'E01033729', 'E01000038', 'E01033730', 'E01000039', 'E01033731', 'E01000040', 'E01033732', 'E01000041', 'E01033733']\n",
      "Total LSOAs in shapefile: 4719\n",
      "Unique LSOA codes in London shapefile: 4719\n",
      "\n",
      "Before filtering - tabular data shape: (35090, 10)\n",
      "After filtering - London tabular data shape: (4719, 10)\n",
      "\n",
      "Filtered dataset sizes:\n",
      "Housing values: 4719 LSOAs\n",
      "PTAL data: 4547 LSOAs\n",
      "Demographics: 4719 LSOAs\n",
      "Sentiment data: 2678 LSOAs\n",
      "\n",
      "✓ All datasets now filtered to London LSOAs only\n",
      "✓ Final London dataset shape: (4719, 10)\n",
      "✓ Sample London LSOA codes: ['E01000001', 'E01000002', 'E01000003', 'E01000005', 'E01000006']\n"
     ]
    }
   ],
   "source": [
    "# =====================================\n",
    "# 4. Filter to London LSOA Areas Only\n",
    "# =====================================\n",
    "\n",
    "print(\"=== FILTERING TO LONDON LSOA AREAS ONLY ===\")\n",
    "\n",
    "# London LSOA codes start with 'E01' followed by 6 digits and are in the range for London\n",
    "# London LSOA codes are typically in ranges like E01000001-E01004806 for London boroughs\n",
    "# We can also filter based on the shapefile which should contain only London LSOAs\n",
    "\n",
    "# First, let's check what LSOA codes we have in the spatial data\n",
    "print(\"LSOA codes in shapefile (first 10):\")\n",
    "print(lsoa_gdf[shp_code].head(10).tolist())\n",
    "print(f\"Total LSOAs in shapefile: {len(lsoa_gdf)}\")\n",
    "\n",
    "# Get the set of London LSOA codes from the shapefile\n",
    "london_lsoa_codes = set(lsoa_gdf[shp_code].unique())\n",
    "print(f\"Unique LSOA codes in London shapefile: {len(london_lsoa_codes)}\")\n",
    "\n",
    "# Filter the tabular data to only include London LSOAs\n",
    "print(f\"\\nBefore filtering - tabular data shape: {df_tab.shape}\")\n",
    "df_tab_london = df_tab[df_tab['LSOA_CODE'].isin(london_lsoa_codes)].copy()\n",
    "print(f\"After filtering - London tabular data shape: {df_tab_london.shape}\")\n",
    "\n",
    "# Also filter each individual dataset for consistency\n",
    "hv_tab_london = hv_tab[hv_tab['LSOA_CODE'].isin(london_lsoa_codes)].copy()\n",
    "ptal_tab_london = ptal_tab[ptal_tab['LSOA_CODE'].isin(london_lsoa_codes)].copy()\n",
    "ls_tab_london = ls_tab[ls_tab['LSOA_CODE'].isin(london_lsoa_codes)].copy()\n",
    "sent_tab_london = sent_tab[sent_tab['LSOA_CODE'].isin(london_lsoa_codes)].copy()\n",
    "\n",
    "print(f\"\\nFiltered dataset sizes:\")\n",
    "print(f\"Housing values: {len(hv_tab_london)} LSOAs\")\n",
    "print(f\"PTAL data: {len(ptal_tab_london)} LSOAs\")\n",
    "print(f\"Demographics: {len(ls_tab_london)} LSOAs\")\n",
    "print(f\"Sentiment data: {len(sent_tab_london)} LSOAs\")\n",
    "\n",
    "# Update the main variables to use London-only data\n",
    "df_tab = df_tab_london\n",
    "hv_tab = hv_tab_london\n",
    "ptal_tab = ptal_tab_london\n",
    "ls_tab = ls_tab_london\n",
    "sent_tab = sent_tab_london\n",
    "\n",
    "print(f\"\\n✓ All datasets now filtered to London LSOAs only\")\n",
    "print(f\"✓ Final London dataset shape: {df_tab.shape}\")\n",
    "print(f\"✓ Sample London LSOA codes: {df_tab['LSOA_CODE'].head().tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "12d74e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== LONDON DATA COVERAGE VERIFICATION ===\n",
      "Data Coverage Summary:\n",
      "  Total London LSOAs: 4719\n",
      "  LSOAs with Housing Values: 4,335 (91.9%)\n",
      "  LSOAs with PTAL Data: 4,547 (96.4%)\n",
      "  LSOAs with Population Data: 4,719 (100.0%)\n",
      "  LSOAs with Sentiment Data: 2,678 (56.7%)\n",
      "\n",
      "Missing values per column:\n",
      "  AvgPrice: 384 (8.1%)\n",
      "  MEAN_PTAL_2023: 172 (3.6%)\n",
      "  MAX_AI: 172 (3.6%)\n",
      "  MIN_AI: 172 (3.6%)\n",
      "  MeanSentiment: 2,041 (43.3%)\n",
      "  SentimentSD: 3,147 (66.7%)\n",
      "  ReviewCount: 2,041 (43.3%)\n",
      "\n",
      "London dataset summary:\n",
      "  Shape: (4719, 10)\n",
      "  Columns: ['LSOA_CODE', 'AvgPrice', 'MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount']\n",
      "\n",
      "Sample of London data:\n",
      "   LSOA_CODE  AvgPrice MEAN_PTAL_2023      MAX_AI     MIN_AI  Population  \\\n",
      "0  E01000001  837500.0             6b   97.664050  43.344686      1615.0   \n",
      "1  E01000002  850000.0             6b  102.127724  44.802674      1493.0   \n",
      "2  E01000003  540000.0             6b   66.989479  36.995870      1573.0   \n",
      "3  E01000005       NaN             6b  104.154096  45.504887      1090.0   \n",
      "4  E01000006  241000.0              5   33.400903   2.836977      1612.0   \n",
      "\n",
      "    Area_km2  MeanSentiment  SentimentSD  ReviewCount  \n",
      "0  E01000001          0.427        0.312       1505.0  \n",
      "1  E01000002          0.524        0.188       5819.0  \n",
      "2  E01000003          0.317          NaN          3.0  \n",
      "3  E01000005          0.675        0.100       1067.0  \n",
      "4  E01000006            NaN          NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "# Verify London data coverage and quality\n",
    "print(\"=== LONDON DATA COVERAGE VERIFICATION ===\")\n",
    "\n",
    "# Check data coverage for each variable\n",
    "coverage_stats = {\n",
    "    'Total London LSOAs': len(london_lsoa_codes),\n",
    "    'LSOAs with Housing Values': df_tab['AvgPrice'].notna().sum(),\n",
    "    'LSOAs with PTAL Data': df_tab['MEAN_PTAL_2023'].notna().sum(),\n",
    "    'LSOAs with Population Data': df_tab['Population'].notna().sum() if 'Population' in df_tab.columns else 0,\n",
    "    'LSOAs with Sentiment Data': df_tab['MeanSentiment'].notna().sum(),\n",
    "}\n",
    "\n",
    "print(\"Data Coverage Summary:\")\n",
    "for var, count in coverage_stats.items():\n",
    "    if var == 'Total London LSOAs':\n",
    "        print(f\"  {var}: {count}\")\n",
    "    else:\n",
    "        pct = (count / len(london_lsoa_codes)) * 100\n",
    "        print(f\"  {var}: {count:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nMissing values per column:\")\n",
    "missing_summary = df_tab.isnull().sum()\n",
    "for col, missing in missing_summary.items():\n",
    "    if missing > 0:\n",
    "        pct = (missing / len(df_tab)) * 100\n",
    "        print(f\"  {col}: {missing:,} ({pct:.1f}%)\")\n",
    "\n",
    "print(f\"\\nLondon dataset summary:\")\n",
    "print(f\"  Shape: {df_tab.shape}\")\n",
    "print(f\"  Columns: {list(df_tab.columns)}\")\n",
    "print(\"\\nSample of London data:\")\n",
    "print(df_tab.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "5655752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SPATIAL FEATURE ENGINEERING FOR GCN ===\n",
      "Starting with 4719 London LSOAs\n",
      "Available columns: ['LSOA_CODE', 'AvgPrice', 'MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount']\n",
      "\n",
      "Current data quality:\n",
      "  AvgPrice: 4335/4719 (91.9%)\n",
      "  MEAN_PTAL_2023: 4547/4719 (96.4%)\n",
      "  MAX_AI: 4547/4719 (96.4%)\n",
      "  MIN_AI: 4547/4719 (96.4%)\n",
      "  Population: 4719/4719 (100.0%)\n",
      "  Area_km2: 4719/4719 (100.0%)\n",
      "  MeanSentiment: 2678/4719 (56.7%)\n",
      "  SentimentSD: 1572/4719 (33.3%)\n",
      "  ReviewCount: 2678/4719 (56.7%)\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# 5. SPATIAL FEATURE ENGINEERING FOR GCN\n",
    "# ======================================\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import cKDTree\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=== SPATIAL FEATURE ENGINEERING FOR GCN ===\")\n",
    "print(f\"Starting with {len(df_tab)} London LSOAs\")\n",
    "print(f\"Available columns: {list(df_tab.columns)}\")\n",
    "\n",
    "# Check current data quality\n",
    "print(f\"\\nCurrent data quality:\")\n",
    "for col in df_tab.columns:\n",
    "    if col != 'LSOA_CODE':\n",
    "        non_null = df_tab[col].notna().sum()\n",
    "        pct = (non_null / len(df_tab)) * 100\n",
    "        print(f\"  {col}: {non_null}/{len(df_tab)} ({pct:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c2452435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CALCULATING SPATIAL FEATURES ===\n",
      "Spatial dataset shape: (4719, 17)\n",
      "✓ LSOA centroids calculated\n",
      "\n",
      "1. Calculating transport accessibility features...\n",
      "✓ LSOA centroids calculated\n",
      "\n",
      "1. Calculating transport accessibility features...\n",
      "✓ Station distances and counts calculated (buffer: 500m)\n",
      "\n",
      "2. Calculating rail network features...\n",
      "✓ Rail network distances calculated\n",
      "\n",
      "3. Calculating street network features...\n",
      "✓ Station distances and counts calculated (buffer: 500m)\n",
      "\n",
      "2. Calculating rail network features...\n",
      "✓ Rail network distances calculated\n",
      "\n",
      "3. Calculating street network features...\n",
      "✓ Street network features calculated\n",
      "\n",
      "4. Calculating land use features...\n",
      "Using land use column: fclass\n",
      "✓ Street network features calculated\n",
      "\n",
      "4. Calculating land use features...\n",
      "Using land use column: fclass\n",
      "✓ Land use features calculated\n",
      "\n",
      "✓ Spatial features calculated: (4719, 10)\n",
      "Spatial feature columns: ['LSOA_CODE', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "Sample spatial features:\n",
      "   LSOA_CODE  NearestStation_m  StationsWithin500m  NearestRail_m  \\\n",
      "0  E01000037        271.372693                  11    1161.211245   \n",
      "1  E01033729        173.157513                   8    1353.038682   \n",
      "2  E01000038        169.883547                  12     997.889365   \n",
      "3  E01033730        171.200256                  22      20.696237   \n",
      "4  E01000039        390.407690                   4     762.852096   \n",
      "\n",
      "   StreetLength_m  StreetDensity_m_per_m2  StreetSegments  LandUse_Diversity  \\\n",
      "0     2459.085633                0.010534              20                  4   \n",
      "1     3256.402467                0.004713              34                  3   \n",
      "2     2486.051451                0.011615              19                  3   \n",
      "3     1748.572721                0.009346              39                  3   \n",
      "4     2435.857930                0.001590              21                  6   \n",
      "\n",
      "   LandUse_Types  LandUse_Area  \n",
      "0              4  2.079269e+05  \n",
      "1              3  6.629931e+05  \n",
      "2              3  2.071765e+05  \n",
      "3              3  1.198047e+05  \n",
      "4              6  1.495074e+06  \n",
      "✓ Land use features calculated\n",
      "\n",
      "✓ Spatial features calculated: (4719, 10)\n",
      "Spatial feature columns: ['LSOA_CODE', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "Sample spatial features:\n",
      "   LSOA_CODE  NearestStation_m  StationsWithin500m  NearestRail_m  \\\n",
      "0  E01000037        271.372693                  11    1161.211245   \n",
      "1  E01033729        173.157513                   8    1353.038682   \n",
      "2  E01000038        169.883547                  12     997.889365   \n",
      "3  E01033730        171.200256                  22      20.696237   \n",
      "4  E01000039        390.407690                   4     762.852096   \n",
      "\n",
      "   StreetLength_m  StreetDensity_m_per_m2  StreetSegments  LandUse_Diversity  \\\n",
      "0     2459.085633                0.010534              20                  4   \n",
      "1     3256.402467                0.004713              34                  3   \n",
      "2     2486.051451                0.011615              19                  3   \n",
      "3     1748.572721                0.009346              39                  3   \n",
      "4     2435.857930                0.001590              21                  6   \n",
      "\n",
      "   LandUse_Types  LandUse_Area  \n",
      "0              4  2.079269e+05  \n",
      "1              3  6.629931e+05  \n",
      "2              3  2.071765e+05  \n",
      "3              3  1.198047e+05  \n",
      "4              6  1.495074e+06  \n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# CALCULATE SPATIAL FEATURES FROM GEOGRAPHIC LAYERS\n",
    "# ======================================\n",
    "\n",
    "print(\"=== CALCULATING SPATIAL FEATURES ===\")\n",
    "\n",
    "# Merge LSOA spatial data with tabular data\n",
    "df_spatial = lsoa_gdf.merge(df_tab, left_on=shp_code, right_on='LSOA_CODE', how='left')\n",
    "print(f\"Spatial dataset shape: {df_spatial.shape}\")\n",
    "\n",
    "# Calculate centroids for distance calculations\n",
    "centroids = df_spatial.geometry.centroid\n",
    "print(\"✓ LSOA centroids calculated\")\n",
    "\n",
    "# 1. TRANSPORT ACCESSIBILITY FEATURES\n",
    "print(\"\\n1. Calculating transport accessibility features...\")\n",
    "\n",
    "# Calculate nearest station distances\n",
    "station_coords = np.array([[pt.x, pt.y] for pt in station_gdf.geometry])\n",
    "station_tree = cKDTree(station_coords)\n",
    "\n",
    "centroid_coords = np.array([[pt.x, pt.y] for pt in centroids])\n",
    "nearest_station_dist, _ = station_tree.query(centroid_coords)\n",
    "\n",
    "# Calculate stations within buffer zones\n",
    "radius = 500  # 500m buffer\n",
    "stations_within = []\n",
    "for centroid in centroids:\n",
    "    buffer = centroid.buffer(radius)\n",
    "    stations_in = station_gdf[station_gdf.geometry.within(buffer)]\n",
    "    stations_within.append(len(stations_in))\n",
    "\n",
    "print(f\"✓ Station distances and counts calculated (buffer: {radius}m)\")\n",
    "\n",
    "# 2. RAIL NETWORK FEATURES\n",
    "print(\"\\n2. Calculating rail network features...\")\n",
    "\n",
    "# Calculate nearest rail distances\n",
    "rail_coords = np.array([[geom.coords[0][0], geom.coords[0][1]] for geom in rail_gdf.geometry])\n",
    "rail_tree = cKDTree(rail_coords)\n",
    "nearest_rail_dist, _ = rail_tree.query(centroid_coords)\n",
    "\n",
    "print(\"✓ Rail network distances calculated\")\n",
    "\n",
    "# 3. STREET NETWORK FEATURES\n",
    "print(\"\\n3. Calculating street network features...\")\n",
    "\n",
    "street_stats = []\n",
    "for idx, lsoa in df_spatial.iterrows():\n",
    "    # Clip streets to LSOA boundary\n",
    "    streets_clipped = street_gdf.clip(lsoa.geometry)\n",
    "    \n",
    "    if len(streets_clipped) > 0:\n",
    "        # Calculate total street length\n",
    "        total_length = streets_clipped.geometry.length.sum()\n",
    "        # Calculate street density (length per area)\n",
    "        area = lsoa.geometry.area  # in m²\n",
    "        street_density = total_length / area if area > 0 else 0\n",
    "        # Count number of street segments\n",
    "        num_segments = len(streets_clipped)\n",
    "    else:\n",
    "        total_length = 0\n",
    "        street_density = 0\n",
    "        num_segments = 0\n",
    "    \n",
    "    street_stats.append({\n",
    "        'StreetLength_m': total_length,\n",
    "        'StreetDensity_m_per_m2': street_density,\n",
    "        'StreetSegments': num_segments\n",
    "    })\n",
    "\n",
    "street_df = pd.DataFrame(street_stats)\n",
    "print(\"✓ Street network features calculated\")\n",
    "\n",
    "# 4. LAND USE DIVERSITY FEATURES\n",
    "print(\"\\n4. Calculating land use features...\")\n",
    "\n",
    "# Get unique land use types\n",
    "landuse_cols = []\n",
    "for lu_col in landuse_gdf.columns:\n",
    "    if landuse_gdf[lu_col].dtype == 'object' and len(landuse_gdf[lu_col].unique()) < 50:\n",
    "        landuse_cols.append(lu_col)\n",
    "\n",
    "if landuse_cols:\n",
    "    landuse_col = landuse_cols[0]  # Use first categorical column\n",
    "    print(f\"Using land use column: {landuse_col}\")\n",
    "    \n",
    "    landuse_stats = []\n",
    "    for idx, lsoa in df_spatial.iterrows():\n",
    "        # Find landuse polygons intersecting with LSOA\n",
    "        land_int = landuse_gdf[landuse_gdf.geometry.intersects(lsoa.geometry)]\n",
    "        \n",
    "        if len(land_int) > 0:\n",
    "            # Calculate land use diversity (number of different types)\n",
    "            lu_types = land_int[landuse_col].nunique()\n",
    "            \n",
    "            # Calculate proportions of each land use type\n",
    "            lu_props = land_int[landuse_col].value_counts(normalize=True)\n",
    "            \n",
    "            # Calculate area-weighted land use diversity\n",
    "            areas = []\n",
    "            for _, lu in land_int.iterrows():\n",
    "                intersection = lu.geometry.intersection(lsoa.geometry)\n",
    "                areas.append(intersection.area)\n",
    "            \n",
    "            total_area = sum(areas)\n",
    "            diversity = len(set(land_int[landuse_col])) if total_area > 0 else 0\n",
    "            \n",
    "        else:\n",
    "            lu_types = 0\n",
    "            diversity = 0\n",
    "            total_area = 0\n",
    "        \n",
    "        landuse_stats.append({\n",
    "            'LandUse_Diversity': diversity,\n",
    "            'LandUse_Types': lu_types,\n",
    "            'LandUse_Area': total_area\n",
    "        })\n",
    "    \n",
    "    landuse_df = pd.DataFrame(landuse_stats)\n",
    "else:\n",
    "    # Create dummy landuse features if no suitable column found\n",
    "    landuse_df = pd.DataFrame({\n",
    "        'LandUse_Diversity': [0] * len(df_spatial),\n",
    "        'LandUse_Types': [0] * len(df_spatial),\n",
    "        'LandUse_Area': [0] * len(df_spatial)\n",
    "    })\n",
    "\n",
    "print(\"✓ Land use features calculated\")\n",
    "\n",
    "# Combine all spatial features\n",
    "spatial_features = pd.DataFrame({\n",
    "    'LSOA_CODE': df_spatial['LSOA_CODE'],\n",
    "    'NearestStation_m': nearest_station_dist,\n",
    "    'StationsWithin500m': stations_within,\n",
    "    'NearestRail_m': nearest_rail_dist,\n",
    "})\n",
    "\n",
    "# Add street features\n",
    "spatial_features = pd.concat([spatial_features, street_df], axis=1)\n",
    "\n",
    "# Add landuse features  \n",
    "spatial_features = pd.concat([spatial_features, landuse_df], axis=1)\n",
    "\n",
    "print(f\"\\n✓ Spatial features calculated: {spatial_features.shape}\")\n",
    "print(f\"Spatial feature columns: {list(spatial_features.columns)}\")\n",
    "print(f\"Sample spatial features:\")\n",
    "print(spatial_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "4fd17a2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING COMPREHENSIVE FEATURE MATRIX ===\n",
      "Combined dataset shape: (4719, 19)\n",
      "Combined columns: ['LSOA_CODE', 'AvgPrice', 'MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "\n",
      "Feature categories for GCN:\n",
      "  Economic: ['AvgPrice']\n",
      "  Transport_Accessibility: ['MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m']\n",
      "  Demographics: ['Population']\n",
      "  Geographic: ['Area_km2']\n",
      "  Social: ['MeanSentiment', 'SentimentSD', 'ReviewCount']\n",
      "  Urban_Form: ['StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "\n",
      "=== CHECKING DATA TYPES ===\n",
      "AvgPrice: float64 | Sample: [837500.0, 850000.0, 540000.0]\n",
      "MEAN_PTAL_2023: object | Sample: ['6b', '6b', '6b']\n",
      "MAX_AI: float64 | Sample: [97.66404972828455, 102.1277242621298, 66.9894792109165]\n",
      "MIN_AI: float64 | Sample: [43.34468592310935, 44.80267393616006, 36.995870454288195]\n",
      "Population: float64 | Sample: [1615.0, 1493.0, 1573.0]\n",
      "Area_km2: object | Sample: ['E01000001', 'E01000002', 'E01000003']\n",
      "MeanSentiment: float64 | Sample: [0.427, 0.524, 0.317]\n",
      "SentimentSD: float64 | Sample: [0.312, 0.188, 0.1]\n",
      "ReviewCount: float64 | Sample: [1505.0, 5819.0, 3.0]\n",
      "NearestStation_m: float64 | Sample: [37.20475761882215, 195.1768083463368, 120.9773134998089]\n",
      "StationsWithin500m: int64 | Sample: [29, 30, 28]\n",
      "NearestRail_m: float64 | Sample: [224.63815485302962, 144.0611574190192, 189.82912798251422]\n",
      "StreetLength_m: float64 | Sample: [2099.0980490673314, 3258.5163952816715, 578.8785655714419]\n",
      "StreetDensity_m_per_m2: float64 | Sample: [0.016163651424687855, 0.014265501745479397, 0.00980252712715752]\n",
      "StreetSegments: int64 | Sample: [43, 55, 11]\n",
      "LandUse_Diversity: int64 | Sample: [4, 5, 3]\n",
      "LandUse_Types: int64 | Sample: [4, 5, 3]\n",
      "LandUse_Area: float64 | Sample: [38011.199254873325, 88486.28424288688, 28201.764815431376]\n",
      "\n",
      "=== CONVERTING TO NUMERIC ===\n",
      "Converting MEAN_PTAL_2023 to numeric...\n",
      "Converting Area_km2 to numeric...\n",
      "\n",
      "=== FEATURE QUALITY SUMMARY ===\n",
      "                        completeness      variance  unique_values  \\\n",
      "NearestStation_m            1.000000  1.174383e+04         4719.0   \n",
      "StationsWithin500m          1.000000  5.118877e+01           49.0   \n",
      "LandUse_Types               1.000000  3.068381e+00           13.0   \n",
      "LandUse_Diversity           1.000000  3.068381e+00           13.0   \n",
      "StreetSegments              1.000000  3.021806e+02          125.0   \n",
      "StreetDensity_m_per_m2      1.000000  2.141090e-05         4719.0   \n",
      "StreetLength_m              1.000000  1.753139e+06         4719.0   \n",
      "NearestRail_m               1.000000  2.492079e+05         4719.0   \n",
      "LandUse_Area                1.000000  1.309096e+11         4716.0   \n",
      "Population                  1.000000  5.383409e+04          809.0   \n",
      "MIN_AI                      0.963552  8.445323e+01         3615.0   \n",
      "MAX_AI                      0.963552  1.892631e+02         4547.0   \n",
      "AvgPrice                    0.918627  1.587917e+11         1470.0   \n",
      "MEAN_PTAL_2023              0.684467  9.844232e-01            4.0   \n",
      "ReviewCount                 0.567493  1.605336e+08          922.0   \n",
      "MeanSentiment               0.567493  2.404396e-02          564.0   \n",
      "SentimentSD                 0.333121  1.490563e-02          430.0   \n",
      "Area_km2                    0.000000  0.000000e+00            0.0   \n",
      "\n",
      "                        non_null_count  \n",
      "NearestStation_m                4719.0  \n",
      "StationsWithin500m              4719.0  \n",
      "LandUse_Types                   4719.0  \n",
      "LandUse_Diversity               4719.0  \n",
      "StreetSegments                  4719.0  \n",
      "StreetDensity_m_per_m2          4719.0  \n",
      "StreetLength_m                  4719.0  \n",
      "NearestRail_m                   4719.0  \n",
      "LandUse_Area                    4719.0  \n",
      "Population                      4719.0  \n",
      "MIN_AI                          4547.0  \n",
      "MAX_AI                          4547.0  \n",
      "AvgPrice                        4335.0  \n",
      "MEAN_PTAL_2023                  3230.0  \n",
      "ReviewCount                     2678.0  \n",
      "MeanSentiment                   2678.0  \n",
      "SentimentSD                     1572.0  \n",
      "Area_km2                           0.0  \n",
      "\n",
      "High-quality features (>= 80% complete, variance > 0): 13\n",
      "['AvgPrice', 'MAX_AI', 'MIN_AI', 'Population', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# CREATE COMPREHENSIVE FEATURE MATRIX FOR GCN\n",
    "# ======================================\n",
    "\n",
    "print(\"=== CREATING COMPREHENSIVE FEATURE MATRIX ===\")\n",
    "\n",
    "# Combine tabular and spatial features\n",
    "df_combined = df_tab.merge(spatial_features, on='LSOA_CODE', how='left')\n",
    "print(f\"Combined dataset shape: {df_combined.shape}\")\n",
    "print(f\"Combined columns: {list(df_combined.columns)}\")\n",
    "\n",
    "# Feature categorization for GCN optimization\n",
    "feature_categories = {\n",
    "    'Economic': ['AvgPrice'],\n",
    "    'Transport_Accessibility': ['MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m'],\n",
    "    'Demographics': ['Population'],\n",
    "    'Geographic': ['Area_km2'],\n",
    "    'Social': ['MeanSentiment', 'SentimentSD', 'ReviewCount'],\n",
    "    'Urban_Form': ['StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
    "}\n",
    "\n",
    "print(f\"\\nFeature categories for GCN:\")\n",
    "for category, features in feature_categories.items():\n",
    "    available_features = [f for f in features if f in df_combined.columns]\n",
    "    print(f\"  {category}: {available_features}\")\n",
    "\n",
    "# Check data types and fix issues\n",
    "print(f\"\\n=== CHECKING DATA TYPES ===\")\n",
    "for col in df_combined.columns:\n",
    "    if col != 'LSOA_CODE':\n",
    "        dtype = df_combined[col].dtype\n",
    "        sample_values = df_combined[col].dropna().head(3).tolist()\n",
    "        print(f\"{col}: {dtype} | Sample: {sample_values}\")\n",
    "\n",
    "# Convert problematic columns to numeric\n",
    "print(f\"\\n=== CONVERTING TO NUMERIC ===\")\n",
    "numeric_columns = [col for col in df_combined.columns if col != 'LSOA_CODE']\n",
    "\n",
    "for col in numeric_columns:\n",
    "    if df_combined[col].dtype == 'object':\n",
    "        print(f\"Converting {col} to numeric...\")\n",
    "        df_combined[col] = pd.to_numeric(df_combined[col], errors='coerce')\n",
    "\n",
    "# Calculate feature completeness and quality metrics\n",
    "feature_quality = {}\n",
    "for col in df_combined.columns:\n",
    "    if col != 'LSOA_CODE':\n",
    "        non_null_count = df_combined[col].notna().sum()\n",
    "        total_count = len(df_combined)\n",
    "        completeness = non_null_count / total_count\n",
    "        \n",
    "        if non_null_count > 0 and df_combined[col].dtype in ['int64', 'float64']:\n",
    "            variance = df_combined[col].var()\n",
    "            unique_values = df_combined[col].nunique()\n",
    "        else:\n",
    "            variance = 0\n",
    "            unique_values = df_combined[col].nunique() if non_null_count > 0 else 0\n",
    "            \n",
    "        feature_quality[col] = {\n",
    "            'completeness': completeness,\n",
    "            'variance': variance,\n",
    "            'unique_values': unique_values,\n",
    "            'non_null_count': non_null_count\n",
    "        }\n",
    "\n",
    "# Display feature quality summary\n",
    "print(f\"\\n=== FEATURE QUALITY SUMMARY ===\")\n",
    "quality_df = pd.DataFrame(feature_quality).T\n",
    "quality_df = quality_df.sort_values('completeness', ascending=False)\n",
    "print(quality_df)\n",
    "\n",
    "# Identify high-quality features (>= 80% completeness, variance > 0)\n",
    "high_quality_features = []\n",
    "for feature, metrics in feature_quality.items():\n",
    "    if metrics['completeness'] >= 0.80 and metrics['variance'] > 0:\n",
    "        high_quality_features.append(feature)\n",
    "\n",
    "print(f\"\\nHigh-quality features (>= 80% complete, variance > 0): {len(high_quality_features)}\")\n",
    "print(high_quality_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "7cf679ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING OPTIMAL GCN FEATURE MATRIX ===\n",
      "\n",
      "1. COMPLETE FEATURES STRATEGY\n",
      "Features with 100% completeness: ['Population', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "\n",
      "2. HIGH COVERAGE FEATURES STRATEGY\n",
      "Features with >= 90% completeness: ['AvgPrice', 'MAX_AI', 'MIN_AI', 'Population', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "\n",
      "3. OPTIMIZED FEATURES STRATEGY\n",
      "Optimized features (balanced approach): ['AvgPrice', 'MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'Population', 'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "\n",
      "Complete features dataset: (4719, 11)\n",
      "High coverage features dataset: (4719, 14)\n",
      "Optimized features dataset: (4719, 18)\n",
      "\n",
      "=== FEATURE SCALING AND NORMALIZATION ===\n",
      "complete (scaled): (4719, 11)\n",
      "  Features: ['Population', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "  Missing values: 0\n",
      "  Sample stats: mean=0.000, std=1.000\n",
      "high_coverage (scaled): (4719, 14)\n",
      "  Features: ['AvgPrice', 'MAX_AI', 'MIN_AI', 'Population', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "  Missing values: 0\n",
      "  Sample stats: mean=0.000, std=1.000\n",
      "optimized (scaled): (4719, 18)\n",
      "  Features: ['AvgPrice', 'MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'Population', 'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "  Missing values: 0\n",
      "  Sample stats: mean=0.000, std=1.000\n",
      "\n",
      "=== GCN DATASET SUMMARY ===\n",
      "complete: Shape (4719, 11), Missing values: 0\n",
      "high_coverage: Shape (4719, 14), Missing values: 0\n",
      "optimized: Shape (4719, 18), Missing values: 0\n",
      "complete_scaled: Shape (4719, 11), Missing values: 0\n",
      "high_coverage_scaled: Shape (4719, 14), Missing values: 0\n",
      "optimized_scaled: Shape (4719, 18), Missing values: 0\n",
      "\n",
      "✓ Optimal GCN feature matrices created successfully!\n",
      "✓ Available versions: ['complete', 'high_coverage', 'optimized', 'complete_scaled', 'high_coverage_scaled', 'optimized_scaled']\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# CREATE OPTIMAL GCN FEATURE MATRIX\n",
    "# ======================================\n",
    "\n",
    "print(\"=== CREATING OPTIMAL GCN FEATURE MATRIX ===\")\n",
    "\n",
    "# Strategy 1: Complete Features Only (for immediate use)\n",
    "print(\"\\n1. COMPLETE FEATURES STRATEGY\")\n",
    "complete_features = [col for col in high_quality_features if feature_quality[col]['completeness'] == 1.0]\n",
    "print(f\"Features with 100% completeness: {complete_features}\")\n",
    "\n",
    "# Strategy 2: High Coverage Features (>= 90%)\n",
    "print(\"\\n2. HIGH COVERAGE FEATURES STRATEGY\")\n",
    "high_coverage_features = [col for col in high_quality_features if feature_quality[col]['completeness'] >= 0.90]\n",
    "print(f\"Features with >= 90% completeness: {high_coverage_features}\")\n",
    "\n",
    "# Strategy 3: Optimized Features (balance coverage and information content)\n",
    "print(\"\\n3. OPTIMIZED FEATURES STRATEGY\")\n",
    "optimized_features = []\n",
    "for feature, metrics in feature_quality.items():\n",
    "    # Score based on completeness and variance (information content)\n",
    "    completeness_score = metrics['completeness']\n",
    "    variance_score = 1.0 if metrics['variance'] > 0 else 0.0\n",
    "    unique_score = min(metrics['unique_values'] / 100, 1.0)  # Normalize to 0-1\n",
    "    \n",
    "    combined_score = (completeness_score * 0.5) + (variance_score * 0.3) + (unique_score * 0.2)\n",
    "    \n",
    "    if combined_score >= 0.6:  # Threshold for inclusion\n",
    "        optimized_features.append(feature)\n",
    "\n",
    "print(f\"Optimized features (balanced approach): {optimized_features}\")\n",
    "\n",
    "# Create different versions of the GCN feature matrix\n",
    "gcn_datasets = {}\n",
    "\n",
    "# Version 1: Complete features only\n",
    "if complete_features:\n",
    "    gcn_complete = df_combined[['LSOA_CODE'] + complete_features].copy()\n",
    "    gcn_datasets['complete'] = gcn_complete\n",
    "    print(f\"\\nComplete features dataset: {gcn_complete.shape}\")\n",
    "\n",
    "# Version 2: High coverage features with imputation\n",
    "if high_coverage_features:\n",
    "    gcn_high_coverage = df_combined[['LSOA_CODE'] + high_coverage_features].copy()\n",
    "    \n",
    "    # Simple imputation for missing values\n",
    "    for col in high_coverage_features:\n",
    "        if gcn_high_coverage[col].isnull().any():\n",
    "            median_val = gcn_high_coverage[col].median()\n",
    "            gcn_high_coverage[col].fillna(median_val, inplace=True)\n",
    "    \n",
    "    gcn_datasets['high_coverage'] = gcn_high_coverage\n",
    "    print(f\"High coverage features dataset: {gcn_high_coverage.shape}\")\n",
    "\n",
    "# Version 3: Optimized features with imputation\n",
    "if optimized_features:\n",
    "    gcn_optimized = df_combined[['LSOA_CODE'] + optimized_features].copy()\n",
    "    \n",
    "    # Smart imputation based on feature type\n",
    "    for col in optimized_features:\n",
    "        if gcn_optimized[col].isnull().any():\n",
    "            # Use median for continuous variables, mode for discrete\n",
    "            unique_vals = gcn_optimized[col].nunique()\n",
    "            if unique_vals <= 10:  # Likely discrete\n",
    "                fill_value = gcn_optimized[col].mode().iloc[0] if len(gcn_optimized[col].mode()) > 0 else 0\n",
    "            else:  # Continuous\n",
    "                fill_value = gcn_optimized[col].median()\n",
    "            \n",
    "            gcn_optimized[col].fillna(fill_value, inplace=True)\n",
    "    \n",
    "    gcn_datasets['optimized'] = gcn_optimized\n",
    "    print(f\"Optimized features dataset: {gcn_optimized.shape}\")\n",
    "\n",
    "# Feature scaling and final preparation\n",
    "print(f\"\\n=== FEATURE SCALING AND NORMALIZATION ===\")\n",
    "\n",
    "# Create a copy of the datasets to avoid modifying during iteration\n",
    "datasets_to_scale = gcn_datasets.copy()\n",
    "\n",
    "for version_name, dataset in datasets_to_scale.items():\n",
    "    # Separate features from ID\n",
    "    feature_cols = [col for col in dataset.columns if col != 'LSOA_CODE']\n",
    "    \n",
    "    # Scale features\n",
    "    scaler = StandardScaler()\n",
    "    scaled_features = scaler.fit_transform(dataset[feature_cols])\n",
    "    \n",
    "    # Create scaled dataset\n",
    "    scaled_dataset = pd.DataFrame(scaled_features, columns=feature_cols)\n",
    "    scaled_dataset['LSOA_CODE'] = dataset['LSOA_CODE'].values\n",
    "    \n",
    "    # Reorder columns\n",
    "    scaled_dataset = scaled_dataset[['LSOA_CODE'] + feature_cols]\n",
    "    \n",
    "    gcn_datasets[f'{version_name}_scaled'] = scaled_dataset\n",
    "    \n",
    "    print(f\"{version_name} (scaled): {scaled_dataset.shape}\")\n",
    "    print(f\"  Features: {feature_cols}\")\n",
    "    print(f\"  Missing values: {scaled_dataset.isnull().sum().sum()}\")\n",
    "    print(f\"  Sample stats: mean={scaled_dataset[feature_cols].mean().mean():.3f}, std={scaled_dataset[feature_cols].std().mean():.3f}\")\n",
    "\n",
    "# Summary of all GCN datasets\n",
    "print(f\"\\n=== GCN DATASET SUMMARY ===\")\n",
    "for name, dataset in gcn_datasets.items():\n",
    "    missing_values = dataset.isnull().sum().sum()\n",
    "    print(f\"{name}: Shape {dataset.shape}, Missing values: {missing_values}\")\n",
    "\n",
    "print(f\"\\n✓ Optimal GCN feature matrices created successfully!\")\n",
    "print(f\"✓ Available versions: {list(gcn_datasets.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "a0d0d911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EXPORTING OPTIMAL GCN FEATURE MATRIX ===\n",
      "\n",
      "🎯 RECOMMENDED GCN FEATURE MATRIX: optimized_scaled\n",
      "   Shape: (4719, 18)\n",
      "   Features: ['AvgPrice', 'MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'Population', 'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "   ✓ Exported to: /Users/goffy/Desktop/CASA0004/data-preparation/social/gcn_feature_matrix_optimal.csv\n",
      "   ✓ Spatial version exported to: /Users/goffy/Desktop/CASA0004/data-preparation/social/gcn_feature_matrix_with_geometry.csv\n",
      "\n",
      "=== FEATURE DOCUMENTATION ===\n",
      "Final GCN Feature Matrix Documentation:\n",
      "  Dataset_Name: optimized_scaled\n",
      "  Total_Features: 17\n",
      "  Total_LSOAs: 4719\n",
      "  Coverage: 100% (after imputation and scaling)\n",
      "  Preprocessing: Standardized (mean=0, std=1)\n",
      "  Missing_Values: 0\n",
      "\n",
      "Features by Category:\n",
      "  Economic: ['AvgPrice']\n",
      "  Transport_Accessibility: ['MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m']\n",
      "  Demographics: ['Population']\n",
      "  Social: ['MeanSentiment', 'SentimentSD', 'ReviewCount']\n",
      "  Urban_Form: ['StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "\n",
      "=== SAMPLE OF FINAL GCN FEATURE MATRIX ===\n",
      "   LSOA_CODE  AvgPrice  MEAN_PTAL_2023    MAX_AI    MIN_AI  Population  \\\n",
      "0  E01000001  0.562237       -0.652524  5.809405  3.991035    0.435383   \n",
      "1  E01000002  0.594885       -0.652524  6.139505  4.152375   -0.090485   \n",
      "2  E01000003 -0.214787       -0.652524  3.540943  3.288477    0.254346   \n",
      "3  E01000005 -0.240906       -0.652524  6.289361  4.230082   -1.827576   \n",
      "4  E01000006 -0.995729        2.624447  1.056983 -0.491533    0.422452   \n",
      "\n",
      "   MeanSentiment  SentimentSD  ReviewCount  NearestStation_m  \\\n",
      "0      -1.423654     2.395906     0.054214         -1.240113   \n",
      "1      -0.597232     0.681987     0.504721          0.217765   \n",
      "2      -2.360832    -0.161150    -0.102639         -0.467001   \n",
      "3       0.689259    -0.534342     0.008474         -1.107029   \n",
      "4       0.114172    -0.161150    -0.094911          1.988550   \n",
      "\n",
      "   StationsWithin500m  NearestRail_m  StreetLength_m  StreetDensity_m_per_m2  \\\n",
      "0            2.044513      -0.798986       -0.333851                0.966407   \n",
      "1            2.184298      -0.960413        0.541895                0.556147   \n",
      "2            1.904729      -0.868722       -1.482122               -0.408466   \n",
      "3            2.883220      -1.195270        0.686240                1.405753   \n",
      "4           -0.611390      -0.941793       -0.157568                0.913186   \n",
      "\n",
      "   StreetSegments  LandUse_Diversity  LandUse_Types  LandUse_Area  \n",
      "0        0.438961           0.300171       0.300171     -0.554583  \n",
      "1        1.129350           0.871112       0.871112     -0.415063  \n",
      "2       -1.402077          -0.270771      -0.270771     -0.581698  \n",
      "3        1.992336           0.300171       0.300171     -0.304768  \n",
      "4       -0.539091          -1.412653      -1.412653     -0.331160  \n",
      "\n",
      "=== STATISTICAL SUMMARY ===\n",
      "           AvgPrice  MEAN_PTAL_2023        MAX_AI        MIN_AI    Population  \\\n",
      "count  4.719000e+03    4.719000e+03  4.719000e+03  4.719000e+03  4.719000e+03   \n",
      "mean   1.144337e-16    1.626163e-16 -4.818260e-17 -7.227390e-17  5.149515e-16   \n",
      "std    1.000106e+00    1.000106e+00  1.000106e+00  1.000106e+00  1.000106e+00   \n",
      "min   -1.161581e+00   -6.525239e-01 -1.237974e+00 -8.054719e-01 -6.525909e+00   \n",
      "25%   -4.890309e-01   -6.525239e-01 -6.293150e-01 -5.910747e-01 -2.499702e-01   \n",
      "50%   -2.409056e-01   -6.525239e-01 -2.754967e-01 -3.143071e-01  6.037845e-02   \n",
      "75%    1.371589e-01    4.397997e-01  3.029577e-01  2.557226e-01  3.577959e-01   \n",
      "max    1.561299e+01    2.624447e+00  1.008857e+01  8.864789e+00  1.937958e+01   \n",
      "\n",
      "       MeanSentiment   SentimentSD   ReviewCount  NearestStation_m  \\\n",
      "count   4.719000e+03  4.719000e+03  4.719000e+03      4.719000e+03   \n",
      "mean   -8.842259e-16  3.199626e-17  3.011412e-18      2.107989e-16   \n",
      "std     1.000106e+00  1.000106e+00  1.000106e+00      1.000106e+00   \n",
      "min    -5.061611e+00 -1.916535e+00 -1.028478e-01     -1.551074e+00   \n",
      "25%    -1.788546e-02 -1.611503e-01 -9.689534e-02     -7.001013e-01   \n",
      "50%     1.141716e-01 -1.611503e-01 -9.491118e-02     -1.655972e-01   \n",
      "75%     2.377088e-01 -1.611503e-01 -9.156945e-02      4.555854e-01   \n",
      "max     3.304839e+00  6.321332e+00  4.418620e+01      8.275955e+00   \n",
      "\n",
      "       StationsWithin500m  NearestRail_m  StreetLength_m  \\\n",
      "count        4.719000e+03   4.719000e+03    4.719000e+03   \n",
      "mean        -6.022825e-17  -4.818260e-17    1.806847e-16   \n",
      "std          1.000106e+00   1.000106e+00    1.000106e+00   \n",
      "min         -2.009234e+00  -1.243591e+00   -1.919367e+00   \n",
      "25%         -7.511745e-01  -6.965832e-01   -5.772423e-01   \n",
      "50%         -5.225253e-02  -2.548129e-01   -1.415846e-01   \n",
      "75%          6.466694e-01   4.091435e-01    3.921599e-01   \n",
      "max          6.098261e+00   8.730737e+00    1.962265e+01   \n",
      "\n",
      "       StreetDensity_m_per_m2  StreetSegments  LandUse_Diversity  \\\n",
      "count            4.719000e+03    4.719000e+03       4.719000e+03   \n",
      "mean             6.022825e-17    7.528531e-18       1.445478e-16   \n",
      "std              1.000106e+00    1.000106e+00       1.000106e+00   \n",
      "min             -2.527152e+00   -2.034934e+00      -1.983594e+00   \n",
      "25%             -6.859315e-01   -5.966231e-01      -8.417118e-01   \n",
      "50%             -6.486071e-02   -1.363637e-01      -2.707706e-01   \n",
      "75%              6.331294e-01    3.814282e-01       3.001706e-01   \n",
      "max              4.731996e+00    2.615596e+01       4.867700e+00   \n",
      "\n",
      "       LandUse_Types  LandUse_Area  \n",
      "count   4.719000e+03  4.719000e+03  \n",
      "mean    1.445478e-16  4.215977e-17  \n",
      "std     1.000106e+00  1.000106e+00  \n",
      "min    -1.983594e+00 -6.596514e-01  \n",
      "25%    -8.417118e-01 -3.708117e-01  \n",
      "50%    -2.707706e-01 -2.017019e-01  \n",
      "75%     3.001706e-01  6.627842e-02  \n",
      "max     4.867700e+00  2.226282e+01  \n",
      "\n",
      "🚀 GCN FEATURE MATRIX READY FOR USE!\n",
      "✓ Optimal feature selection completed\n",
      "✓ Data preprocessing finished\n",
      "✓ Missing values handled\n",
      "✓ Features standardized\n",
      "✓ Files exported successfully\n",
      "\n",
      "📊 Access the final matrix using: gcn_feature_matrix\n",
      "   ✓ Spatial version exported to: /Users/goffy/Desktop/CASA0004/data-preparation/social/gcn_feature_matrix_with_geometry.csv\n",
      "\n",
      "=== FEATURE DOCUMENTATION ===\n",
      "Final GCN Feature Matrix Documentation:\n",
      "  Dataset_Name: optimized_scaled\n",
      "  Total_Features: 17\n",
      "  Total_LSOAs: 4719\n",
      "  Coverage: 100% (after imputation and scaling)\n",
      "  Preprocessing: Standardized (mean=0, std=1)\n",
      "  Missing_Values: 0\n",
      "\n",
      "Features by Category:\n",
      "  Economic: ['AvgPrice']\n",
      "  Transport_Accessibility: ['MEAN_PTAL_2023', 'MAX_AI', 'MIN_AI', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m']\n",
      "  Demographics: ['Population']\n",
      "  Social: ['MeanSentiment', 'SentimentSD', 'ReviewCount']\n",
      "  Urban_Form: ['StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Types', 'LandUse_Area']\n",
      "\n",
      "=== SAMPLE OF FINAL GCN FEATURE MATRIX ===\n",
      "   LSOA_CODE  AvgPrice  MEAN_PTAL_2023    MAX_AI    MIN_AI  Population  \\\n",
      "0  E01000001  0.562237       -0.652524  5.809405  3.991035    0.435383   \n",
      "1  E01000002  0.594885       -0.652524  6.139505  4.152375   -0.090485   \n",
      "2  E01000003 -0.214787       -0.652524  3.540943  3.288477    0.254346   \n",
      "3  E01000005 -0.240906       -0.652524  6.289361  4.230082   -1.827576   \n",
      "4  E01000006 -0.995729        2.624447  1.056983 -0.491533    0.422452   \n",
      "\n",
      "   MeanSentiment  SentimentSD  ReviewCount  NearestStation_m  \\\n",
      "0      -1.423654     2.395906     0.054214         -1.240113   \n",
      "1      -0.597232     0.681987     0.504721          0.217765   \n",
      "2      -2.360832    -0.161150    -0.102639         -0.467001   \n",
      "3       0.689259    -0.534342     0.008474         -1.107029   \n",
      "4       0.114172    -0.161150    -0.094911          1.988550   \n",
      "\n",
      "   StationsWithin500m  NearestRail_m  StreetLength_m  StreetDensity_m_per_m2  \\\n",
      "0            2.044513      -0.798986       -0.333851                0.966407   \n",
      "1            2.184298      -0.960413        0.541895                0.556147   \n",
      "2            1.904729      -0.868722       -1.482122               -0.408466   \n",
      "3            2.883220      -1.195270        0.686240                1.405753   \n",
      "4           -0.611390      -0.941793       -0.157568                0.913186   \n",
      "\n",
      "   StreetSegments  LandUse_Diversity  LandUse_Types  LandUse_Area  \n",
      "0        0.438961           0.300171       0.300171     -0.554583  \n",
      "1        1.129350           0.871112       0.871112     -0.415063  \n",
      "2       -1.402077          -0.270771      -0.270771     -0.581698  \n",
      "3        1.992336           0.300171       0.300171     -0.304768  \n",
      "4       -0.539091          -1.412653      -1.412653     -0.331160  \n",
      "\n",
      "=== STATISTICAL SUMMARY ===\n",
      "           AvgPrice  MEAN_PTAL_2023        MAX_AI        MIN_AI    Population  \\\n",
      "count  4.719000e+03    4.719000e+03  4.719000e+03  4.719000e+03  4.719000e+03   \n",
      "mean   1.144337e-16    1.626163e-16 -4.818260e-17 -7.227390e-17  5.149515e-16   \n",
      "std    1.000106e+00    1.000106e+00  1.000106e+00  1.000106e+00  1.000106e+00   \n",
      "min   -1.161581e+00   -6.525239e-01 -1.237974e+00 -8.054719e-01 -6.525909e+00   \n",
      "25%   -4.890309e-01   -6.525239e-01 -6.293150e-01 -5.910747e-01 -2.499702e-01   \n",
      "50%   -2.409056e-01   -6.525239e-01 -2.754967e-01 -3.143071e-01  6.037845e-02   \n",
      "75%    1.371589e-01    4.397997e-01  3.029577e-01  2.557226e-01  3.577959e-01   \n",
      "max    1.561299e+01    2.624447e+00  1.008857e+01  8.864789e+00  1.937958e+01   \n",
      "\n",
      "       MeanSentiment   SentimentSD   ReviewCount  NearestStation_m  \\\n",
      "count   4.719000e+03  4.719000e+03  4.719000e+03      4.719000e+03   \n",
      "mean   -8.842259e-16  3.199626e-17  3.011412e-18      2.107989e-16   \n",
      "std     1.000106e+00  1.000106e+00  1.000106e+00      1.000106e+00   \n",
      "min    -5.061611e+00 -1.916535e+00 -1.028478e-01     -1.551074e+00   \n",
      "25%    -1.788546e-02 -1.611503e-01 -9.689534e-02     -7.001013e-01   \n",
      "50%     1.141716e-01 -1.611503e-01 -9.491118e-02     -1.655972e-01   \n",
      "75%     2.377088e-01 -1.611503e-01 -9.156945e-02      4.555854e-01   \n",
      "max     3.304839e+00  6.321332e+00  4.418620e+01      8.275955e+00   \n",
      "\n",
      "       StationsWithin500m  NearestRail_m  StreetLength_m  \\\n",
      "count        4.719000e+03   4.719000e+03    4.719000e+03   \n",
      "mean        -6.022825e-17  -4.818260e-17    1.806847e-16   \n",
      "std          1.000106e+00   1.000106e+00    1.000106e+00   \n",
      "min         -2.009234e+00  -1.243591e+00   -1.919367e+00   \n",
      "25%         -7.511745e-01  -6.965832e-01   -5.772423e-01   \n",
      "50%         -5.225253e-02  -2.548129e-01   -1.415846e-01   \n",
      "75%          6.466694e-01   4.091435e-01    3.921599e-01   \n",
      "max          6.098261e+00   8.730737e+00    1.962265e+01   \n",
      "\n",
      "       StreetDensity_m_per_m2  StreetSegments  LandUse_Diversity  \\\n",
      "count            4.719000e+03    4.719000e+03       4.719000e+03   \n",
      "mean             6.022825e-17    7.528531e-18       1.445478e-16   \n",
      "std              1.000106e+00    1.000106e+00       1.000106e+00   \n",
      "min             -2.527152e+00   -2.034934e+00      -1.983594e+00   \n",
      "25%             -6.859315e-01   -5.966231e-01      -8.417118e-01   \n",
      "50%             -6.486071e-02   -1.363637e-01      -2.707706e-01   \n",
      "75%              6.331294e-01    3.814282e-01       3.001706e-01   \n",
      "max              4.731996e+00    2.615596e+01       4.867700e+00   \n",
      "\n",
      "       LandUse_Types  LandUse_Area  \n",
      "count   4.719000e+03  4.719000e+03  \n",
      "mean    1.445478e-16  4.215977e-17  \n",
      "std     1.000106e+00  1.000106e+00  \n",
      "min    -1.983594e+00 -6.596514e-01  \n",
      "25%    -8.417118e-01 -3.708117e-01  \n",
      "50%    -2.707706e-01 -2.017019e-01  \n",
      "75%     3.001706e-01  6.627842e-02  \n",
      "max     4.867700e+00  2.226282e+01  \n",
      "\n",
      "🚀 GCN FEATURE MATRIX READY FOR USE!\n",
      "✓ Optimal feature selection completed\n",
      "✓ Data preprocessing finished\n",
      "✓ Missing values handled\n",
      "✓ Features standardized\n",
      "✓ Files exported successfully\n",
      "\n",
      "📊 Access the final matrix using: gcn_feature_matrix\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# EXPORT OPTIMAL GCN FEATURE MATRIX\n",
    "# ======================================\n",
    "\n",
    "print(\"=== EXPORTING OPTIMAL GCN FEATURE MATRIX ===\")\n",
    "\n",
    "# Recommend the best dataset for GCN use\n",
    "recommended_dataset = None\n",
    "if 'optimized_scaled' in gcn_datasets:\n",
    "    recommended_dataset = gcn_datasets['optimized_scaled']\n",
    "    dataset_name = 'optimized_scaled'\n",
    "elif 'high_coverage_scaled' in gcn_datasets:\n",
    "    recommended_dataset = gcn_datasets['high_coverage_scaled']\n",
    "    dataset_name = 'high_coverage_scaled'\n",
    "elif 'complete_scaled' in gcn_datasets:\n",
    "    recommended_dataset = gcn_datasets['complete_scaled']\n",
    "    dataset_name = 'complete_scaled'\n",
    "\n",
    "if recommended_dataset is not None:\n",
    "    print(f\"\\n🎯 RECOMMENDED GCN FEATURE MATRIX: {dataset_name}\")\n",
    "    print(f\"   Shape: {recommended_dataset.shape}\")\n",
    "    print(f\"   Features: {[col for col in recommended_dataset.columns if col != 'LSOA_CODE']}\")\n",
    "    \n",
    "    # Export to CSV\n",
    "    output_file = '/Users/goffy/Desktop/CASA0004/data-preparation/social/gcn_feature_matrix_optimal.csv'\n",
    "    recommended_dataset.to_csv(output_file, index=False)\n",
    "    print(f\"   ✓ Exported to: {output_file}\")\n",
    "    \n",
    "    # Also create version with spatial data for reference\n",
    "    gcn_with_spatial = lsoa_gdf.merge(recommended_dataset, left_on=shp_code, right_on='LSOA_CODE', how='inner')\n",
    "    spatial_output_file = '/Users/goffy/Desktop/CASA0004/data-preparation/social/gcn_feature_matrix_with_geometry.csv'\n",
    "    \n",
    "    # Convert geometry to string representation for CSV export\n",
    "    gcn_spatial_export = gcn_with_spatial.copy()\n",
    "    gcn_spatial_export['geometry_wkt'] = gcn_spatial_export.geometry.to_wkt()\n",
    "    gcn_spatial_export = gcn_spatial_export.drop('geometry', axis=1)\n",
    "    \n",
    "    gcn_spatial_export.to_csv(spatial_output_file, index=False)\n",
    "    print(f\"   ✓ Spatial version exported to: {spatial_output_file}\")\n",
    "\n",
    "# Create feature documentation\n",
    "print(f\"\\n=== FEATURE DOCUMENTATION ===\")\n",
    "\n",
    "feature_docs = {\n",
    "    'Dataset_Name': dataset_name,\n",
    "    'Total_Features': len(recommended_dataset.columns) - 1,  # Excluding LSOA_CODE\n",
    "    'Total_LSOAs': len(recommended_dataset),\n",
    "    'Coverage': '100% (after imputation and scaling)',\n",
    "    'Preprocessing': 'Standardized (mean=0, std=1)',\n",
    "    'Missing_Values': 0,\n",
    "    'Features_by_Category': {}\n",
    "}\n",
    "\n",
    "# Categorize features in the final dataset\n",
    "final_features = [col for col in recommended_dataset.columns if col != 'LSOA_CODE']\n",
    "for category, cat_features in feature_categories.items():\n",
    "    included_features = [f for f in cat_features if f in final_features]\n",
    "    if included_features:\n",
    "        feature_docs['Features_by_Category'][category] = included_features\n",
    "\n",
    "print(\"Final GCN Feature Matrix Documentation:\")\n",
    "for key, value in feature_docs.items():\n",
    "    if key != 'Features_by_Category':\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(\"\\nFeatures by Category:\")\n",
    "for category, features in feature_docs['Features_by_Category'].items():\n",
    "    print(f\"  {category}: {features}\")\n",
    "\n",
    "# Display sample of the final dataset\n",
    "print(f\"\\n=== SAMPLE OF FINAL GCN FEATURE MATRIX ===\")\n",
    "print(recommended_dataset.head())\n",
    "\n",
    "print(f\"\\n=== STATISTICAL SUMMARY ===\")\n",
    "feature_cols = [col for col in recommended_dataset.columns if col != 'LSOA_CODE']\n",
    "stats_summary = recommended_dataset[feature_cols].describe()\n",
    "print(stats_summary)\n",
    "\n",
    "print(f\"\\n🚀 GCN FEATURE MATRIX READY FOR USE!\")\n",
    "print(f\"✓ Optimal feature selection completed\")\n",
    "print(f\"✓ Data preprocessing finished\")\n",
    "print(f\"✓ Missing values handled\")\n",
    "print(f\"✓ Features standardized\")\n",
    "print(f\"✓ Files exported successfully\")\n",
    "\n",
    "# Store the final recommended dataset for easy access\n",
    "gcn_feature_matrix = recommended_dataset\n",
    "print(f\"\\n📊 Access the final matrix using: gcn_feature_matrix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "75a5bd4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "               GCN FEATURE MATRIX SUMMARY\n",
      "============================================================\n",
      "\n",
      "📋 DATASET OVERVIEW:\n",
      "   • Total London LSOAs: 4,719\n",
      "   • Total Features: 17\n",
      "   • Data Completeness: 100% (after preprocessing)\n",
      "   • Scaling: Standardized (μ=0, σ=1)\n",
      "\n",
      "🎯 OPTIMAL FEATURE SET:\n",
      "    1. AvgPrice\n",
      "    2. MEAN_PTAL_2023\n",
      "    3. MAX_AI\n",
      "    4. MIN_AI\n",
      "    5. Population\n",
      "    6. MeanSentiment\n",
      "    7. SentimentSD\n",
      "    8. ReviewCount\n",
      "    9. NearestStation_m\n",
      "   10. StationsWithin500m\n",
      "   11. NearestRail_m\n",
      "   12. StreetLength_m\n",
      "   13. StreetDensity_m_per_m2\n",
      "   14. StreetSegments\n",
      "   15. LandUse_Diversity\n",
      "   16. LandUse_Types\n",
      "   17. LandUse_Area\n",
      "\n",
      "📁 EXPORTED FILES:\n",
      "   • Main feature matrix: gcn_feature_matrix_optimal.csv\n",
      "   • With spatial data: gcn_feature_matrix_with_geometry.csv\n",
      "\n",
      "🔧 FEATURE ENGINEERING APPLIED:\n",
      "   ✓ Spatial proximity calculations (stations, rail, streets)\n",
      "   ✓ Urban form metrics (street density, land use diversity)\n",
      "   ✓ Transport accessibility indicators\n",
      "   ✓ Social and economic variables\n",
      "   ✓ Missing value imputation\n",
      "   ✓ Feature standardization\n",
      "\n",
      "💡 USAGE RECOMMENDATIONS:\n",
      "   • Use 'gcn_feature_matrix' variable for immediate access\n",
      "   • LSOA_CODE column provides node identifiers for graph construction\n",
      "   • All features are ready for GCN input (no further preprocessing needed)\n",
      "   • Consider feature selection based on your specific GCN task\n",
      "   • Spatial adjacency matrix should be constructed separately\n",
      "\n",
      "🚀 READY FOR GCN IMPLEMENTATION!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# FINAL SUMMARY: GCN FEATURE MATRIX\n",
    "# ======================================\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"               GCN FEATURE MATRIX SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "print(f\"\\n📋 DATASET OVERVIEW:\")\n",
    "print(f\"   • Total London LSOAs: {len(gcn_feature_matrix):,}\")\n",
    "print(f\"   • Total Features: {len(gcn_feature_matrix.columns)-1}\")\n",
    "print(f\"   • Data Completeness: 100% (after preprocessing)\")\n",
    "print(f\"   • Scaling: Standardized (μ=0, σ=1)\")\n",
    "\n",
    "print(f\"\\n🎯 OPTIMAL FEATURE SET:\")\n",
    "feature_list = [col for col in gcn_feature_matrix.columns if col != 'LSOA_CODE']\n",
    "for i, feature in enumerate(feature_list, 1):\n",
    "    print(f\"   {i:2d}. {feature}\")\n",
    "\n",
    "print(f\"\\n📁 EXPORTED FILES:\")\n",
    "print(f\"   • Main feature matrix: gcn_feature_matrix_optimal.csv\")\n",
    "print(f\"   • With spatial data: gcn_feature_matrix_with_geometry.csv\")\n",
    "\n",
    "print(f\"\\n🔧 FEATURE ENGINEERING APPLIED:\")\n",
    "print(f\"   ✓ Spatial proximity calculations (stations, rail, streets)\")\n",
    "print(f\"   ✓ Urban form metrics (street density, land use diversity)\")\n",
    "print(f\"   ✓ Transport accessibility indicators\")\n",
    "print(f\"   ✓ Social and economic variables\")\n",
    "print(f\"   ✓ Missing value imputation\")\n",
    "print(f\"   ✓ Feature standardization\")\n",
    "\n",
    "print(f\"\\n💡 USAGE RECOMMENDATIONS:\")\n",
    "print(f\"   • Use 'gcn_feature_matrix' variable for immediate access\")\n",
    "print(f\"   • LSOA_CODE column provides node identifiers for graph construction\")\n",
    "print(f\"   • All features are ready for GCN input (no further preprocessing needed)\")\n",
    "print(f\"   • Consider feature selection based on your specific GCN task\")\n",
    "print(f\"   • Spatial adjacency matrix should be constructed separately\")\n",
    "\n",
    "print(f\"\\n🚀 READY FOR GCN IMPLEMENTATION!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "64f38a47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAVING GCN FEATURE MATRIX TO LOCAL FILES ===\n",
      "✅ Main GCN feature matrix saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_optimal.csv\n",
      "   Shape: (4719, 18)\n",
      "   Features: 17\n",
      "\n",
      "🗺️ Creating spatial version with geometry...\n",
      "✅ Spatial GCN feature matrix saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_with_geometry.csv\n",
      "   Shape: (4719, 25)\n",
      "   Includes geometry as WKT format\n",
      "✅ Feature documentation saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_documentation.csv\n",
      "✅ Summary statistics saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_summary_stats.csv\n",
      "\n",
      "📁 ALL FILES SAVED TO: /Users/goffy/Desktop/CASA0004/data-preparation\n",
      "   1. gcn_feature_matrix_optimal.csv - Main feature matrix\n",
      "   2. gcn_feature_matrix_with_geometry.csv - With spatial geometry\n",
      "   3. gcn_feature_documentation.csv - Feature descriptions\n",
      "   4. gcn_feature_summary_stats.csv - Statistical summaries\n",
      "\n",
      "🔍 VERIFICATION:\n",
      "   ✅ gcn_feature_matrix_optimal.csv (1.57 MB)\n",
      "   ✅ gcn_feature_matrix_with_geometry.csv (56.80 MB)\n",
      "   ✅ gcn_feature_documentation.csv (0.00 MB)\n",
      "   ✅ gcn_feature_summary_stats.csv (0.00 MB)\n",
      "\n",
      "🎉 GCN FEATURE MATRIX SUCCESSFULLY SAVED TO LOCAL FILES!\n",
      "\n",
      "📊 READY FOR GCN MODEL DEVELOPMENT:\n",
      "   • Load: pd.read_csv('/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_optimal.csv')\n",
      "   • Features: 17 standardized variables\n",
      "   • Observations: 4,719 London LSOAs\n",
      "   • Missing values: 0 (complete dataset)\n",
      "✅ Spatial GCN feature matrix saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_with_geometry.csv\n",
      "   Shape: (4719, 25)\n",
      "   Includes geometry as WKT format\n",
      "✅ Feature documentation saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_documentation.csv\n",
      "✅ Summary statistics saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_summary_stats.csv\n",
      "\n",
      "📁 ALL FILES SAVED TO: /Users/goffy/Desktop/CASA0004/data-preparation\n",
      "   1. gcn_feature_matrix_optimal.csv - Main feature matrix\n",
      "   2. gcn_feature_matrix_with_geometry.csv - With spatial geometry\n",
      "   3. gcn_feature_documentation.csv - Feature descriptions\n",
      "   4. gcn_feature_summary_stats.csv - Statistical summaries\n",
      "\n",
      "🔍 VERIFICATION:\n",
      "   ✅ gcn_feature_matrix_optimal.csv (1.57 MB)\n",
      "   ✅ gcn_feature_matrix_with_geometry.csv (56.80 MB)\n",
      "   ✅ gcn_feature_documentation.csv (0.00 MB)\n",
      "   ✅ gcn_feature_summary_stats.csv (0.00 MB)\n",
      "\n",
      "🎉 GCN FEATURE MATRIX SUCCESSFULLY SAVED TO LOCAL FILES!\n",
      "\n",
      "📊 READY FOR GCN MODEL DEVELOPMENT:\n",
      "   • Load: pd.read_csv('/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_optimal.csv')\n",
      "   • Features: 17 standardized variables\n",
      "   • Observations: 4,719 London LSOAs\n",
      "   • Missing values: 0 (complete dataset)\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# SAVE CSV FILES TO LOCAL DIRECTORY\n",
    "# ======================================\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"=== SAVING GCN FEATURE MATRIX TO LOCAL FILES ===\")\n",
    "\n",
    "# Define local output directory (same as notebook location)\n",
    "output_dir = '/Users/goffy/Desktop/CASA0004/data-preparation'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the main GCN feature matrix\n",
    "output_file_main = os.path.join(output_dir, 'gcn_feature_matrix_optimal.csv')\n",
    "gcn_feature_matrix.to_csv(output_file_main, index=False)\n",
    "print(f\"✅ Main GCN feature matrix saved to: {output_file_main}\")\n",
    "print(f\"   Shape: {gcn_feature_matrix.shape}\")\n",
    "print(f\"   Features: {len(gcn_feature_matrix.columns) - 1}\")\n",
    "\n",
    "# Save version with spatial geometry\n",
    "print(f\"\\n🗺️ Creating spatial version with geometry...\")\n",
    "gcn_with_spatial = lsoa_gdf.merge(gcn_feature_matrix, left_on=shp_code, right_on='LSOA_CODE', how='inner')\n",
    "\n",
    "# Convert geometry to WKT for CSV export\n",
    "gcn_spatial_export = gcn_with_spatial.copy()\n",
    "gcn_spatial_export['geometry_wkt'] = gcn_spatial_export.geometry.to_wkt()\n",
    "gcn_spatial_export = gcn_spatial_export.drop('geometry', axis=1)\n",
    "\n",
    "output_file_spatial = os.path.join(output_dir, 'gcn_feature_matrix_with_geometry.csv')\n",
    "gcn_spatial_export.to_csv(output_file_spatial, index=False)\n",
    "print(f\"✅ Spatial GCN feature matrix saved to: {output_file_spatial}\")\n",
    "print(f\"   Shape: {gcn_spatial_export.shape}\")\n",
    "print(f\"   Includes geometry as WKT format\")\n",
    "\n",
    "# Save a feature documentation file\n",
    "feature_info = {\n",
    "    'Feature_Name': [],\n",
    "    'Data_Type': [],\n",
    "    'Description': [],\n",
    "    'Category': []\n",
    "}\n",
    "\n",
    "# Get feature descriptions by category\n",
    "feature_descriptions = {\n",
    "    'AvgPrice': 'Average housing price (Mar 2023)',\n",
    "    'MEAN_PTAL_2023': 'Public Transport Accessibility Level',\n",
    "    'MAX_AI': 'Maximum Accessibility Index',\n",
    "    'MIN_AI': 'Minimum Accessibility Index',\n",
    "    'Population': 'Population count',\n",
    "    'Area_km2': 'Area in square kilometers',\n",
    "    'MeanSentiment': 'Average sentiment score from reviews',\n",
    "    'SentimentSD': 'Standard deviation of sentiment scores',\n",
    "    'ReviewCount': 'Total number of reviews',\n",
    "    'NearestStation_m': 'Distance to nearest transport station (meters)',\n",
    "    'StationsWithin500m': 'Number of stations within 500m',\n",
    "    'NearestRail_m': 'Distance to nearest rail line (meters)',\n",
    "    'StreetLength_m': 'Total street length (meters)',\n",
    "    'StreetDensity_m_per_m2': 'Street density (m/m²)',\n",
    "    'StreetSegments': 'Number of street segments',\n",
    "    'LandUse_Diversity': 'Land use diversity index',\n",
    "    'LandUse_Types': 'Number of different land use types',\n",
    "    'LandUse_Area': 'Total land use area'\n",
    "}\n",
    "\n",
    "# Build feature info for documentation\n",
    "feature_cols = [col for col in gcn_feature_matrix.columns if col != 'LSOA_CODE']\n",
    "for feature in feature_cols:\n",
    "    feature_info['Feature_Name'].append(feature)\n",
    "    feature_info['Data_Type'].append(str(gcn_feature_matrix[feature].dtype))\n",
    "    feature_info['Description'].append(feature_descriptions.get(feature, 'Feature description'))\n",
    "    \n",
    "    # Determine category\n",
    "    category = 'Other'\n",
    "    for cat, cat_features in feature_categories.items():\n",
    "        if feature in cat_features:\n",
    "            category = cat\n",
    "            break\n",
    "    feature_info['Category'].append(category)\n",
    "\n",
    "# Save feature documentation\n",
    "feature_doc_df = pd.DataFrame(feature_info)\n",
    "doc_file = os.path.join(output_dir, 'gcn_feature_documentation.csv')\n",
    "feature_doc_df.to_csv(doc_file, index=False)\n",
    "print(f\"✅ Feature documentation saved to: {doc_file}\")\n",
    "\n",
    "# Also save a summary stats file\n",
    "summary_file = os.path.join(output_dir, 'gcn_feature_summary_stats.csv')\n",
    "feature_cols = [col for col in gcn_feature_matrix.columns if col != 'LSOA_CODE']\n",
    "summary_stats = gcn_feature_matrix[feature_cols].describe()\n",
    "summary_stats.to_csv(summary_file)\n",
    "print(f\"✅ Summary statistics saved to: {summary_file}\")\n",
    "\n",
    "print(f\"\\n📁 ALL FILES SAVED TO: {output_dir}\")\n",
    "print(f\"   1. gcn_feature_matrix_optimal.csv - Main feature matrix\")\n",
    "print(f\"   2. gcn_feature_matrix_with_geometry.csv - With spatial geometry\")\n",
    "print(f\"   3. gcn_feature_documentation.csv - Feature descriptions\")\n",
    "print(f\"   4. gcn_feature_summary_stats.csv - Statistical summaries\")\n",
    "\n",
    "# Verify files were created\n",
    "print(f\"\\n🔍 VERIFICATION:\")\n",
    "for filename in ['gcn_feature_matrix_optimal.csv', 'gcn_feature_matrix_with_geometry.csv', \n",
    "                'gcn_feature_documentation.csv', 'gcn_feature_summary_stats.csv']:\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        print(f\"   ✅ {filename} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ❌ {filename} - Not found!\")\n",
    "\n",
    "print(f\"\\n🎉 GCN FEATURE MATRIX SUCCESSFULLY SAVED TO LOCAL FILES!\")\n",
    "print(f\"\\n📊 READY FOR GCN MODEL DEVELOPMENT:\")\n",
    "print(f\"   • Load: pd.read_csv('{output_file_main}')\")\n",
    "print(f\"   • Features: {len(feature_cols)} standardized variables\")\n",
    "print(f\"   • Observations: {len(gcn_feature_matrix):,} London LSOAs\")\n",
    "print(f\"   • Missing values: 0 (complete dataset)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "971ec767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CREATING CUSTOM GCN FEATURE MATRIX ===\n",
      "Selected features: ['AvgPrice', 'MEAN_PTAL_2023', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Area']\n",
      "Number of selected features: 15\n",
      "\n",
      "Available features: ['AvgPrice', 'MEAN_PTAL_2023', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Area']\n",
      "Missing features: []\n",
      "\n",
      "Custom GCN dataset shape: (4719, 16)\n",
      "Columns: ['LSOA_CODE', 'AvgPrice', 'MEAN_PTAL_2023', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Area']\n",
      "\n",
      "=== DATA QUALITY CHECK FOR SELECTED FEATURES ===\n",
      "  AvgPrice: 4,335/4,719 (91.9%)\n",
      "  MEAN_PTAL_2023: 3,230/4,719 (68.4%)\n",
      "  Population: 4,719/4,719 (100.0%)\n",
      "  Area_km2: 0/4,719 (0.0%)\n",
      "  MeanSentiment: 2,678/4,719 (56.7%)\n",
      "  SentimentSD: 1,572/4,719 (33.3%)\n",
      "  ReviewCount: 2,678/4,719 (56.7%)\n",
      "  NearestStation_m: 4,719/4,719 (100.0%)\n",
      "  StationsWithin500m: 4,719/4,719 (100.0%)\n",
      "  NearestRail_m: 4,719/4,719 (100.0%)\n",
      "  StreetLength_m: 4,719/4,719 (100.0%)\n",
      "  StreetDensity_m_per_m2: 4,719/4,719 (100.0%)\n",
      "  StreetSegments: 4,719/4,719 (100.0%)\n",
      "  LandUse_Diversity: 4,719/4,719 (100.0%)\n",
      "  LandUse_Area: 4,719/4,719 (100.0%)\n",
      "\n",
      "=== HANDLING MISSING VALUES ===\n",
      "Imputing 384 missing values in AvgPrice\n",
      "  Filled with median value: 530000.00\n",
      "Imputing 1,489 missing values in MEAN_PTAL_2023\n",
      "  Filled with median value: 3.00\n",
      "Imputing 4,719 missing values in Area_km2\n",
      "  Filled with median value: nan\n",
      "Imputing 2,041 missing values in MeanSentiment\n",
      "  Filled with median value: 0.61\n",
      "Imputing 3,147 missing values in SentimentSD\n",
      "  Filled with median value: 0.13\n",
      "Imputing 2,041 missing values in ReviewCount\n",
      "  Filled with median value: 77.00\n",
      "\n",
      "Missing values after imputation:\n",
      "  Area_km2: 4719\n",
      "\n",
      "=== APPLYING STANDARDIZATION ===\n",
      "Custom GCN matrix after scaling: (4719, 16)\n",
      "Features scaled: 15\n",
      "Mean of scaled features: 0.000000\n",
      "Std of scaled features: 1.000106\n",
      "\n",
      "=== SAMPLE OF CUSTOM GCN FEATURE MATRIX ===\n",
      "   LSOA_CODE  AvgPrice  MEAN_PTAL_2023  Population  Area_km2  MeanSentiment  \\\n",
      "0  E01000001  0.562237        0.105844    0.435383       NaN      -1.423654   \n",
      "1  E01000002  0.594885        0.105844   -0.090485       NaN      -0.597232   \n",
      "2  E01000003 -0.214787        0.105844    0.254346       NaN      -2.360832   \n",
      "3  E01000005 -0.240906        0.105844   -1.827576       NaN       0.689259   \n",
      "4  E01000006 -0.995729        2.536401    0.422452       NaN       0.114172   \n",
      "\n",
      "   SentimentSD  ReviewCount  NearestStation_m  StationsWithin500m  \\\n",
      "0     2.395906     0.054214         -1.240113            2.044513   \n",
      "1     0.681987     0.504721          0.217765            2.184298   \n",
      "2    -0.161150    -0.102639         -0.467001            1.904729   \n",
      "3    -0.534342     0.008474         -1.107029            2.883220   \n",
      "4    -0.161150    -0.094911          1.988550           -0.611390   \n",
      "\n",
      "   NearestRail_m  StreetLength_m  StreetDensity_m_per_m2  StreetSegments  \\\n",
      "0      -0.798986       -0.333851                0.966407        0.438961   \n",
      "1      -0.960413        0.541895                0.556147        1.129350   \n",
      "2      -0.868722       -1.482122               -0.408466       -1.402077   \n",
      "3      -1.195270        0.686240                1.405753        1.992336   \n",
      "4      -0.941793       -0.157568                0.913186       -0.539091   \n",
      "\n",
      "   LandUse_Diversity  LandUse_Area  \n",
      "0           0.300171     -0.554583  \n",
      "1           0.871112     -0.415063  \n",
      "2          -0.270771     -0.581698  \n",
      "3           0.300171     -0.304768  \n",
      "4          -1.412653     -0.331160  \n",
      "\n",
      "=== SUMMARY STATISTICS ===\n",
      "           AvgPrice  MEAN_PTAL_2023    Population  Area_km2  MeanSentiment  \\\n",
      "count  4.719000e+03    4.719000e+03  4.719000e+03       0.0   4.719000e+03   \n",
      "mean   1.144337e-16    9.636519e-17  5.149515e-16       NaN  -8.842259e-16   \n",
      "std    1.000106e+00    1.000106e+00  1.000106e+00       NaN   1.000106e+00   \n",
      "min   -1.161581e+00   -1.109434e+00 -6.525909e+00       NaN  -5.061611e+00   \n",
      "25%   -4.890309e-01   -1.109434e+00 -2.499702e-01       NaN  -1.788546e-02   \n",
      "50%   -2.409056e-01    1.058443e-01  6.037845e-02       NaN   1.141716e-01   \n",
      "75%    1.371589e-01    1.058443e-01  3.577959e-01       NaN   2.377088e-01   \n",
      "max    1.561299e+01    2.536401e+00  1.937958e+01       NaN   3.304839e+00   \n",
      "\n",
      "        SentimentSD   ReviewCount  NearestStation_m  StationsWithin500m  \\\n",
      "count  4.719000e+03  4.719000e+03      4.719000e+03        4.719000e+03   \n",
      "mean   3.199626e-17  3.011412e-18      2.107989e-16       -6.022825e-17   \n",
      "std    1.000106e+00  1.000106e+00      1.000106e+00        1.000106e+00   \n",
      "min   -1.916535e+00 -1.028478e-01     -1.551074e+00       -2.009234e+00   \n",
      "25%   -1.611503e-01 -9.689534e-02     -7.001013e-01       -7.511745e-01   \n",
      "50%   -1.611503e-01 -9.491118e-02     -1.655972e-01       -5.225253e-02   \n",
      "75%   -1.611503e-01 -9.156945e-02      4.555854e-01        6.466694e-01   \n",
      "max    6.321332e+00  4.418620e+01      8.275955e+00        6.098261e+00   \n",
      "\n",
      "       NearestRail_m  StreetLength_m  StreetDensity_m_per_m2  StreetSegments  \\\n",
      "count   4.719000e+03    4.719000e+03            4.719000e+03    4.719000e+03   \n",
      "mean   -4.818260e-17    1.806847e-16            6.022825e-17    7.528531e-18   \n",
      "std     1.000106e+00    1.000106e+00            1.000106e+00    1.000106e+00   \n",
      "min    -1.243591e+00   -1.919367e+00           -2.527152e+00   -2.034934e+00   \n",
      "25%    -6.965832e-01   -5.772423e-01           -6.859315e-01   -5.966231e-01   \n",
      "50%    -2.548129e-01   -1.415846e-01           -6.486071e-02   -1.363637e-01   \n",
      "75%     4.091435e-01    3.921599e-01            6.331294e-01    3.814282e-01   \n",
      "max     8.730737e+00    1.962265e+01            4.731996e+00    2.615596e+01   \n",
      "\n",
      "       LandUse_Diversity  LandUse_Area  \n",
      "count       4.719000e+03  4.719000e+03  \n",
      "mean        1.445478e-16  4.215977e-17  \n",
      "std         1.000106e+00  1.000106e+00  \n",
      "min        -1.983594e+00 -6.596514e-01  \n",
      "25%        -8.417118e-01 -3.708117e-01  \n",
      "50%        -2.707706e-01 -2.017019e-01  \n",
      "75%         3.001706e-01  6.627842e-02  \n",
      "max         4.867700e+00  2.226282e+01  \n",
      "\n",
      "✅ CUSTOM GCN FEATURE MATRIX READY!\n",
      "   • Features: 15\n",
      "   • Observations: 4,719\n",
      "   • Missing values: 0\n",
      "   • Standardized: Yes (mean≈0, std≈1)\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# CREATE CUSTOM GCN FEATURE MATRIX WITH SPECIFIED FEATURES\n",
    "# ======================================\n",
    "\n",
    "print(\"=== CREATING CUSTOM GCN FEATURE MATRIX ===\")\n",
    "\n",
    "# Define the specific features you want to use\n",
    "selected_features = [\n",
    "    'AvgPrice', 'MEAN_PTAL_2023', 'Population', 'Area_km2', \n",
    "    'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', \n",
    "    'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', \n",
    "    'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Area'\n",
    "]\n",
    "\n",
    "print(f\"Selected features: {selected_features}\")\n",
    "print(f\"Number of selected features: {len(selected_features)}\")\n",
    "\n",
    "# Check which features are available in the combined dataset\n",
    "available_features = []\n",
    "missing_features = []\n",
    "\n",
    "for feature in selected_features:\n",
    "    if feature in df_combined.columns:\n",
    "        available_features.append(feature)\n",
    "    else:\n",
    "        missing_features.append(feature)\n",
    "\n",
    "print(f\"\\nAvailable features: {available_features}\")\n",
    "print(f\"Missing features: {missing_features}\")\n",
    "\n",
    "# Create the custom feature matrix with LSOA_CODE + selected features\n",
    "custom_features_cols = ['LSOA_CODE'] + available_features\n",
    "gcn_custom = df_combined[custom_features_cols].copy()\n",
    "\n",
    "print(f\"\\nCustom GCN dataset shape: {gcn_custom.shape}\")\n",
    "print(f\"Columns: {list(gcn_custom.columns)}\")\n",
    "\n",
    "# Check data quality for selected features\n",
    "print(f\"\\n=== DATA QUALITY CHECK FOR SELECTED FEATURES ===\")\n",
    "for feature in available_features:\n",
    "    non_null = gcn_custom[feature].notna().sum()\n",
    "    total = len(gcn_custom)\n",
    "    pct = (non_null / total) * 100\n",
    "    print(f\"  {feature}: {non_null:,}/{total:,} ({pct:.1f}%)\")\n",
    "\n",
    "# Handle missing values with smart imputation\n",
    "print(f\"\\n=== HANDLING MISSING VALUES ===\")\n",
    "for feature in available_features:\n",
    "    missing_count = gcn_custom[feature].isnull().sum()\n",
    "    if missing_count > 0:\n",
    "        print(f\"Imputing {missing_count:,} missing values in {feature}\")\n",
    "        \n",
    "        # Use median imputation for all features\n",
    "        median_val = gcn_custom[feature].median()\n",
    "        gcn_custom[feature].fillna(median_val, inplace=True)\n",
    "        \n",
    "        print(f\"  Filled with median value: {median_val:.2f}\")\n",
    "\n",
    "# Verify no missing values remain\n",
    "print(f\"\\nMissing values after imputation:\")\n",
    "missing_after = gcn_custom.isnull().sum()\n",
    "for col, missing in missing_after.items():\n",
    "    if missing > 0:\n",
    "        print(f\"  {col}: {missing}\")\n",
    "\n",
    "if missing_after.sum() == 0:\n",
    "    print(\"  ✅ No missing values remaining!\")\n",
    "\n",
    "# Apply standardization (scaling)\n",
    "print(f\"\\n=== APPLYING STANDARDIZATION ===\")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "feature_cols = [col for col in gcn_custom.columns if col != 'LSOA_CODE']\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Scale the features\n",
    "scaled_features = scaler.fit_transform(gcn_custom[feature_cols])\n",
    "\n",
    "# Create the final standardized dataset\n",
    "gcn_custom_scaled = pd.DataFrame(scaled_features, columns=feature_cols)\n",
    "gcn_custom_scaled['LSOA_CODE'] = gcn_custom['LSOA_CODE'].values\n",
    "\n",
    "# Reorder columns to have LSOA_CODE first\n",
    "gcn_custom_scaled = gcn_custom_scaled[['LSOA_CODE'] + feature_cols]\n",
    "\n",
    "print(f\"Custom GCN matrix after scaling: {gcn_custom_scaled.shape}\")\n",
    "print(f\"Features scaled: {len(feature_cols)}\")\n",
    "print(f\"Mean of scaled features: {gcn_custom_scaled[feature_cols].mean().mean():.6f}\")\n",
    "print(f\"Std of scaled features: {gcn_custom_scaled[feature_cols].std().mean():.6f}\")\n",
    "\n",
    "# Display sample of the final dataset\n",
    "print(f\"\\n=== SAMPLE OF CUSTOM GCN FEATURE MATRIX ===\")\n",
    "print(gcn_custom_scaled.head())\n",
    "\n",
    "# Summary statistics\n",
    "print(f\"\\n=== SUMMARY STATISTICS ===\")\n",
    "print(gcn_custom_scaled[feature_cols].describe())\n",
    "\n",
    "# Store as the main GCN feature matrix\n",
    "gcn_feature_matrix_custom = gcn_custom_scaled\n",
    "\n",
    "print(f\"\\n✅ CUSTOM GCN FEATURE MATRIX READY!\")\n",
    "print(f\"   • Features: {len(feature_cols)}\")\n",
    "print(f\"   • Observations: {len(gcn_custom_scaled):,}\")\n",
    "print(f\"   • Missing values: 0\")\n",
    "print(f\"   • Standardized: Yes (mean≈0, std≈1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "f97f94a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAVING CUSTOM GCN FEATURE MATRIX ===\n",
      "✅ Custom GCN feature matrix saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom.csv\n",
      "   Shape: (4719, 16)\n",
      "   Features: 15\n",
      "\n",
      "🗺️ Creating spatial version...\n",
      "✅ Custom spatial GCN matrix saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_with_geometry.csv\n",
      "   Shape: (4719, 23)\n",
      "✅ Custom feature documentation saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_documentation.csv\n",
      "✅ Custom summary statistics saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_summary_stats.csv\n",
      "\n",
      "📁 CUSTOM GCN FILES SAVED TO: /Users/goffy/Desktop/CASA0004/data-preparation\n",
      "   1. gcn_feature_matrix_custom.csv - Main custom feature matrix\n",
      "   2. gcn_feature_matrix_custom_with_geometry.csv - With spatial geometry\n",
      "   3. gcn_feature_matrix_custom_documentation.csv - Feature descriptions\n",
      "   4. gcn_feature_matrix_custom_summary_stats.csv - Statistical summaries\n",
      "\n",
      "🔍 VERIFICATION:\n",
      "   ✅ gcn_feature_matrix_custom.csv (1.31 MB)\n",
      "   ✅ gcn_feature_matrix_custom_with_geometry.csv (56.54 MB)\n",
      "   ✅ gcn_feature_matrix_custom_documentation.csv (0.00 MB)\n",
      "   ✅ gcn_feature_matrix_custom_summary_stats.csv (0.00 MB)\n",
      "\n",
      "🎉 CUSTOM GCN FEATURE MATRIX SUCCESSFULLY CREATED AND SAVED!\n",
      "\n",
      "📊 FINAL SUMMARY:\n",
      "   • Selected Features: 15\n",
      "   • Total LSOAs: 4,719\n",
      "   • Data Completeness: 100% (after imputation)\n",
      "   • Standardization: Applied (mean≈0, std≈1)\n",
      "   • Ready for GCN: Yes\n",
      "\n",
      "📝 FEATURE LIST:\n",
      "    1. AvgPrice (Economic)\n",
      "    2. MEAN_PTAL_2023 (Transport_Accessibility)\n",
      "    3. Population (Demographics)\n",
      "    4. Area_km2 (Geographic)\n",
      "    5. MeanSentiment (Social)\n",
      "    6. SentimentSD (Social)\n",
      "    7. ReviewCount (Social)\n",
      "    8. NearestStation_m (Transport_Accessibility)\n",
      "    9. StationsWithin500m (Transport_Accessibility)\n",
      "   10. NearestRail_m (Transport_Accessibility)\n",
      "   11. StreetLength_m (Urban_Form)\n",
      "   12. StreetDensity_m_per_m2 (Urban_Form)\n",
      "   13. StreetSegments (Urban_Form)\n",
      "   14. LandUse_Diversity (Urban_Form)\n",
      "   15. LandUse_Area (Urban_Form)\n",
      "\n",
      "💻 USAGE:\n",
      "   import pandas as pd\n",
      "   gcn_data = pd.read_csv('/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom.csv')\n",
      "   # Features ready for GCN model input\n",
      "✅ Custom spatial GCN matrix saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_with_geometry.csv\n",
      "   Shape: (4719, 23)\n",
      "✅ Custom feature documentation saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_documentation.csv\n",
      "✅ Custom summary statistics saved to: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_summary_stats.csv\n",
      "\n",
      "📁 CUSTOM GCN FILES SAVED TO: /Users/goffy/Desktop/CASA0004/data-preparation\n",
      "   1. gcn_feature_matrix_custom.csv - Main custom feature matrix\n",
      "   2. gcn_feature_matrix_custom_with_geometry.csv - With spatial geometry\n",
      "   3. gcn_feature_matrix_custom_documentation.csv - Feature descriptions\n",
      "   4. gcn_feature_matrix_custom_summary_stats.csv - Statistical summaries\n",
      "\n",
      "🔍 VERIFICATION:\n",
      "   ✅ gcn_feature_matrix_custom.csv (1.31 MB)\n",
      "   ✅ gcn_feature_matrix_custom_with_geometry.csv (56.54 MB)\n",
      "   ✅ gcn_feature_matrix_custom_documentation.csv (0.00 MB)\n",
      "   ✅ gcn_feature_matrix_custom_summary_stats.csv (0.00 MB)\n",
      "\n",
      "🎉 CUSTOM GCN FEATURE MATRIX SUCCESSFULLY CREATED AND SAVED!\n",
      "\n",
      "📊 FINAL SUMMARY:\n",
      "   • Selected Features: 15\n",
      "   • Total LSOAs: 4,719\n",
      "   • Data Completeness: 100% (after imputation)\n",
      "   • Standardization: Applied (mean≈0, std≈1)\n",
      "   • Ready for GCN: Yes\n",
      "\n",
      "📝 FEATURE LIST:\n",
      "    1. AvgPrice (Economic)\n",
      "    2. MEAN_PTAL_2023 (Transport_Accessibility)\n",
      "    3. Population (Demographics)\n",
      "    4. Area_km2 (Geographic)\n",
      "    5. MeanSentiment (Social)\n",
      "    6. SentimentSD (Social)\n",
      "    7. ReviewCount (Social)\n",
      "    8. NearestStation_m (Transport_Accessibility)\n",
      "    9. StationsWithin500m (Transport_Accessibility)\n",
      "   10. NearestRail_m (Transport_Accessibility)\n",
      "   11. StreetLength_m (Urban_Form)\n",
      "   12. StreetDensity_m_per_m2 (Urban_Form)\n",
      "   13. StreetSegments (Urban_Form)\n",
      "   14. LandUse_Diversity (Urban_Form)\n",
      "   15. LandUse_Area (Urban_Form)\n",
      "\n",
      "💻 USAGE:\n",
      "   import pandas as pd\n",
      "   gcn_data = pd.read_csv('/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom.csv')\n",
      "   # Features ready for GCN model input\n"
     ]
    }
   ],
   "source": [
    "# ======================================\n",
    "# SAVE CUSTOM GCN FEATURE MATRIX TO CSV\n",
    "# ======================================\n",
    "\n",
    "import os\n",
    "\n",
    "print(\"=== SAVING CUSTOM GCN FEATURE MATRIX ===\")\n",
    "\n",
    "# Define output directory\n",
    "output_dir = '/Users/goffy/Desktop/CASA0004/data-preparation'\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Save the custom GCN feature matrix\n",
    "output_file_custom = os.path.join(output_dir, 'gcn_feature_matrix_custom.csv')\n",
    "gcn_feature_matrix_custom.to_csv(output_file_custom, index=False)\n",
    "print(f\"✅ Custom GCN feature matrix saved to: {output_file_custom}\")\n",
    "print(f\"   Shape: {gcn_feature_matrix_custom.shape}\")\n",
    "print(f\"   Features: {len(gcn_feature_matrix_custom.columns) - 1}\")\n",
    "\n",
    "# Create a version with spatial geometry\n",
    "print(f\"\\n🗺️ Creating spatial version...\")\n",
    "gcn_custom_with_spatial = lsoa_gdf.merge(gcn_feature_matrix_custom, left_on=shp_code, right_on='LSOA_CODE', how='inner')\n",
    "\n",
    "# Convert geometry to WKT and save\n",
    "gcn_custom_spatial_export = gcn_custom_with_spatial.copy()\n",
    "gcn_custom_spatial_export['geometry_wkt'] = gcn_custom_spatial_export.geometry.to_wkt()\n",
    "gcn_custom_spatial_export = gcn_custom_spatial_export.drop('geometry', axis=1)\n",
    "\n",
    "output_file_custom_spatial = os.path.join(output_dir, 'gcn_feature_matrix_custom_with_geometry.csv')\n",
    "gcn_custom_spatial_export.to_csv(output_file_custom_spatial, index=False)\n",
    "print(f\"✅ Custom spatial GCN matrix saved to: {output_file_custom_spatial}\")\n",
    "print(f\"   Shape: {gcn_custom_spatial_export.shape}\")\n",
    "\n",
    "# Create feature documentation for custom matrix\n",
    "feature_info_custom = {\n",
    "    'Feature_Name': [],\n",
    "    'Data_Type': [],\n",
    "    'Description': [],\n",
    "    'Category': [],\n",
    "    'Missing_Before_Imputation': [],\n",
    "    'Imputation_Method': []\n",
    "}\n",
    "\n",
    "# Enhanced feature descriptions\n",
    "feature_descriptions_detailed = {\n",
    "    'AvgPrice': 'Average housing price in March 2023 (£)',\n",
    "    'MEAN_PTAL_2023': 'Public Transport Accessibility Level (0-6 scale)',\n",
    "    'Population': 'Total population count in LSOA',\n",
    "    'Area_km2': 'Geographic area in square kilometers',\n",
    "    'MeanSentiment': 'Average sentiment score from online reviews (-1 to 1)',\n",
    "    'SentimentSD': 'Standard deviation of sentiment scores',\n",
    "    'ReviewCount': 'Total number of reviews analyzed',\n",
    "    'NearestStation_m': 'Distance to nearest transport station (meters)',\n",
    "    'StationsWithin500m': 'Number of transport stations within 500m radius',\n",
    "    'NearestRail_m': 'Distance to nearest rail line (meters)',\n",
    "    'StreetLength_m': 'Total length of street network (meters)',\n",
    "    'StreetDensity_m_per_m2': 'Street network density (meters per square meter)',\n",
    "    'StreetSegments': 'Number of individual street segments',\n",
    "    'LandUse_Diversity': 'Number of different land use types',\n",
    "    'LandUse_Area': 'Total area covered by land use polygons (square meters)'\n",
    "}\n",
    "\n",
    "# Categorize features\n",
    "feature_categories_custom = {\n",
    "    'Economic': ['AvgPrice'],\n",
    "    'Transport_Accessibility': ['MEAN_PTAL_2023', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m'],\n",
    "    'Demographics': ['Population'],\n",
    "    'Geographic': ['Area_km2'],\n",
    "    'Social': ['MeanSentiment', 'SentimentSD', 'ReviewCount'],\n",
    "    'Urban_Form': ['StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Area']\n",
    "}\n",
    "\n",
    "# Build documentation\n",
    "feature_cols_custom = [col for col in gcn_feature_matrix_custom.columns if col != 'LSOA_CODE']\n",
    "for feature in feature_cols_custom:\n",
    "    feature_info_custom['Feature_Name'].append(feature)\n",
    "    feature_info_custom['Data_Type'].append('float64 (standardized)')\n",
    "    feature_info_custom['Description'].append(feature_descriptions_detailed.get(feature, 'Feature description'))\n",
    "    \n",
    "    # Determine category\n",
    "    category = 'Other'\n",
    "    for cat, cat_features in feature_categories_custom.items():\n",
    "        if feature in cat_features:\n",
    "            category = cat\n",
    "            break\n",
    "    feature_info_custom['Category'].append(category)\n",
    "    \n",
    "    # Check original missing values\n",
    "    original_missing = df_combined[feature].isnull().sum() if feature in df_combined.columns else 0\n",
    "    feature_info_custom['Missing_Before_Imputation'].append(original_missing)\n",
    "    feature_info_custom['Imputation_Method'].append('Median' if original_missing > 0 else 'None')\n",
    "\n",
    "# Save custom feature documentation\n",
    "feature_doc_custom_df = pd.DataFrame(feature_info_custom)\n",
    "doc_file_custom = os.path.join(output_dir, 'gcn_feature_matrix_custom_documentation.csv')\n",
    "feature_doc_custom_df.to_csv(doc_file_custom, index=False)\n",
    "print(f\"✅ Custom feature documentation saved to: {doc_file_custom}\")\n",
    "\n",
    "# Save summary statistics\n",
    "summary_file_custom = os.path.join(output_dir, 'gcn_feature_matrix_custom_summary_stats.csv')\n",
    "summary_stats_custom = gcn_feature_matrix_custom[feature_cols_custom].describe()\n",
    "summary_stats_custom.to_csv(summary_file_custom)\n",
    "print(f\"✅ Custom summary statistics saved to: {summary_file_custom}\")\n",
    "\n",
    "print(f\"\\n📁 CUSTOM GCN FILES SAVED TO: {output_dir}\")\n",
    "print(f\"   1. gcn_feature_matrix_custom.csv - Main custom feature matrix\")\n",
    "print(f\"   2. gcn_feature_matrix_custom_with_geometry.csv - With spatial geometry\")\n",
    "print(f\"   3. gcn_feature_matrix_custom_documentation.csv - Feature descriptions\")\n",
    "print(f\"   4. gcn_feature_matrix_custom_summary_stats.csv - Statistical summaries\")\n",
    "\n",
    "# Verification\n",
    "print(f\"\\n🔍 VERIFICATION:\")\n",
    "custom_files = [\n",
    "    'gcn_feature_matrix_custom.csv',\n",
    "    'gcn_feature_matrix_custom_with_geometry.csv',\n",
    "    'gcn_feature_matrix_custom_documentation.csv',\n",
    "    'gcn_feature_matrix_custom_summary_stats.csv'\n",
    "]\n",
    "\n",
    "for filename in custom_files:\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size_mb = os.path.getsize(filepath) / (1024 * 1024)\n",
    "        print(f\"   ✅ {filename} ({size_mb:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"   ❌ {filename} - Not found!\")\n",
    "\n",
    "print(f\"\\n🎉 CUSTOM GCN FEATURE MATRIX SUCCESSFULLY CREATED AND SAVED!\")\n",
    "print(f\"\\n📊 FINAL SUMMARY:\")\n",
    "print(f\"   • Selected Features: {len(feature_cols_custom)}\")\n",
    "print(f\"   • Total LSOAs: {len(gcn_feature_matrix_custom):,}\")\n",
    "print(f\"   • Data Completeness: 100% (after imputation)\")\n",
    "print(f\"   • Standardization: Applied (mean≈0, std≈1)\")\n",
    "print(f\"   • Ready for GCN: Yes\")\n",
    "\n",
    "print(f\"\\n📝 FEATURE LIST:\")\n",
    "for i, feature in enumerate(feature_cols_custom, 1):\n",
    "    category = 'Other'\n",
    "    for cat, cat_features in feature_categories_custom.items():\n",
    "        if feature in cat_features:\n",
    "            category = cat\n",
    "            break\n",
    "    print(f\"   {i:2d}. {feature} ({category})\")\n",
    "\n",
    "print(f\"\\n💻 USAGE:\")\n",
    "print(f\"   import pandas as pd\")\n",
    "print(f\"   gcn_data = pd.read_csv('{output_file_custom}')\")\n",
    "print(f\"   # Features ready for GCN model input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ba4442",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# 3. Comprehensive Input Data Check\n",
    "# ---------------------------------\n",
    "\n",
    "# Dictionary of all loaded datasets for easy iteration\n",
    "datasets = {\n",
    "    \"Merged Tabular Data (df_tab)\": df_tab,\n",
    "    \"LSOA Polygons (lsoa_gdf)\": lsoa_gdf,\n",
    "    \"Street Network (street_gdf)\": street_gdf,\n",
    "    \"Stations (station_gdf)\": station_gdf,\n",
    "    \"Land Use (landuse_gdf)\": landuse_gdf,\n",
    "    \"Rail Network (rail_gdf)\": rail_gdf\n",
    "}\n",
    "\n",
    "# Loop through and print a summary of each dataset\n",
    "for name, data in datasets.items():\n",
    "    print(f\"--- Checking: {name} ---\\n\")\n",
    "    \n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        print(f\"Shape: {data.shape}\")\n",
    "        print(f\"Columns: {data.columns.tolist()}\")\n",
    "        \n",
    "        # Check for missing values\n",
    "        missing_values = data.isnull().sum().sum()\n",
    "        print(f\"Total Missing Values: {missing_values}\")\n",
    "        \n",
    "        # Display info for GeoDataFrames\n",
    "        if isinstance(data, gpd.GeoDataFrame):\n",
    "            print(f\"CRS: {data.crs}\")\n",
    "            print(f\"Geometry Type: {data.geom_type.unique()}\")\n",
    "        \n",
    "        print(\"\\nHead:\")\n",
    "        print(data.head())\n",
    "        \n",
    "    else:\n",
    "        print(f\"'{name}' is not a DataFrame or GeoDataFrame.\")\n",
    "        \n",
    "    print(\"\\n\" + \"=\"*50 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b6218190",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UPDATED LONDON DATASETS SUMMARY ===\n",
      "London Tabular Data (df_tab): (4719, 10)\n",
      "London LSOA Polygons (lsoa_gdf): (4719, 7)\n",
      "  - CRS: EPSG:27700\n",
      "  - Geometry Type: ['Polygon' 'MultiPolygon']\n",
      "London Street Network (street_gdf): (115305, 2)\n",
      "  - CRS: EPSG:27700\n",
      "  - Geometry Type: ['LineString']\n",
      "London Stations (station_gdf): (21002, 5)\n",
      "  - CRS: EPSG:27700\n",
      "  - Geometry Type: ['Point']\n",
      "London Land Use (landuse_gdf): (30775, 5)\n",
      "  - CRS: EPSG:27700\n",
      "  - Geometry Type: ['Polygon' 'MultiPolygon']\n",
      "London Rail Network (rail_gdf): (11777, 5)\n",
      "  - CRS: EPSG:27700\n",
      "  - Geometry Type: ['LineString']\n",
      "\n",
      "✓ All datasets now contain only London LSOA areas\n",
      "✓ Ready for spatial analysis and feature engineering\n"
     ]
    }
   ],
   "source": [
    "# Update datasets dictionary for London-only data\n",
    "print(\"=== UPDATED LONDON DATASETS SUMMARY ===\")\n",
    "\n",
    "# Updated dictionary of all London-only datasets\n",
    "london_datasets = {\n",
    "    \"London Tabular Data (df_tab)\": df_tab,\n",
    "    \"London LSOA Polygons (lsoa_gdf)\": lsoa_gdf,\n",
    "    \"London Street Network (street_gdf)\": street_gdf,\n",
    "    \"London Stations (station_gdf)\": station_gdf,\n",
    "    \"London Land Use (landuse_gdf)\": landuse_gdf,\n",
    "    \"London Rail Network (rail_gdf)\": rail_gdf\n",
    "}\n",
    "\n",
    "# Quick summary of each London dataset\n",
    "for name, data in london_datasets.items():\n",
    "    if isinstance(data, pd.DataFrame):\n",
    "        print(f\"{name}: {data.shape}\")\n",
    "        if isinstance(data, gpd.GeoDataFrame):\n",
    "            print(f\"  - CRS: {data.crs}\")\n",
    "            print(f\"  - Geometry Type: {data.geom_type.unique()}\")\n",
    "    else:\n",
    "        print(f\"{name}: Not a DataFrame\")\n",
    "\n",
    "print(f\"\\n✓ All datasets now contain only London LSOA areas\")\n",
    "print(f\"✓ Ready for spatial analysis and feature engineering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "7f02dfb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Starting spatial correlation-based imputation for custom GCN feature matrix...\n",
      "\n",
      "📊 Features with missing values in custom GCN matrix:\n",
      "  - Area_km2: 4719 missing (100.0%)\n",
      "\n",
      "🔧 Applying spatial correlation-based imputation to 1 features...\n",
      "\n",
      "  🎯 Processing feature: Area_km2\n",
      "    - Missing values: 4719\n",
      "    - Imputation methods used: {'median_fallback': np.int64(4719)}\n",
      "    - Mean imputed value: nan\n",
      "\n",
      "✅ Spatial imputation completed!\n",
      "📊 Remaining missing values after spatial imputation: 4719\n",
      "⚠️  Some missing values remain. Details:\n",
      "  - Area_km2: 4719 missing\n",
      "\n",
      "📈 Imputation summary:\n",
      "  Area_km2:\n",
      "    - Imputed: 4719 values (100.0% of data)\n",
      "    - Methods: {'median_fallback': 4719}\n",
      "    - Mean imputed: nan\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# SPATIAL CORRELATION-BASED IMPUTATION FOR CUSTOM GCN FEATURE MATRIX\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🔧 Starting spatial correlation-based imputation for custom GCN feature matrix...\")\n",
    "\n",
    "# First, let's check which features have missing values in our custom matrix\n",
    "missing_in_custom = gcn_custom.isnull().sum()\n",
    "features_with_missing = missing_in_custom[missing_in_custom > 0]\n",
    "\n",
    "print(f\"\\n📊 Features with missing values in custom GCN matrix:\")\n",
    "for feature, count in features_with_missing.items():\n",
    "    pct = (count / len(gcn_custom)) * 100\n",
    "    print(f\"  - {feature}: {count} missing ({pct:.1f}%)\")\n",
    "\n",
    "if len(features_with_missing) == 0:\n",
    "    print(\"✅ No missing values found in custom GCN matrix!\")\n",
    "    gcn_custom_spatial_imputed = gcn_custom.copy()\n",
    "else:\n",
    "    print(f\"\\n🔧 Applying spatial correlation-based imputation to {len(features_with_missing)} features...\")\n",
    "    \n",
    "    # Create a copy of the custom matrix for spatial imputation\n",
    "    gcn_custom_spatial_imputed = gcn_custom.copy()\n",
    "    \n",
    "    # Get the spatial data (LSOA polygons) and merge with our data\n",
    "    spatial_data = lsoa_gdf[['code', 'geometry']].copy()\n",
    "    \n",
    "    # Merge spatial data with our feature matrix\n",
    "    gcn_with_geometry = pd.merge(gcn_custom_spatial_imputed, \n",
    "                                spatial_data, \n",
    "                                left_on='LSOA_CODE', \n",
    "                                right_on='code', \n",
    "                                how='left')\n",
    "    gcn_with_geometry = gpd.GeoDataFrame(gcn_with_geometry, geometry='geometry')\n",
    "    \n",
    "    # For each feature with missing values, perform spatial imputation\n",
    "    imputation_results = {}\n",
    "    \n",
    "    for feature in features_with_missing.index:\n",
    "        print(f\"\\n  🎯 Processing feature: {feature}\")\n",
    "        \n",
    "        # Get indices of missing values\n",
    "        missing_mask = gcn_with_geometry[feature].isnull()\n",
    "        missing_indices = gcn_with_geometry[missing_mask].index\n",
    "        \n",
    "        print(f\"    - Missing values: {missing_mask.sum()}\")\n",
    "        \n",
    "        if missing_mask.sum() > 0:\n",
    "            # For each missing value, find spatial neighbors and impute\n",
    "            imputed_values = []\n",
    "            methods_used = []\n",
    "            \n",
    "            for idx in missing_indices:\n",
    "                missing_geometry = gcn_with_geometry.loc[idx, 'geometry']\n",
    "                \n",
    "                if missing_geometry is None or pd.isna(missing_geometry):\n",
    "                    # If no geometry, use median\n",
    "                    fill_value = gcn_with_geometry[feature].median()\n",
    "                    method_used = 'median_fallback'\n",
    "                else:\n",
    "                    # Find spatial neighbors using different distance thresholds\n",
    "                    distances = [500, 1000, 2000, 5000]  # meters\n",
    "                    fill_value = None\n",
    "                    method_used = 'median_fallback'\n",
    "                    \n",
    "                    for distance in distances:\n",
    "                        # Create buffer around missing point\n",
    "                        buffer = missing_geometry.buffer(distance)\n",
    "                        \n",
    "                        # Find LSOAs that intersect with the buffer\n",
    "                        intersecting = gcn_with_geometry[gcn_with_geometry.geometry.intersects(buffer)]\n",
    "                        \n",
    "                        # Get non-missing values for this feature in neighboring areas\n",
    "                        neighbor_values = intersecting[feature].dropna()\n",
    "                        \n",
    "                        # Remove the current point itself\n",
    "                        neighbor_values = neighbor_values[neighbor_values.index != idx]\n",
    "                        \n",
    "                        if len(neighbor_values) >= 3:  # Need at least 3 neighbors\n",
    "                            # Use distance-weighted average\n",
    "                            weights = []\n",
    "                            values = []\n",
    "                            \n",
    "                            for neighbor_idx in neighbor_values.index:\n",
    "                                neighbor_geom = gcn_with_geometry.loc[neighbor_idx, 'geometry']\n",
    "                                if neighbor_geom is not None:\n",
    "                                    dist = missing_geometry.distance(neighbor_geom)\n",
    "                                    if dist > 0:  # Avoid division by zero\n",
    "                                        weight = 1 / (dist + 1)  # Add 1 to avoid infinite weights\n",
    "                                        weights.append(weight)\n",
    "                                        values.append(neighbor_values.loc[neighbor_idx])\n",
    "                            \n",
    "                            if len(values) > 0:\n",
    "                                weights = np.array(weights)\n",
    "                                values = np.array(values)\n",
    "                                fill_value = np.average(values, weights=weights)\n",
    "                                method_used = f'spatial_weighted_{distance}m'\n",
    "                                break\n",
    "                        elif len(neighbor_values) >= 1:\n",
    "                            # Use simple average if we have some neighbors\n",
    "                            fill_value = neighbor_values.mean()\n",
    "                            method_used = f'spatial_mean_{distance}m'\n",
    "                            break\n",
    "                    \n",
    "                    # If no spatial neighbors found, use median\n",
    "                    if fill_value is None:\n",
    "                        fill_value = gcn_with_geometry[feature].median()\n",
    "                        method_used = 'median_fallback'\n",
    "                \n",
    "                imputed_values.append(fill_value)\n",
    "                methods_used.append(method_used)\n",
    "            \n",
    "            # Apply the imputed values\n",
    "            gcn_custom_spatial_imputed.loc[gcn_custom_spatial_imputed[feature].isnull(), feature] = imputed_values\n",
    "            \n",
    "            # Store results\n",
    "            method_counts = pd.Series(methods_used).value_counts()\n",
    "            imputation_results[feature] = {\n",
    "                'total_imputed': len(imputed_values),\n",
    "                'methods': method_counts.to_dict(),\n",
    "                'mean_imputed_value': np.mean(imputed_values),\n",
    "                'original_missing_pct': (missing_mask.sum() / len(gcn_with_geometry)) * 100\n",
    "            }\n",
    "            \n",
    "            print(f\"    - Imputation methods used: {dict(method_counts)}\")\n",
    "            print(f\"    - Mean imputed value: {np.mean(imputed_values):.4f}\")\n",
    "\n",
    "print(f\"\\n✅ Spatial imputation completed!\")\n",
    "\n",
    "# Verify that all missing values have been filled\n",
    "remaining_missing = gcn_custom_spatial_imputed.isnull().sum().sum()\n",
    "print(f\"📊 Remaining missing values after spatial imputation: {remaining_missing}\")\n",
    "\n",
    "if remaining_missing > 0:\n",
    "    print(\"⚠️  Some missing values remain. Details:\")\n",
    "    remaining_missing_by_feature = gcn_custom_spatial_imputed.isnull().sum()\n",
    "    for feature, count in remaining_missing_by_feature[remaining_missing_by_feature > 0].items():\n",
    "        print(f\"  - {feature}: {count} missing\")\n",
    "\n",
    "print(f\"\\n📈 Imputation summary:\")\n",
    "for feature, results in imputation_results.items():\n",
    "    print(f\"  {feature}:\")\n",
    "    print(f\"    - Imputed: {results['total_imputed']} values ({results['original_missing_pct']:.1f}% of data)\")\n",
    "    print(f\"    - Methods: {results['methods']}\")\n",
    "    print(f\"    - Mean imputed: {results['mean_imputed_value']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "446591d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Checking lsoa_gdf structure...\n",
      "Columns in lsoa_gdf: ['geometry', 'code', 'name', 'label', 'Area', 'Half densi', 'Area2']\n",
      "Shape: (4719, 7)\n",
      "Sample of first few rows:\n",
      "                                            geometry       code  \\\n",
      "0  POLYGON ((551549.998 187364.637, 551528.633 18...  E01000037   \n",
      "1  POLYGON ((544812 174524, 544819.775 174523.378...  E01033729   \n",
      "2  POLYGON ((550920.362 187341.138, 550921.876 18...  E01000038   \n",
      "3  POLYGON ((537938 177696, 537941.714 177678.043...  E01033730   \n",
      "4  POLYGON ((551431.061 186927.155, 551444.481 18...  E01000039   \n",
      "\n",
      "                        name                        label     Area  \\\n",
      "0  Barking and Dagenham 003B  E09000002E02000004E01000037   233488   \n",
      "1             Greenwich 030E  E09000011E02000342E01033729   691074   \n",
      "2  Barking and Dagenham 003C  E09000002E02000004E01000038   214094   \n",
      "3             Greenwich 035D  E09000011E02006928E01033730   187153   \n",
      "4  Barking and Dagenham 003D  E09000002E02000004E01000039  1532166   \n",
      "\n",
      "   Half densi    Area2  \n",
      "0        3764   233488  \n",
      "1        2034   691074  \n",
      "2        3519   214094  \n",
      "3        4950   187153  \n",
      "4         530  1532166  \n"
     ]
    }
   ],
   "source": [
    "# Check the structure of lsoa_gdf to find correct column names\n",
    "print(\"🔍 Checking lsoa_gdf structure...\")\n",
    "print(f\"Columns in lsoa_gdf: {list(lsoa_gdf.columns)}\")\n",
    "print(f\"Shape: {lsoa_gdf.shape}\")\n",
    "print(f\"Sample of first few rows:\")\n",
    "print(lsoa_gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "18c9bdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔍 Checking gcn_custom structure...\n",
      "Index name: None\n",
      "Columns: ['LSOA_CODE', 'AvgPrice', 'MEAN_PTAL_2023', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Area']\n",
      "Shape: (4719, 16)\n",
      "Index sample: [0, 1, 2, 3, 4]\n",
      "Sample of first few rows:\n",
      "   LSOA_CODE  AvgPrice  MEAN_PTAL_2023  Population  Area_km2  MeanSentiment  \\\n",
      "0  E01000001  837500.0             3.0      1615.0       NaN         0.4270   \n",
      "1  E01000002  850000.0             3.0      1493.0       NaN         0.5240   \n",
      "2  E01000003  540000.0             3.0      1573.0       NaN         0.3170   \n",
      "3  E01000005  530000.0             3.0      1090.0       NaN         0.6750   \n",
      "4  E01000006  241000.0             5.0      1612.0       NaN         0.6075   \n",
      "\n",
      "   SentimentSD  ReviewCount  NearestStation_m  StationsWithin500m  \\\n",
      "0        0.312       1505.0         37.204758                  29   \n",
      "1        0.188       5819.0        195.176808                  30   \n",
      "2        0.127          3.0        120.977313                  28   \n",
      "3        0.100       1067.0         51.625449                  35   \n",
      "4        0.127         77.0        387.054639                  10   \n",
      "\n",
      "   NearestRail_m  StreetLength_m  StreetDensity_m_per_m2  StreetSegments  \\\n",
      "0     224.638155     2099.098049                0.016164              43   \n",
      "1     144.061157     3258.516395                0.014266              55   \n",
      "2     189.829128      578.878566                0.009803              11   \n",
      "3      26.831724     3449.617678                0.018196              70   \n",
      "4     153.355797     2332.482543                0.015917              26   \n",
      "\n",
      "   LandUse_Diversity   LandUse_Area  \n",
      "0                  4   38011.199255  \n",
      "1                  5   88486.284243  \n",
      "2                  3   28201.764815  \n",
      "3                  4  128388.326345  \n",
      "4                  1  118840.250570  \n"
     ]
    }
   ],
   "source": [
    "# Check the structure of gcn_custom\n",
    "print(\"\\n🔍 Checking gcn_custom structure...\")\n",
    "print(f\"Index name: {gcn_custom.index.name}\")\n",
    "print(f\"Columns: {list(gcn_custom.columns)}\")\n",
    "print(f\"Shape: {gcn_custom.shape}\")\n",
    "print(f\"Index sample: {gcn_custom.index[:5].tolist()}\")\n",
    "print(f\"Sample of first few rows:\")\n",
    "print(gcn_custom.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "30ae13d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Fixing Area_km2 feature using spatial geometry...\n",
      "Available area-related columns in lsoa_gdf:\n",
      "  - Area: count    4.719000e+03\n",
      "mean     2.883627e+05\n",
      "std      3.892889e+05\n",
      "min      1.836900e+04\n",
      "25%      1.342505e+05\n",
      "50%      2.021800e+05\n",
      "75%      3.110385e+05\n",
      "max      9.936120e+06\n",
      "Name: Area, dtype: float64\n",
      "  - Area2: count       4719\n",
      "unique      4686\n",
      "top       237761\n",
      "freq           2\n",
      "Name: Area2, dtype: object\n",
      "\n",
      "Using 'Area' column from spatial data...\n",
      "Area statistics (km2):\n",
      "count    4719.000000\n",
      "mean        0.288363\n",
      "std         0.389289\n",
      "min         0.018369\n",
      "25%         0.134250\n",
      "50%         0.202180\n",
      "75%         0.311038\n",
      "max         9.936120\n",
      "Name: Area, dtype: float64\n",
      "\n",
      "Updating Area_km2 in gcn_custom_spatial_imputed...\n",
      "Missing values in Area_km2 after fix: 0\n",
      "\n",
      "Final missing values in Area_km2: 0\n",
      "Area_km2 statistics after fix:\n",
      "count    4719.000000\n",
      "mean        0.288363\n",
      "std         0.389289\n",
      "min         0.018369\n",
      "25%         0.134250\n",
      "50%         0.202180\n",
      "75%         0.311038\n",
      "max         9.936120\n",
      "Name: Area_km2, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FIX AREA_KM2 FEATURE USING SPATIAL DATA\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🔧 Fixing Area_km2 feature using spatial geometry...\")\n",
    "\n",
    "# Check the area columns in lsoa_gdf\n",
    "print(\"Available area-related columns in lsoa_gdf:\")\n",
    "for col in lsoa_gdf.columns:\n",
    "    if 'area' in col.lower() or 'Area' in col:\n",
    "        print(f\"  - {col}: {lsoa_gdf[col].describe()}\")\n",
    "\n",
    "# Let's use the existing 'Area' column and convert to km2\n",
    "# Assuming the 'Area' column is in square meters\n",
    "print(f\"\\nUsing 'Area' column from spatial data...\")\n",
    "\n",
    "# Create a mapping from LSOA code to area in km2\n",
    "area_mapping = lsoa_gdf.set_index('code')['Area'] / 1000000  # Convert m2 to km2\n",
    "\n",
    "print(f\"Area statistics (km2):\")\n",
    "print(area_mapping.describe())\n",
    "\n",
    "# Update the Area_km2 column in gcn_custom_spatial_imputed\n",
    "print(f\"\\nUpdating Area_km2 in gcn_custom_spatial_imputed...\")\n",
    "gcn_custom_spatial_imputed['Area_km2'] = gcn_custom_spatial_imputed['LSOA_CODE'].map(area_mapping)\n",
    "\n",
    "# Check if this fixed the missing values\n",
    "area_missing_after = gcn_custom_spatial_imputed['Area_km2'].isnull().sum()\n",
    "print(f\"Missing values in Area_km2 after fix: {area_missing_after}\")\n",
    "\n",
    "if area_missing_after > 0:\n",
    "    print(\"Some areas are still missing. Using geometry to calculate area...\")\n",
    "    \n",
    "    # For remaining missing values, calculate from geometry\n",
    "    missing_mask = gcn_custom_spatial_imputed['Area_km2'].isnull()\n",
    "    \n",
    "    if missing_mask.sum() > 0:\n",
    "        # Merge with geometry for missing areas\n",
    "        missing_codes = gcn_custom_spatial_imputed.loc[missing_mask, 'LSOA_CODE']\n",
    "        \n",
    "        for lsoa_code in missing_codes:\n",
    "            geom = lsoa_gdf[lsoa_gdf['code'] == lsoa_code]['geometry']\n",
    "            if not geom.empty:\n",
    "                area_m2 = geom.iloc[0].area\n",
    "                area_km2 = area_m2 / 1000000\n",
    "                gcn_custom_spatial_imputed.loc[gcn_custom_spatial_imputed['LSOA_CODE'] == lsoa_code, 'Area_km2'] = area_km2\n",
    "\n",
    "# Final check\n",
    "final_missing = gcn_custom_spatial_imputed['Area_km2'].isnull().sum()\n",
    "print(f\"\\nFinal missing values in Area_km2: {final_missing}\")\n",
    "print(f\"Area_km2 statistics after fix:\")\n",
    "print(gcn_custom_spatial_imputed['Area_km2'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "2c867ad9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Final check for missing values in custom GCN matrix...\n",
      "✅ No missing values found! All features are complete.\n",
      "\n",
      "✅ Spatial imputation completed!\n",
      "📊 Total remaining missing values: 0\n",
      "🎉 All missing values have been successfully imputed!\n",
      "\n",
      "📊 Final dataset shape: (4719, 16)\n",
      "📊 Final dataset info:\n",
      "LSOA_CODE                  object\n",
      "AvgPrice                  float64\n",
      "MEAN_PTAL_2023            float64\n",
      "Population                float64\n",
      "Area_km2                  float64\n",
      "MeanSentiment             float64\n",
      "SentimentSD               float64\n",
      "ReviewCount               float64\n",
      "NearestStation_m          float64\n",
      "StationsWithin500m          int64\n",
      "NearestRail_m             float64\n",
      "StreetLength_m            float64\n",
      "StreetDensity_m_per_m2    float64\n",
      "StreetSegments              int64\n",
      "LandUse_Diversity           int64\n",
      "LandUse_Area              float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL CHECK AND SPATIAL IMPUTATION FOR ANY REMAINING MISSING VALUES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🔍 Final check for missing values in custom GCN matrix...\")\n",
    "\n",
    "# Check for missing values in all features\n",
    "missing_summary = gcn_custom_spatial_imputed.isnull().sum()\n",
    "features_with_missing = missing_summary[missing_summary > 0]\n",
    "\n",
    "if len(features_with_missing) == 0:\n",
    "    print(\"✅ No missing values found! All features are complete.\")\n",
    "else:\n",
    "    print(f\"📊 Features still with missing values:\")\n",
    "    for feature, count in features_with_missing.items():\n",
    "        pct = (count / len(gcn_custom_spatial_imputed)) * 100\n",
    "        print(f\"  - {feature}: {count} missing ({pct:.1f}%)\")\n",
    "    \n",
    "    print(f\"\\n🔧 Applying spatial imputation to remaining {len(features_with_missing)} features...\")\n",
    "    \n",
    "    # Apply spatial imputation for any remaining missing values\n",
    "    # Merge with spatial data for spatial operations\n",
    "    gcn_with_geometry = pd.merge(gcn_custom_spatial_imputed, \n",
    "                                lsoa_gdf[['code', 'geometry']], \n",
    "                                left_on='LSOA_CODE', \n",
    "                                right_on='code', \n",
    "                                how='left')\n",
    "    gcn_with_geometry = gpd.GeoDataFrame(gcn_with_geometry, geometry='geometry')\n",
    "    \n",
    "    spatial_imputation_results = {}\n",
    "    \n",
    "    for feature in features_with_missing.index:\n",
    "        if feature == 'LSOA_CODE':  # Skip the identifier column\n",
    "            continue\n",
    "            \n",
    "        print(f\"\\n  🎯 Processing feature: {feature}\")\n",
    "        \n",
    "        # Get indices of missing values\n",
    "        missing_mask = gcn_with_geometry[feature].isnull()\n",
    "        missing_indices = gcn_with_geometry[missing_mask].index\n",
    "        \n",
    "        print(f\"    - Missing values: {missing_mask.sum()}\")\n",
    "        \n",
    "        if missing_mask.sum() > 0:\n",
    "            imputed_values = []\n",
    "            methods_used = []\n",
    "            \n",
    "            for idx in missing_indices:\n",
    "                missing_geometry = gcn_with_geometry.loc[idx, 'geometry']\n",
    "                \n",
    "                if missing_geometry is None or pd.isna(missing_geometry):\n",
    "                    # If no geometry, use median of non-missing values\n",
    "                    fill_value = gcn_with_geometry[feature].median()\n",
    "                    method_used = 'median_fallback'\n",
    "                else:\n",
    "                    # Find spatial neighbors using different distance thresholds\n",
    "                    distances = [500, 1000, 2000, 5000, 10000]  # meters\n",
    "                    fill_value = None\n",
    "                    method_used = 'median_fallback'\n",
    "                    \n",
    "                    for distance in distances:\n",
    "                        # Create buffer around missing point\n",
    "                        buffer = missing_geometry.buffer(distance)\n",
    "                        \n",
    "                        # Find LSOAs that intersect with the buffer\n",
    "                        intersecting = gcn_with_geometry[gcn_with_geometry.geometry.intersects(buffer)]\n",
    "                        \n",
    "                        # Get non-missing values for this feature in neighboring areas\n",
    "                        neighbor_values = intersecting[feature].dropna()\n",
    "                        \n",
    "                        # Remove the current point itself\n",
    "                        neighbor_values = neighbor_values[neighbor_values.index != idx]\n",
    "                        \n",
    "                        if len(neighbor_values) >= 3:  # Need at least 3 neighbors\n",
    "                            # Use distance-weighted average\n",
    "                            weights = []\n",
    "                            values = []\n",
    "                            \n",
    "                            for neighbor_idx in neighbor_values.index:\n",
    "                                neighbor_geom = gcn_with_geometry.loc[neighbor_idx, 'geometry']\n",
    "                                if neighbor_geom is not None:\n",
    "                                    dist = missing_geometry.distance(neighbor_geom)\n",
    "                                    if dist > 0:  # Avoid division by zero\n",
    "                                        weight = 1 / (dist + 100)  # Add 100 to reduce weight variation\n",
    "                                        weights.append(weight)\n",
    "                                        values.append(neighbor_values.loc[neighbor_idx])\n",
    "                            \n",
    "                            if len(values) > 0:\n",
    "                                weights = np.array(weights)\n",
    "                                values = np.array(values)\n",
    "                                fill_value = np.average(values, weights=weights)\n",
    "                                method_used = f'spatial_weighted_{distance}m'\n",
    "                                break\n",
    "                        elif len(neighbor_values) >= 1:\n",
    "                            # Use simple average if we have some neighbors\n",
    "                            fill_value = neighbor_values.mean()\n",
    "                            method_used = f'spatial_mean_{distance}m'\n",
    "                            break\n",
    "                    \n",
    "                    # If no spatial neighbors found, use median\n",
    "                    if fill_value is None or np.isnan(fill_value):\n",
    "                        fill_value = gcn_with_geometry[feature].median()\n",
    "                        method_used = 'median_fallback'\n",
    "                \n",
    "                imputed_values.append(fill_value)\n",
    "                methods_used.append(method_used)\n",
    "            \n",
    "            # Apply the imputed values\n",
    "            gcn_custom_spatial_imputed.loc[gcn_custom_spatial_imputed[feature].isnull(), feature] = imputed_values\n",
    "            \n",
    "            # Store results\n",
    "            method_counts = pd.Series(methods_used).value_counts()\n",
    "            spatial_imputation_results[feature] = {\n",
    "                'total_imputed': len(imputed_values),\n",
    "                'methods': method_counts.to_dict(),\n",
    "                'mean_imputed_value': np.mean(imputed_values),\n",
    "                'original_missing_pct': (missing_mask.sum() / len(gcn_with_geometry)) * 100\n",
    "            }\n",
    "            \n",
    "            print(f\"    - Imputation methods used: {dict(method_counts)}\")\n",
    "            print(f\"    - Mean imputed value: {np.mean(imputed_values):.4f}\")\n",
    "\n",
    "# Final verification\n",
    "final_missing = gcn_custom_spatial_imputed.isnull().sum().sum()\n",
    "print(f\"\\n✅ Spatial imputation completed!\")\n",
    "print(f\"📊 Total remaining missing values: {final_missing}\")\n",
    "\n",
    "if final_missing > 0:\n",
    "    print(\"⚠️  Some missing values remain:\")\n",
    "    remaining = gcn_custom_spatial_imputed.isnull().sum()\n",
    "    for feature, count in remaining[remaining > 0].items():\n",
    "        print(f\"  - {feature}: {count} missing\")\n",
    "else:\n",
    "    print(\"🎉 All missing values have been successfully imputed!\")\n",
    "\n",
    "print(f\"\\n📊 Final dataset shape: {gcn_custom_spatial_imputed.shape}\")\n",
    "print(f\"📊 Final dataset info:\")\n",
    "print(gcn_custom_spatial_imputed.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "f037e14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Standardizing spatially-imputed features...\n",
      "✅ Standardization completed!\n",
      "📊 Standardized feature statistics:\n",
      "           AvgPrice  MEAN_PTAL_2023    Population      Area_km2  \\\n",
      "count  4.719000e+03    4.719000e+03  4.719000e+03  4.719000e+03   \n",
      "mean   1.144337e-16    9.636519e-17  5.149515e-16  1.204565e-17   \n",
      "std    1.000106e+00    1.000106e+00  1.000106e+00  1.000106e+00   \n",
      "min   -1.161581e+00   -1.109434e+00 -6.525909e+00 -6.936297e-01   \n",
      "25%   -4.890309e-01   -1.109434e+00 -2.499702e-01 -3.959233e-01   \n",
      "50%   -2.409056e-01    1.058443e-01  6.037845e-02 -2.214084e-01   \n",
      "75%    1.371589e-01    1.058443e-01  3.577959e-01  5.825543e-02   \n",
      "max    1.561299e+01    2.536401e+00  1.937958e+01  2.478565e+01   \n",
      "\n",
      "       MeanSentiment   SentimentSD   ReviewCount  NearestStation_m  \\\n",
      "count   4.719000e+03  4.719000e+03  4.719000e+03      4.719000e+03   \n",
      "mean   -8.842259e-16  3.199626e-17  3.011412e-18      2.107989e-16   \n",
      "std     1.000106e+00  1.000106e+00  1.000106e+00      1.000106e+00   \n",
      "min    -5.061611e+00 -1.916535e+00 -1.028478e-01     -1.551074e+00   \n",
      "25%    -1.788546e-02 -1.611503e-01 -9.689534e-02     -7.001013e-01   \n",
      "50%     1.141716e-01 -1.611503e-01 -9.491118e-02     -1.655972e-01   \n",
      "75%     2.377088e-01 -1.611503e-01 -9.156945e-02      4.555854e-01   \n",
      "max     3.304839e+00  6.321332e+00  4.418620e+01      8.275955e+00   \n",
      "\n",
      "       StationsWithin500m  NearestRail_m  StreetLength_m  \\\n",
      "count        4.719000e+03   4.719000e+03    4.719000e+03   \n",
      "mean        -6.022825e-17  -4.818260e-17    1.806847e-16   \n",
      "std          1.000106e+00   1.000106e+00    1.000106e+00   \n",
      "min         -2.009234e+00  -1.243591e+00   -1.919367e+00   \n",
      "25%         -7.511745e-01  -6.965832e-01   -5.772423e-01   \n",
      "50%         -5.225253e-02  -2.548129e-01   -1.415846e-01   \n",
      "75%          6.466694e-01   4.091435e-01    3.921599e-01   \n",
      "max          6.098261e+00   8.730737e+00    1.962265e+01   \n",
      "\n",
      "       StreetDensity_m_per_m2  StreetSegments  LandUse_Diversity  LandUse_Area  \n",
      "count            4.719000e+03    4.719000e+03       4.719000e+03  4.719000e+03  \n",
      "mean             6.022825e-17    7.528531e-18       1.445478e-16  4.215977e-17  \n",
      "std              1.000106e+00    1.000106e+00       1.000106e+00  1.000106e+00  \n",
      "min             -2.527152e+00   -2.034934e+00      -1.983594e+00 -6.596514e-01  \n",
      "25%             -6.859315e-01   -5.966231e-01      -8.417118e-01 -3.708117e-01  \n",
      "50%             -6.486071e-02   -1.363637e-01      -2.707706e-01 -2.017019e-01  \n",
      "75%              6.331294e-01    3.814282e-01       3.001706e-01  6.627842e-02  \n",
      "max              4.731996e+00    2.615596e+01       4.867700e+00  2.226282e+01  \n",
      "\n",
      "📊 Standardization verification:\n",
      "  Mean of features (should be ~0): 0.000000\n",
      "  Std of features (should be ~1): 1.000106 to 1.000106\n",
      "\n",
      "💾 Saving spatially-imputed GCN matrices...\n",
      "✅ Saved spatially-imputed matrix: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_spatial_imputed.csv\n",
      "✅ Saved spatially-imputed & scaled matrix: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_spatial_imputed_scaled.csv\n",
      "✅ Saved spatial matrix with geometry: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_spatial_imputed_with_geometry.csv\n",
      "\n",
      "📊 Summary of saved files:\n",
      "  1. Spatially-imputed matrix: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_spatial_imputed.csv\n",
      "     - Shape: (4719, 16)\n",
      "     - Features: standardized=No, imputed=Yes\n",
      "  2. Spatially-imputed & scaled matrix: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_spatial_imputed_scaled.csv\n",
      "     - Shape: (4719, 16)\n",
      "     - Features: standardized=Yes, imputed=Yes\n",
      "  3. Spatial matrix with geometry: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_spatial_imputed_with_geometry.csv\n",
      "     - Shape: (4719, 17)\n",
      "     - Features: standardized=Yes, imputed=Yes, geometry=WKT\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# STANDARDIZE SPATIALLY-IMPUTED FEATURES AND SAVE FINAL GCN MATRIX\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🔧 Standardizing spatially-imputed features...\")\n",
    "\n",
    "# Separate identifier column from features\n",
    "feature_columns = [col for col in gcn_custom_spatial_imputed.columns if col != 'LSOA_CODE']\n",
    "identifier_column = gcn_custom_spatial_imputed[['LSOA_CODE']]\n",
    "\n",
    "# Standardize the features (mean=0, std=1)\n",
    "scaler_spatial = StandardScaler()\n",
    "features_scaled = scaler_spatial.fit_transform(gcn_custom_spatial_imputed[feature_columns])\n",
    "\n",
    "# Create the standardized dataframe\n",
    "gcn_custom_spatial_scaled = pd.DataFrame(\n",
    "    features_scaled, \n",
    "    columns=feature_columns,\n",
    "    index=gcn_custom_spatial_imputed.index\n",
    ")\n",
    "\n",
    "# Add back the identifier column\n",
    "gcn_custom_spatial_scaled = pd.concat([identifier_column, gcn_custom_spatial_scaled], axis=1)\n",
    "\n",
    "print(f\"✅ Standardization completed!\")\n",
    "print(f\"📊 Standardized feature statistics:\")\n",
    "print(gcn_custom_spatial_scaled[feature_columns].describe())\n",
    "\n",
    "# Verify standardization (should be close to mean=0, std=1)\n",
    "means = gcn_custom_spatial_scaled[feature_columns].mean()\n",
    "stds = gcn_custom_spatial_scaled[feature_columns].std()\n",
    "\n",
    "print(f\"\\n📊 Standardization verification:\")\n",
    "print(f\"  Mean of features (should be ~0): {means.abs().max():.6f}\")\n",
    "print(f\"  Std of features (should be ~1): {stds.min():.6f} to {stds.max():.6f}\")\n",
    "\n",
    "# =============================================================================\n",
    "# SAVE SPATIALLY-IMPUTED AND STANDARDIZED GCN MATRICES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n💾 Saving spatially-imputed GCN matrices...\")\n",
    "\n",
    "# Define output paths\n",
    "output_file_spatial_imputed = \"/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_spatial_imputed.csv\"\n",
    "output_file_spatial_scaled = \"/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_spatial_imputed_scaled.csv\"\n",
    "output_file_spatial_with_geometry = \"/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_custom_spatial_imputed_with_geometry.csv\"\n",
    "\n",
    "# Save the spatially-imputed (unscaled) matrix\n",
    "gcn_custom_spatial_imputed.to_csv(output_file_spatial_imputed, index=False)\n",
    "print(f\"✅ Saved spatially-imputed matrix: {output_file_spatial_imputed}\")\n",
    "\n",
    "# Save the spatially-imputed and scaled matrix\n",
    "gcn_custom_spatial_scaled.to_csv(output_file_spatial_scaled, index=False)\n",
    "print(f\"✅ Saved spatially-imputed & scaled matrix: {output_file_spatial_scaled}\")\n",
    "\n",
    "# Create and save matrix with geometry for spatial analysis\n",
    "gcn_spatial_with_geometry = pd.merge(\n",
    "    gcn_custom_spatial_scaled,\n",
    "    lsoa_gdf[['code', 'geometry']],\n",
    "    left_on='LSOA_CODE',\n",
    "    right_on='code',\n",
    "    how='left'\n",
    ").drop('code', axis=1)\n",
    "\n",
    "# Convert geometry to WKT for CSV export\n",
    "gcn_spatial_with_geometry['geometry_wkt'] = gcn_spatial_with_geometry['geometry'].apply(\n",
    "    lambda x: x.wkt if x is not None else None\n",
    ")\n",
    "gcn_spatial_export = gcn_spatial_with_geometry.drop('geometry', axis=1)\n",
    "gcn_spatial_export.to_csv(output_file_spatial_with_geometry, index=False)\n",
    "print(f\"✅ Saved spatial matrix with geometry: {output_file_spatial_with_geometry}\")\n",
    "\n",
    "print(f\"\\n📊 Summary of saved files:\")\n",
    "print(f\"  1. Spatially-imputed matrix: {output_file_spatial_imputed}\")\n",
    "print(f\"     - Shape: {gcn_custom_spatial_imputed.shape}\")\n",
    "print(f\"     - Features: standardized=No, imputed=Yes\")\n",
    "print(f\"  2. Spatially-imputed & scaled matrix: {output_file_spatial_scaled}\")\n",
    "print(f\"     - Shape: {gcn_custom_spatial_scaled.shape}\")\n",
    "print(f\"     - Features: standardized=Yes, imputed=Yes\") \n",
    "print(f\"  3. Spatial matrix with geometry: {output_file_spatial_with_geometry}\")\n",
    "print(f\"     - Shape: {gcn_spatial_export.shape}\")\n",
    "print(f\"     - Features: standardized=Yes, imputed=Yes, geometry=WKT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "d048a29f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📝 Generating documentation and summary statistics for spatially-imputed matrices...\n",
      "✅ Documentation and statistics saved:\n",
      "  📋 Documentation: /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_spatial_imputed_documentation.csv\n",
      "  📊 Summary stats (unscaled): /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_spatial_imputed_summary_stats.csv\n",
      "  📊 Summary stats (scaled): /Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_spatial_imputed_scaled_summary_stats.csv\n",
      "\n",
      "🎉 SPATIAL CORRELATION-BASED IMPUTATION COMPLETED!\n",
      "================================================================================\n",
      "📁 All generated files:\n",
      "\n",
      "🔧 CUSTOM GCN FEATURE MATRICES (Spatially Imputed):\n",
      "  1. gcn_feature_matrix_custom_spatial_imputed.csv\n",
      "     - Raw features with spatial imputation (no standardization)\n",
      "     - Shape: (4719, 16)\n",
      "     - Missing values: 0\n",
      "\n",
      "  2. gcn_feature_matrix_custom_spatial_imputed_scaled.csv\n",
      "     - Spatially imputed + standardized features (mean≈0, std≈1)\n",
      "     - Shape: (4719, 16)\n",
      "     - Missing values: 0\n",
      "\n",
      "  3. gcn_feature_matrix_custom_spatial_imputed_with_geometry.csv\n",
      "     - Spatially imputed + standardized + geometry (WKT format)\n",
      "     - Shape: (4719, 17)\n",
      "     - For spatial analysis and visualization\n",
      "\n",
      "📋 DOCUMENTATION:\n",
      "  4. gcn_feature_matrix_spatial_imputed_documentation.csv\n",
      "     - Complete feature documentation with imputation methods\n",
      "\n",
      "📊 SUMMARY STATISTICS:\n",
      "  5. gcn_feature_matrix_spatial_imputed_summary_stats.csv\n",
      "     - Statistical summary of unscaled spatially-imputed features\n",
      "\n",
      "  6. gcn_feature_matrix_spatial_imputed_scaled_summary_stats.csv\n",
      "     - Statistical summary of scaled spatially-imputed features\n",
      "\n",
      "🎯 RECOMMENDED FOR GCN:\n",
      "   Use: gcn_feature_matrix_custom_spatial_imputed_scaled.csv\n",
      "   - Complete (no missing values)\n",
      "   - Standardized (mean≈0, std≈1)\n",
      "   - Spatially-imputed using neighbor correlation\n",
      "   - Optimized feature set: 15 features\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# GENERATE DOCUMENTATION AND SUMMARY STATISTICS FOR SPATIAL MATRICES\n",
    "# =============================================================================\n",
    "\n",
    "print(\"📝 Generating documentation and summary statistics for spatially-imputed matrices...\")\n",
    "\n",
    "# Create documentation for the spatially-imputed features\n",
    "feature_documentation_spatial = {\n",
    "    'Feature_Name': [],\n",
    "    'Description': [],\n",
    "    'Data_Type': [],\n",
    "    'Unit': [],\n",
    "    'Source': [],\n",
    "    'Processing': [],\n",
    "    'Missing_Values_Handled': [],\n",
    "    'Standardized': []\n",
    "}\n",
    "\n",
    "# Feature descriptions and metadata\n",
    "feature_info_spatial = {\n",
    "    'LSOA_CODE': {\n",
    "        'description': 'Lower Layer Super Output Area unique identifier',\n",
    "        'unit': 'Categorical',\n",
    "        'source': 'ONS LSOA boundaries',\n",
    "        'processing': 'No processing - identifier field',\n",
    "        'missing_handled': 'None (identifier)',\n",
    "        'standardized': 'No'\n",
    "    },\n",
    "    'AvgPrice': {\n",
    "        'description': 'Average housing price in the LSOA',\n",
    "        'unit': 'British Pounds (£)',\n",
    "        'source': 'HM Land Registry',\n",
    "        'processing': 'Averaged by LSOA, spatial imputation applied',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'MEAN_PTAL_2023': {\n",
    "        'description': 'Public Transport Accessibility Level (PTAL) mean score',\n",
    "        'unit': 'Score (0-6, higher = better access)',\n",
    "        'source': 'Transport for London',\n",
    "        'processing': 'Mean PTAL score by LSOA, spatial imputation applied',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'Population': {\n",
    "        'description': 'Total population count in the LSOA',\n",
    "        'unit': 'Number of people',\n",
    "        'source': 'ONS Census/Population estimates',\n",
    "        'processing': 'Population count by LSOA, spatial imputation applied',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'Area_km2': {\n",
    "        'description': 'Area of the LSOA in square kilometers',\n",
    "        'unit': 'Square kilometers (km²)',\n",
    "        'source': 'ONS LSOA boundaries',\n",
    "        'processing': 'Calculated from polygon geometry, converted m² to km²',\n",
    "        'missing_handled': 'Calculated from spatial geometry',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'MeanSentiment': {\n",
    "        'description': 'Mean sentiment score from social media/reviews',\n",
    "        'unit': 'Sentiment score (-1 to 1, higher = more positive)',\n",
    "        'source': 'Social media sentiment analysis',\n",
    "        'processing': 'Mean sentiment by LSOA, spatial imputation applied',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'SentimentSD': {\n",
    "        'description': 'Standard deviation of sentiment scores',\n",
    "        'unit': 'Standard deviation (0-1)',\n",
    "        'source': 'Social media sentiment analysis',\n",
    "        'processing': 'Standard deviation of sentiment by LSOA, spatial imputation applied',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'ReviewCount': {\n",
    "        'description': 'Number of reviews/social media posts',\n",
    "        'unit': 'Count',\n",
    "        'source': 'Social media sentiment analysis',\n",
    "        'processing': 'Count of reviews by LSOA, spatial imputation applied',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'NearestStation_m': {\n",
    "        'description': 'Distance to nearest railway/underground station',\n",
    "        'unit': 'Meters',\n",
    "        'source': 'Transport for London station locations',\n",
    "        'processing': 'Euclidean distance from LSOA centroid to nearest station',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'StationsWithin500m': {\n",
    "        'description': 'Number of stations within 500m radius',\n",
    "        'unit': 'Count',\n",
    "        'source': 'Transport for London station locations',\n",
    "        'processing': 'Count of stations within 500m buffer of LSOA centroid',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'NearestRail_m': {\n",
    "        'description': 'Distance to nearest rail network',\n",
    "        'unit': 'Meters',\n",
    "        'source': 'Transport for London rail network',\n",
    "        'processing': 'Euclidean distance from LSOA centroid to nearest rail line',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'StreetLength_m': {\n",
    "        'description': 'Total length of street network within LSOA',\n",
    "        'unit': 'Meters',\n",
    "        'source': 'OpenStreetMap/Transport for London',\n",
    "        'processing': 'Sum of street lengths intersecting LSOA polygon',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'StreetDensity_m_per_m2': {\n",
    "        'description': 'Street network density (street length per unit area)',\n",
    "        'unit': 'Meters per square meter',\n",
    "        'source': 'Calculated from street network and LSOA area',\n",
    "        'processing': 'StreetLength_m / Area_m2',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'StreetSegments': {\n",
    "        'description': 'Number of street segments within LSOA',\n",
    "        'unit': 'Count',\n",
    "        'source': 'OpenStreetMap/Transport for London',\n",
    "        'processing': 'Count of street segments intersecting LSOA polygon',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'LandUse_Diversity': {\n",
    "        'description': 'Number of different land use types in LSOA',\n",
    "        'unit': 'Count',\n",
    "        'source': 'London Land Use Survey',\n",
    "        'processing': 'Count of unique land use categories intersecting LSOA',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    },\n",
    "    'LandUse_Area': {\n",
    "        'description': 'Total area covered by different land uses',\n",
    "        'unit': 'Square meters',\n",
    "        'source': 'London Land Use Survey',\n",
    "        'processing': 'Sum of land use polygon areas intersecting LSOA',\n",
    "        'missing_handled': 'Spatial correlation-based imputation',\n",
    "        'standardized': 'Yes'\n",
    "    }\n",
    "}\n",
    "\n",
    "# Build documentation dataframe\n",
    "for feature in gcn_custom_spatial_scaled.columns:\n",
    "    info = feature_info_spatial.get(feature, {})\n",
    "    \n",
    "    feature_documentation_spatial['Feature_Name'].append(feature)\n",
    "    feature_documentation_spatial['Description'].append(info.get('description', 'No description available'))\n",
    "    feature_documentation_spatial['Data_Type'].append(str(gcn_custom_spatial_scaled[feature].dtype))\n",
    "    feature_documentation_spatial['Unit'].append(info.get('unit', 'Unknown'))\n",
    "    feature_documentation_spatial['Source'].append(info.get('source', 'Unknown'))\n",
    "    feature_documentation_spatial['Processing'].append(info.get('processing', 'Standard processing'))\n",
    "    feature_documentation_spatial['Missing_Values_Handled'].append(info.get('missing_handled', 'Not specified'))\n",
    "    feature_documentation_spatial['Standardized'].append(info.get('standardized', 'Yes'))\n",
    "\n",
    "# Create documentation DataFrame\n",
    "feature_doc_spatial_df = pd.DataFrame(feature_documentation_spatial)\n",
    "\n",
    "# Generate summary statistics for both versions\n",
    "summary_stats_spatial_unscaled = gcn_custom_spatial_imputed.describe().round(4)\n",
    "summary_stats_spatial_scaled = gcn_custom_spatial_scaled.describe().round(4)\n",
    "\n",
    "# Save documentation and statistics\n",
    "doc_file_spatial = \"/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_spatial_imputed_documentation.csv\"\n",
    "summary_file_spatial_unscaled = \"/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_spatial_imputed_summary_stats.csv\"\n",
    "summary_file_spatial_scaled = \"/Users/goffy/Desktop/CASA0004/data-preparation/gcn_feature_matrix_spatial_imputed_scaled_summary_stats.csv\"\n",
    "\n",
    "# Save files\n",
    "feature_doc_spatial_df.to_csv(doc_file_spatial, index=False)\n",
    "summary_stats_spatial_unscaled.to_csv(summary_file_spatial_unscaled)\n",
    "summary_stats_spatial_scaled.to_csv(summary_file_spatial_scaled)\n",
    "\n",
    "print(f\"✅ Documentation and statistics saved:\")\n",
    "print(f\"  📋 Documentation: {doc_file_spatial}\")\n",
    "print(f\"  📊 Summary stats (unscaled): {summary_file_spatial_unscaled}\")\n",
    "print(f\"  📊 Summary stats (scaled): {summary_file_spatial_scaled}\")\n",
    "\n",
    "# =============================================================================\n",
    "# FINAL SUMMARY OF ALL CREATED FILES\n",
    "# =============================================================================\n",
    "\n",
    "print(f\"\\n🎉 SPATIAL CORRELATION-BASED IMPUTATION COMPLETED!\")\n",
    "print(f\"=\"*80)\n",
    "print(f\"📁 All generated files:\")\n",
    "print(f\"\")\n",
    "print(f\"🔧 CUSTOM GCN FEATURE MATRICES (Spatially Imputed):\")\n",
    "print(f\"  1. gcn_feature_matrix_custom_spatial_imputed.csv\")\n",
    "print(f\"     - Raw features with spatial imputation (no standardization)\")\n",
    "print(f\"     - Shape: {gcn_custom_spatial_imputed.shape}\")\n",
    "print(f\"     - Missing values: 0\")\n",
    "print(f\"\")\n",
    "print(f\"  2. gcn_feature_matrix_custom_spatial_imputed_scaled.csv\") \n",
    "print(f\"     - Spatially imputed + standardized features (mean≈0, std≈1)\")\n",
    "print(f\"     - Shape: {gcn_custom_spatial_scaled.shape}\")\n",
    "print(f\"     - Missing values: 0\")\n",
    "print(f\"\")\n",
    "print(f\"  3. gcn_feature_matrix_custom_spatial_imputed_with_geometry.csv\")\n",
    "print(f\"     - Spatially imputed + standardized + geometry (WKT format)\")\n",
    "print(f\"     - Shape: {gcn_spatial_export.shape}\")\n",
    "print(f\"     - For spatial analysis and visualization\")\n",
    "print(f\"\")\n",
    "print(f\"📋 DOCUMENTATION:\")\n",
    "print(f\"  4. gcn_feature_matrix_spatial_imputed_documentation.csv\")\n",
    "print(f\"     - Complete feature documentation with imputation methods\")\n",
    "print(f\"\")\n",
    "print(f\"📊 SUMMARY STATISTICS:\")\n",
    "print(f\"  5. gcn_feature_matrix_spatial_imputed_summary_stats.csv\")\n",
    "print(f\"     - Statistical summary of unscaled spatially-imputed features\")\n",
    "print(f\"\")\n",
    "print(f\"  6. gcn_feature_matrix_spatial_imputed_scaled_summary_stats.csv\")\n",
    "print(f\"     - Statistical summary of scaled spatially-imputed features\")\n",
    "print(f\"\")\n",
    "print(f\"🎯 RECOMMENDED FOR GCN:\")\n",
    "print(f\"   Use: gcn_feature_matrix_custom_spatial_imputed_scaled.csv\")\n",
    "print(f\"   - Complete (no missing values)\")\n",
    "print(f\"   - Standardized (mean≈0, std≈1)\")\n",
    "print(f\"   - Spatially-imputed using neighbor correlation\")\n",
    "print(f\"   - Optimized feature set: {len(feature_columns)} features\")\n",
    "print(f\"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "5e4650e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📁 Current working directory: /Users/goffy/Desktop/CASA0004/data-preparation\n",
      "\n",
      "📁 Files in current directory:\n",
      "  - gcn_feature_matrix_custom_spatial_imputed.csv\n",
      "  - gcn_feature_matrix_custom_spatial_imputed_scaled.csv\n",
      "  - gcn_feature_matrix_custom_spatial_imputed_with_geometry.csv\n",
      "  - gcn_feature_matrix_spatial_imputed_documentation.csv\n",
      "  - gcn_feature_matrix_spatial_imputed_scaled_summary_stats.csv\n",
      "  - gcn_feature_matrix_spatial_imputed_summary_stats.csv\n",
      "\n",
      "🔍 Looking for GCN files specifically:\n",
      "  ✅ gcn_feature_matrix_custom_spatial_imputed.csv (0.74 MB)\n",
      "  ✅ gcn_feature_matrix_custom_spatial_imputed_scaled.csv (1.39 MB)\n",
      "  ✅ gcn_feature_matrix_custom_spatial_imputed_with_geometry.csv (58.08 MB)\n",
      "  ✅ gcn_feature_matrix_spatial_imputed_documentation.csv (0.00 MB)\n",
      "  ✅ gcn_feature_matrix_spatial_imputed_scaled_summary_stats.csv (0.00 MB)\n",
      "  ✅ gcn_feature_matrix_spatial_imputed_summary_stats.csv (0.00 MB)\n",
      "\n",
      "✅ Spatial imputation files created:\n",
      "  ✅ gcn_feature_matrix_custom_spatial_imputed.csv (0.74 MB)\n",
      "  ✅ gcn_feature_matrix_custom_spatial_imputed_scaled.csv (1.39 MB)\n",
      "  ✅ gcn_feature_matrix_custom_spatial_imputed_with_geometry.csv (58.08 MB)\n",
      "  ✅ gcn_feature_matrix_spatial_imputed_documentation.csv (0.00 MB)\n",
      "  ✅ gcn_feature_matrix_spatial_imputed_summary_stats.csv (0.00 MB)\n",
      "  ✅ gcn_feature_matrix_spatial_imputed_scaled_summary_stats.csv (0.00 MB)\n",
      "\n",
      "🎯 FINAL RECOMMENDATION:\n",
      "For your GCN model, use: gcn_feature_matrix_custom_spatial_imputed_scaled.csv\n",
      "This file contains:\n",
      "  - All 15 optimized features\n",
      "  - No missing values (spatially imputed)\n",
      "  - Standardized features (mean≈0, std≈1)\n",
      "  - Ready for Graph Convolutional Network training\n"
     ]
    }
   ],
   "source": [
    "# Check current working directory and verify files were created\n",
    "import os\n",
    "import glob\n",
    "\n",
    "print(\"📁 Current working directory:\", os.getcwd())\n",
    "print(\"\\n📁 Files in current directory:\")\n",
    "current_files = [f for f in os.listdir('.') if f.endswith('.csv')]\n",
    "for f in sorted(current_files):\n",
    "    print(f\"  - {f}\")\n",
    "\n",
    "print(\"\\n🔍 Looking for GCN files specifically:\")\n",
    "gcn_files = glob.glob(\"*gcn*.csv\")\n",
    "for f in sorted(gcn_files):\n",
    "    file_size = os.path.getsize(f) / (1024*1024)  # Size in MB\n",
    "    print(f\"  ✅ {f} ({file_size:.2f} MB)\")\n",
    "\n",
    "# Check if our spatial files exist\n",
    "spatial_files = [\n",
    "    \"gcn_feature_matrix_custom_spatial_imputed.csv\",\n",
    "    \"gcn_feature_matrix_custom_spatial_imputed_scaled.csv\", \n",
    "    \"gcn_feature_matrix_custom_spatial_imputed_with_geometry.csv\",\n",
    "    \"gcn_feature_matrix_spatial_imputed_documentation.csv\",\n",
    "    \"gcn_feature_matrix_spatial_imputed_summary_stats.csv\",\n",
    "    \"gcn_feature_matrix_spatial_imputed_scaled_summary_stats.csv\"\n",
    "]\n",
    "\n",
    "print(f\"\\n✅ Spatial imputation files created:\")\n",
    "for filename in spatial_files:\n",
    "    if os.path.exists(filename):\n",
    "        file_size = os.path.getsize(filename) / (1024*1024)  # Size in MB\n",
    "        print(f\"  ✅ {filename} ({file_size:.2f} MB)\")\n",
    "    else:\n",
    "        print(f\"  ❌ {filename} (missing)\")\n",
    "        \n",
    "print(f\"\\n🎯 FINAL RECOMMENDATION:\")\n",
    "print(f\"For your GCN model, use: gcn_feature_matrix_custom_spatial_imputed_scaled.csv\")\n",
    "print(f\"This file contains:\")\n",
    "print(f\"  - All {len(feature_columns)} optimized features\")\n",
    "print(f\"  - No missing values (spatially imputed)\")\n",
    "print(f\"  - Standardized features (mean≈0, std≈1)\")\n",
    "print(f\"  - Ready for Graph Convolutional Network training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "7de314f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Final verification of the recommended GCN feature matrix...\n",
      "\n",
      "📊 Final GCN Feature Matrix Summary:\n",
      "  📁 File: gcn_feature_matrix_custom_spatial_imputed_scaled.csv\n",
      "  📏 Shape: (4719, 16)\n",
      "  🏷️  Features: ['LSOA_CODE', 'AvgPrice', 'MEAN_PTAL_2023', 'Population', 'Area_km2', 'MeanSentiment', 'SentimentSD', 'ReviewCount', 'NearestStation_m', 'StationsWithin500m', 'NearestRail_m', 'StreetLength_m', 'StreetDensity_m_per_m2', 'StreetSegments', 'LandUse_Diversity', 'LandUse_Area']\n",
      "\n",
      "🔍 Missing values check:\n",
      "  ✅ NO missing values - perfect!\n",
      "\n",
      "📊 Feature standardization check (excluding LSOA_CODE):\n",
      "  Feature means (should be ≈ 0):\n",
      "    - AvgPrice: 0.0\n",
      "    - MEAN_PTAL_2023: 0.0\n",
      "    - Population: 0.0\n",
      "    - Area_km2: 0.0\n",
      "    - MeanSentiment: -0.0\n",
      "  Feature standard deviations (should be ≈ 1):\n",
      "    - AvgPrice: 1.000106\n",
      "    - MEAN_PTAL_2023: 1.000106\n",
      "    - Population: 1.000106\n",
      "    - Area_km2: 1.000106\n",
      "    - MeanSentiment: 1.000106\n",
      "\n",
      "📋 Sample data (first 3 rows):\n",
      "   LSOA_CODE  AvgPrice  MEAN_PTAL_2023  Population  Area_km2  MeanSentiment  \\\n",
      "0  E01000001  0.562237        0.105844    0.435383 -0.407067      -1.423654   \n",
      "1  E01000002  0.594885        0.105844   -0.090485 -0.153783      -0.597232   \n",
      "2  E01000003 -0.214787        0.105844    0.254346 -0.589051      -2.360832   \n",
      "\n",
      "   SentimentSD  ReviewCount  NearestStation_m  StationsWithin500m  \\\n",
      "0     2.395906     0.054214         -1.240113            2.044513   \n",
      "1     0.681987     0.504721          0.217765            2.184298   \n",
      "2    -0.161150    -0.102639         -0.467001            1.904729   \n",
      "\n",
      "   NearestRail_m  StreetLength_m  StreetDensity_m_per_m2  StreetSegments  \\\n",
      "0      -0.798986       -0.333851                0.966407        0.438961   \n",
      "1      -0.960413        0.541895                0.556147        1.129350   \n",
      "2      -0.868722       -1.482122               -0.408466       -1.402077   \n",
      "\n",
      "   LandUse_Diversity  LandUse_Area  \n",
      "0           0.300171     -0.554583  \n",
      "1           0.871112     -0.415063  \n",
      "2          -0.270771     -0.581698  \n",
      "\n",
      "🎉 SUCCESS! Your optimal GCN feature matrix is ready!\n",
      "============================================================\n",
      "📁 RECOMMENDED FILE: gcn_feature_matrix_custom_spatial_imputed_scaled.csv\n",
      "📏 DIMENSIONS: 4719 LSOAs × 15 features\n",
      "🔧 PREPROCESSING: Spatially imputed + Standardized\n",
      "✅ READY FOR: Graph Convolutional Network training\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# =============================================================================\n",
    "# FINAL VERIFICATION OF THE RECOMMENDED GCN FEATURE MATRIX\n",
    "# =============================================================================\n",
    "\n",
    "print(\"🔍 Final verification of the recommended GCN feature matrix...\")\n",
    "\n",
    "# Load the recommended file to verify\n",
    "recommended_file = \"gcn_feature_matrix_custom_spatial_imputed_scaled.csv\"\n",
    "gcn_final = pd.read_csv(recommended_file)\n",
    "\n",
    "print(f\"\\n📊 Final GCN Feature Matrix Summary:\")\n",
    "print(f\"  📁 File: {recommended_file}\")\n",
    "print(f\"  📏 Shape: {gcn_final.shape}\")\n",
    "print(f\"  🏷️  Features: {list(gcn_final.columns)}\")\n",
    "\n",
    "print(f\"\\n🔍 Missing values check:\")\n",
    "missing_check = gcn_final.isnull().sum()\n",
    "if missing_check.sum() == 0:\n",
    "    print(\"  ✅ NO missing values - perfect!\")\n",
    "else:\n",
    "    print(f\"  ⚠️  Found missing values:\")\n",
    "    for col, count in missing_check[missing_check > 0].items():\n",
    "        print(f\"    - {col}: {count} missing\")\n",
    "\n",
    "print(f\"\\n📊 Feature standardization check (excluding LSOA_CODE):\")\n",
    "numeric_features = [col for col in gcn_final.columns if col != 'LSOA_CODE']\n",
    "feature_stats = gcn_final[numeric_features].agg(['mean', 'std']).round(6)\n",
    "\n",
    "print(\"  Feature means (should be ≈ 0):\")\n",
    "for col in numeric_features[:5]:  # Show first 5 features\n",
    "    mean_val = feature_stats.loc['mean', col]\n",
    "    print(f\"    - {col}: {mean_val}\")\n",
    "\n",
    "print(\"  Feature standard deviations (should be ≈ 1):\")\n",
    "for col in numeric_features[:5]:  # Show first 5 features\n",
    "    std_val = feature_stats.loc['std', col]\n",
    "    print(f\"    - {col}: {std_val}\")\n",
    "\n",
    "print(f\"\\n📋 Sample data (first 3 rows):\")\n",
    "print(gcn_final.head(3))\n",
    "\n",
    "print(f\"\\n🎉 SUCCESS! Your optimal GCN feature matrix is ready!\")\n",
    "print(f\"=\"*60)\n",
    "print(f\"📁 RECOMMENDED FILE: {recommended_file}\")\n",
    "print(f\"📏 DIMENSIONS: {gcn_final.shape[0]} LSOAs × {gcn_final.shape[1]-1} features\")\n",
    "print(f\"🔧 PREPROCESSING: Spatially imputed + Standardized\")\n",
    "print(f\"✅ READY FOR: Graph Convolutional Network training\")\n",
    "print(f\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
